{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "data_folder = \"/home/savio/Documents/Tutorials/NLP_Tutorials/datasets/wmt-14-eng-deu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This may take a while.\n",
      "\n",
      "Downloading training-parallel-europarl-v7.tgz...\n",
      "\n",
      "Extracting training-parallel-europarl-v7.tgz...\n",
      "\n",
      "Downloading training-parallel-commoncrawl.tgz...\n",
      "\n",
      "Extracting training-parallel-commoncrawl.tgz...\n",
      "\n",
      "Downloading training-parallel-nc-v9.tgz...\n",
      "\n",
      "Extracting training-parallel-nc-v9.tgz...\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download all the training, test and validation data\n",
    "# 1. Training data - Combination of EuroParlv7, CommonCrawl and NewsCommentary (Total 4.5 million sentence pairs)\n",
    "download_data(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading extracted files and combining...\n",
      "\n",
      "Writing to single files...\n"
     ]
    }
   ],
   "source": [
    "# Read in the training data and combine into a single dataset:\n",
    "read_and_combine_data(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning BPE...\n",
      "\n",
      " BPE DONE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training parameters\n",
      "  input: /home/savio/Documents/Tutorials/NLP_Tutorials/datasets/wmt-14-eng-deu/train.ende\n",
      "  model: /home/savio/Documents/Tutorials/NLP_Tutorials/datasets/wmt-14-eng-deu/bpe.model\n",
      "  vocab_size: 37000\n",
      "  n_threads: 8\n",
      "  character_coverage: 1\n",
      "  pad: 0\n",
      "  unk: 1\n",
      "  bos: 2\n",
      "  eos: 3\n",
      "\n",
      "reading file...\n",
      "learning bpe...\n",
      "number of unique characters in the training data: 3762\n",
      "number of deleted characters: 0\n",
      "number of unique characters left: 3762\n",
      "id: 4000=3785+8               freq: 606668      subword: ant=an+t\n",
      "id: 5000=4691+3909            freq: 78525       subword: ▁know=▁kn+ow\n",
      "id: 6000=3801+13              freq: 39092       subword: ash=as+h\n",
      "id: 7000=3807+5197            freq: 25400       subword: usätz=us+ätz\n",
      "id: 8000=3857+4012            freq: 18095       subword: ▁live=▁l+ive\n",
      "id: 9000=4026+26              freq: 13882       subword: lav=la+v\n",
      "id: 10000=5255+3903           freq: 11067       subword: ▁France=▁Fran+ce\n",
      "id: 11000=8171+3849           freq: 9163        subword: ▁schaffen,=���schaff+en,\n",
      "id: 12000=4354+4496           freq: 7714        subword: ▁dispos=▁dis+pos\n",
      "id: 13000=3805+3810           freq: 6562        subword: ▁unge=▁un+ge\n",
      "id: 14000=3830+25             freq: 5705        subword: ic.=ic+.\n",
      "id: 15000=9645+4009           freq: 5014        subword: ▁Anwendungen=▁Anwend+ungen\n",
      "id: 16000=4869+12981          freq: 4443        subword: ▁Gesetze=▁Ges+etze\n",
      "id: 17000=3782+3878           freq: 3986        subword: aten.=at+en.\n",
      "id: 18000=17+4727             freq: 3602        subword: cale=c+ale\n",
      "id: 19000=4275+3854           freq: 3264        subword: ▁Vorder=▁Vor+der\n",
      "id: 20000=11+4081             freq: 2983        subword: se.=s+e.\n",
      "id: 21000=5727+3967           freq: 2743        subword: raft,=raf+t,\n",
      "id: 22000=14565+5490          freq: 2531        subword: ▁grammatically=▁grammat+ically\n",
      "id: 23000=4636+4832           freq: 2347        subword: ▁Neuer=▁Ne+uer\n",
      "id: 24000=4253+3849           freq: 2180        subword: auen,=au+en,\n",
      "id: 25000=13631+3977          freq: 2028        subword: ▁englischen=▁engl+ischen\n",
      "id: 26000=12414+3785          freq: 1895        subword: ▁Liban=▁Lib+an\n",
      "id: 27000=7758+27             freq: 1772        subword: ▁Brok=▁Bro+k\n",
      "id: 28000=8763+3849           freq: 1665        subword: ▁erwähnen,=▁erwähn+en,\n",
      "id: 29000=4097+14503          freq: 1563        subword: ▁entries=▁ent+ries\n",
      "id: 30000=6330+27             freq: 1471        subword: ▁Funk=▁Fun+k\n",
      "id: 31000=7094+5132           freq: 1394        subword: ▁Partnerschafts=▁Partner+schafts\n",
      "id: 32000=9124+10254          freq: 1321        subword: ▁compromise.=▁comprom+ise.\n",
      "id: 33000=4050+3845           freq: 1252        subword: spra=sp+ra\n",
      "id: 34000=9501+8304           freq: 1191        subword: ▁preparatory=▁prepar+atory\n",
      "id: 35000=3768+3821           freq: 1132        subword: ered=er+ed\n",
      "id: 36000=9910+3879           freq: 1081        subword: ▁verbindlich=▁verbind+lich\n",
      "model saved to: /home/savio/Documents/Tutorials/NLP_Tutorials/datasets/wmt-14-eng-deu/bpe.model\n"
     ]
    }
   ],
   "source": [
    "# Perform byte-pair encoding and create a BPE model\n",
    "perform_bpe(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading BPE model...\n",
      "\n",
      "Re-reading single files...\n",
      "\n",
      "Filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4520623/4520623 [02:48<00:00, 26874.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: 13.85 per cent of en-de pairs were filtered out based on sub-word sequence length limits.\n",
      "\n",
      "Re-writing filtered sentences to single files...\n",
      "\n",
      "...FILTERING DONE!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform filtering of the data:\n",
    "perform_filtering(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data loaders: One for traing and one for validation \n",
    "from sequence_loader import SequenceLoader\n",
    "\n",
    "source_suffix = \"en\"\n",
    "target_suffix = \"de\"\n",
    "tokens_in_batch = 2000\n",
    "\n",
    "train_loader = SequenceLoader(data_folder, source_suffix, target_suffix, \"train\", tokens_in_batch)\n",
    "val_loader   = SequenceLoader(data_folder, source_suffix, target_suffix, \"val\", tokens_in_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model parameters:\n",
    "d_model      = 512  # size of vectors throughout the transformer model\n",
    "n_heads      = 8  # number of heads in the multi-head attention\n",
    "d_queries    = 64  # size of query vectors (and also the size of the key vectors) in the multi-head attention\n",
    "d_values     = 64  # size of value vectors in the multi-head attention\n",
    "d_hidden     = 2048  # an intermediate size in the position-wise Feed forward networks\n",
    "n_layers     = 6  # number of layers in the Encoder and Decoder\n",
    "dropout_prob = 0.1  # dropout probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# Define the Training parameters;\n",
    "batches_per_step = 25000 // tokens_in_batch  # perform a training step, i.e. update parameters, once every so many batches\n",
    "print_frequency = 20  # print status once every so many steps\n",
    "n_steps = 100000  # number of training steps\n",
    "warmup_steps = 8000  # number of warmup steps where learning rate is increased linearly; twice the value in the paper, as in the official transformer repo.\n",
    "step = 1  # the step number, start from 1 to prevent math error in the next line\n",
    "lr = get_lr(step=step, d_model=d_model,\n",
    "            warmup_steps=warmup_steps)  # see utils.py for learning rate schedule; twice the schedule in the paper, as in the official transformer repo.\n",
    "start_epoch = 0  # start at this epoch\n",
    "betas = (0.9, 0.98)  # beta coefficients in the Adam optimizer\n",
    "epsilon = 1e-9  # epsilon term in the Adam optimizer\n",
    "label_smoothing = 0.1  # label smoothing co-efficient in the Cross Entropy loss\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # CPU isn't really practical here\n",
    "cudnn.benchmark = False  # since input tensor size is variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized.\n"
     ]
    }
   ],
   "source": [
    "from transformer import Transformer\n",
    "\n",
    "# Create the positional encoding matrix:\n",
    "positional_encoding = get_positional_encoding(d_model=d_model, max_length=160)  # positional encodings up to the maximum possible pad-length\n",
    "\n",
    "# Instantiate the Transformer model\n",
    "model = Transformer(vocab_size=train_loader.bpe_model.vocab_size(),\n",
    "                    positional_encoding=positional_encoding,\n",
    "                    num_layers= n_layers,\n",
    "                    d_model=d_model,\n",
    "                    n_heads=n_heads,\n",
    "                    dropout_prob = dropout_prob,\n",
    "                    d_hidden=d_hidden,\n",
    "                    d_queries=d_queries,\n",
    "                    d_values=d_values)\n",
    "\n",
    "# Instantiate the Optimizer\n",
    "optimizer = torch.optim.Adam(params=[p for p in model.parameters() if p.requires_grad],\n",
    "                            lr=lr,\n",
    "                            betas=betas,\n",
    "                            eps=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_smoothed_ce import LabelSmoothedCE\n",
    "\n",
    "# Setup the loss function: Label Smoother Cross Entropy\n",
    "\n",
    "# Loss function\n",
    "criterion = LabelSmoothedCE(eps=label_smoothing)\n",
    "\n",
    "# Move to default device\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Find total epochs to train\n",
    "epochs = (n_steps // (train_loader.n_batches // batches_per_step)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from utils import *\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, step):\n",
    "    \"\"\"\n",
    "    One epoch's training.\n",
    "\n",
    "    :param train_loader: loader for training data\n",
    "    :param model: model\n",
    "    :param criterion: label-smoothed cross-entropy loss\n",
    "    :param optimizer: optimizer\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "    model.train()  # training mode enables dropout\n",
    "\n",
    "    # Track some metrics\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    step_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    losses = AverageMeter()  # loss\n",
    "\n",
    "    # Starting time\n",
    "    start_data_time = time.time()\n",
    "    start_step_time = time.time()\n",
    "\n",
    "    # Batches\n",
    "    for i, (source_sequences, target_sequences, source_sequence_lengths, target_sequence_lengths, src_padding_mask, target_padding_mask) in enumerate(\n",
    "            train_loader):\n",
    "\n",
    "        # Move to default device\n",
    "        source_sequences = source_sequences.to(device)  # (N, max_source_sequence_pad_length_this_batch)\n",
    "        target_sequences = target_sequences.to(device)  # (N, max_target_sequence_pad_length_this_batch)\n",
    "        source_sequence_lengths = source_sequence_lengths.to(device)  # (N)\n",
    "        target_sequence_lengths = target_sequence_lengths.to(device)  # (N)\n",
    "\n",
    "        # Time taken to load data\n",
    "        data_time.update(time.time() - start_data_time)\n",
    "\n",
    "        src_padding_mask = src_padding_mask.to(device)\n",
    "        target_padding_mask = target_padding_mask.to(device)\n",
    "\n",
    "        # Forward prop.\n",
    "        predicted_sequences = model(source_sequences, target_sequences, src_padding_mask,\n",
    "                                    target_padding_mask)  # (1, target_sequence_length, vocab_size)\n",
    "\n",
    "        # Note: If the target sequence is \"<BOS> w1 w2 ... wN <EOS> <PAD> <PAD> <PAD> <PAD> ...\"\n",
    "        # we should consider only \"w1 w2 ... wN <EOS>\" as <BOS> is not predicted\n",
    "        # Therefore, pads start after (length - 1) positions\n",
    "        loss = criterion(inputs=predicted_sequences,\n",
    "                         targets=target_sequences[:, 1:],\n",
    "                         lengths=target_sequence_lengths - 1)  # scalar\n",
    "\n",
    "        # Backward prop.\n",
    "        (loss / batches_per_step).backward()\n",
    "\n",
    "        # Keep track of losses\n",
    "        losses.update(loss.item(), (target_sequence_lengths - 1).sum().item())\n",
    "\n",
    "        # Update model (i.e. perform a training step) only after gradients are accumulated from batches_per_step batches\n",
    "        if (i + 1) % batches_per_step == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This step is now complete\n",
    "            step += 1\n",
    "\n",
    "            # Update learning rate after each step\n",
    "            change_lr(optimizer, new_lr=get_lr(step=step, d_model=d_model, warmup_steps=warmup_steps))\n",
    "\n",
    "            # Time taken for this training step\n",
    "            step_time.update(time.time() - start_step_time)\n",
    "\n",
    "            # Print status\n",
    "            if step % print_frequency == 0:\n",
    "                print('Epoch {0}/{1}-----'\n",
    "                      'Batch {2}/{3}-----'\n",
    "                      'Step {4}/{5}-----'\n",
    "                      'Data Time {data_time.val:.3f} ({data_time.avg:.3f})-----'\n",
    "                      'Step Time {step_time.val:.3f} ({step_time.avg:.3f})-----'\n",
    "                      'Loss {losses.val:.4f} ({losses.avg:.4f})'.format(epoch + 1, epochs,\n",
    "                                                                        i + 1, train_loader.n_batches,\n",
    "                                                                        step, n_steps,\n",
    "                                                                        step_time=step_time,\n",
    "                                                                        data_time=data_time,\n",
    "                                                                        losses=losses))\n",
    "\n",
    "            # Reset step time\n",
    "            start_step_time = time.time()\n",
    "\n",
    "            # If this is the last one or two epochs, save checkpoints at regular intervals for averaging\n",
    "            if epoch in [epochs - 1, epochs - 2] and step % 1500 == 0:  # 'epoch' is 0-indexed\n",
    "                save_checkpoint(epoch, model, optimizer, prefix='step' + str(step) + \"_\")\n",
    "\n",
    "        # Reset data time\n",
    "        start_data_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    One epoch's validation.\n",
    "\n",
    "    :param val_loader: loader for validation data\n",
    "    :param model: model\n",
    "    :param criterion: label-smoothed cross-entropy loss\n",
    "    \"\"\"\n",
    "    model.eval()  # eval mode disables dropout\n",
    "\n",
    "    # Prohibit gradient computation explicitly\n",
    "    with torch.no_grad():\n",
    "        losses = AverageMeter()\n",
    "        # Batches\n",
    "        for i, (source_sequence, target_sequence, source_sequence_length, target_sequence_length, src_padding_mask, target_padding_mask) in enumerate(\n",
    "                tqdm(val_loader, total=val_loader.n_batches)):\n",
    "            source_sequence = source_sequence.to(device)  # (1, source_sequence_length)\n",
    "            target_sequence = target_sequence.to(device)  # (1, target_sequence_length)\n",
    "            source_sequence_length = source_sequence_length.to(device)  # (1)\n",
    "            target_sequence_length = target_sequence_length.to(device)  # (1)\n",
    "            src_padding_mask = src_padding_mask.to(device)\n",
    "            target_padding_mask = target_padding_mask.to(device)\n",
    "\n",
    "            # Forward prop.\n",
    "            predicted_sequence = model(source_sequence, target_sequence, src_padding_mask,\n",
    "                                       target_padding_mask)  # (1, target_sequence_length, vocab_size)\n",
    "\n",
    "            # Note: If the target sequence is \"<BOS> w1 w2 ... wN <EOS> <PAD> <PAD> <PAD> <PAD> ...\"\n",
    "            # we should consider only \"w1 w2 ... wN <EOS>\" as <BOS> is not predicted\n",
    "            # Therefore, pads start after (length - 1) positions\n",
    "            loss = criterion(inputs=predicted_sequence,\n",
    "                             targets=target_sequence[:, 1:],\n",
    "                             lengths=target_sequence_length - 1)  # scalar\n",
    "\n",
    "            # Keep track of losses\n",
    "            losses.update(loss.item(), (target_sequence_length - 1).sum().item())\n",
    "\n",
    "        print(\"\\nValidation loss: %.3f\\n\\n\" % losses.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch #  0\n",
      "Epoch 1/21-----Batch 240/59476-----Step 20/100000-----Data Time 0.003 (0.005)-----Step Time 3.124 (3.089)-----Loss 10.7014 (10.8921)\n",
      "Epoch 1/21-----Batch 480/59476-----Step 40/100000-----Data Time 0.004 (0.005)-----Step Time 3.283 (3.121)-----Loss 10.2190 (10.6955)\n",
      "Epoch 1/21-----Batch 720/59476-----Step 60/100000-----Data Time 0.003 (0.005)-----Step Time 3.417 (3.168)-----Loss 9.8823 (10.5131)\n",
      "Epoch 1/21-----Batch 960/59476-----Step 80/100000-----Data Time 0.003 (0.005)-----Step Time 3.509 (3.217)-----Loss 9.7260 (10.3752)\n",
      "Epoch 1/21-----Batch 1200/59476-----Step 100/100000-----Data Time 0.003 (0.005)-----Step Time 3.380 (3.246)-----Loss 9.8473 (10.2598)\n",
      "Epoch 1/21-----Batch 1440/59476-----Step 120/100000-----Data Time 0.004 (0.005)-----Step Time 3.348 (3.274)-----Loss 9.9047 (10.1629)\n",
      "Epoch 1/21-----Batch 1680/59476-----Step 140/100000-----Data Time 0.003 (0.005)-----Step Time 3.520 (3.300)-----Loss 9.3696 (10.0734)\n",
      "Epoch 1/21-----Batch 1920/59476-----Step 160/100000-----Data Time 0.003 (0.005)-----Step Time 3.244 (3.323)-----Loss 9.1309 (9.9864)\n",
      "Epoch 1/21-----Batch 2160/59476-----Step 180/100000-----Data Time 0.003 (0.005)-----Step Time 3.249 (3.321)-----Loss 9.0201 (9.9034)\n",
      "Epoch 1/21-----Batch 2400/59476-----Step 200/100000-----Data Time 0.002 (0.005)-----Step Time 3.518 (3.328)-----Loss 9.2263 (9.8241)\n",
      "Epoch 1/21-----Batch 2640/59476-----Step 220/100000-----Data Time 0.004 (0.005)-----Step Time 3.938 (3.344)-----Loss 9.1379 (9.7449)\n",
      "Epoch 1/21-----Batch 2880/59476-----Step 240/100000-----Data Time 0.003 (0.005)-----Step Time 3.774 (3.356)-----Loss 8.9990 (9.6685)\n",
      "Epoch 1/21-----Batch 3120/59476-----Step 260/100000-----Data Time 0.003 (0.005)-----Step Time 3.697 (3.379)-----Loss 8.5056 (9.5944)\n",
      "Epoch 1/21-----Batch 3360/59476-----Step 280/100000-----Data Time 0.004 (0.005)-----Step Time 3.506 (3.396)-----Loss 8.2551 (9.5241)\n",
      "Epoch 1/21-----Batch 3600/59476-----Step 300/100000-----Data Time 0.005 (0.005)-----Step Time 3.744 (3.400)-----Loss 8.5566 (9.4555)\n",
      "Epoch 1/21-----Batch 3840/59476-----Step 320/100000-----Data Time 0.004 (0.005)-----Step Time 3.421 (3.403)-----Loss 8.5120 (9.3939)\n",
      "Epoch 1/21-----Batch 4080/59476-----Step 340/100000-----Data Time 0.004 (0.005)-----Step Time 3.275 (3.402)-----Loss 8.4790 (9.3356)\n",
      "Epoch 1/21-----Batch 4320/59476-----Step 360/100000-----Data Time 0.002 (0.005)-----Step Time 3.437 (3.402)-----Loss 8.1341 (9.2802)\n",
      "Epoch 1/21-----Batch 4560/59476-----Step 380/100000-----Data Time 0.004 (0.005)-----Step Time 3.580 (3.414)-----Loss 8.3146 (9.2287)\n",
      "Epoch 1/21-----Batch 4800/59476-----Step 400/100000-----Data Time 0.003 (0.005)-----Step Time 3.749 (3.423)-----Loss 8.2900 (9.1812)\n",
      "Epoch 1/21-----Batch 5040/59476-----Step 420/100000-----Data Time 0.007 (0.005)-----Step Time 3.613 (3.431)-----Loss 8.0749 (9.1360)\n",
      "Epoch 1/21-----Batch 5280/59476-----Step 440/100000-----Data Time 0.004 (0.005)-----Step Time 3.465 (3.441)-----Loss 8.0839 (9.0939)\n",
      "Epoch 1/21-----Batch 5520/59476-----Step 460/100000-----Data Time 0.005 (0.005)-----Step Time 3.478 (3.442)-----Loss 7.8906 (9.0531)\n",
      "Epoch 1/21-----Batch 5760/59476-----Step 480/100000-----Data Time 0.005 (0.005)-----Step Time 3.791 (3.457)-----Loss 8.0668 (9.0128)\n",
      "Epoch 1/21-----Batch 6000/59476-----Step 500/100000-----Data Time 0.007 (0.005)-----Step Time 3.420 (3.463)-----Loss 7.5531 (8.9769)\n",
      "Epoch 1/21-----Batch 6240/59476-----Step 520/100000-----Data Time 0.003 (0.005)-----Step Time 3.620 (3.468)-----Loss 8.2648 (8.9402)\n",
      "Epoch 1/21-----Batch 6480/59476-----Step 540/100000-----Data Time 0.004 (0.005)-----Step Time 3.619 (3.474)-----Loss 7.2014 (8.9048)\n",
      "Epoch 1/21-----Batch 6720/59476-----Step 560/100000-----Data Time 0.004 (0.005)-----Step Time 3.067 (3.474)-----Loss 8.0357 (8.8682)\n",
      "Epoch 1/21-----Batch 6960/59476-----Step 580/100000-----Data Time 0.002 (0.005)-----Step Time 2.864 (3.460)-----Loss 8.4329 (8.8329)\n",
      "Epoch 1/21-----Batch 7200/59476-----Step 600/100000-----Data Time 0.003 (0.005)-----Step Time 3.102 (3.448)-----Loss 8.2444 (8.7989)\n",
      "Epoch 1/21-----Batch 7440/59476-----Step 620/100000-----Data Time 0.004 (0.005)-----Step Time 3.046 (3.436)-----Loss 8.0308 (8.7666)\n",
      "Epoch 1/21-----Batch 7680/59476-----Step 640/100000-----Data Time 0.003 (0.005)-----Step Time 3.020 (3.425)-----Loss 8.3271 (8.7360)\n",
      "Epoch 1/21-----Batch 7920/59476-----Step 660/100000-----Data Time 0.004 (0.005)-----Step Time 3.084 (3.415)-----Loss 8.2188 (8.7051)\n",
      "Epoch 1/21-----Batch 8160/59476-----Step 680/100000-----Data Time 0.003 (0.005)-----Step Time 3.053 (3.405)-----Loss 7.3035 (8.6749)\n",
      "Epoch 1/21-----Batch 8400/59476-----Step 700/100000-----Data Time 0.003 (0.005)-----Step Time 3.077 (3.397)-----Loss 8.1757 (8.6450)\n",
      "Epoch 1/21-----Batch 8640/59476-----Step 720/100000-----Data Time 0.003 (0.005)-----Step Time 2.939 (3.388)-----Loss 7.9940 (8.6147)\n",
      "Epoch 1/21-----Batch 8880/59476-----Step 740/100000-----Data Time 0.004 (0.005)-----Step Time 3.034 (3.380)-----Loss 7.6771 (8.5850)\n",
      "Epoch 1/21-----Batch 9120/59476-----Step 760/100000-----Data Time 0.003 (0.005)-----Step Time 3.073 (3.372)-----Loss 8.0279 (8.5558)\n",
      "Epoch 1/21-----Batch 9360/59476-----Step 780/100000-----Data Time 0.004 (0.005)-----Step Time 3.090 (3.365)-----Loss 7.5856 (8.5280)\n",
      "Epoch 1/21-----Batch 9600/59476-----Step 800/100000-----Data Time 0.004 (0.005)-----Step Time 3.002 (3.358)-----Loss 7.3197 (8.5008)\n",
      "Epoch 1/21-----Batch 9840/59476-----Step 820/100000-----Data Time 0.003 (0.005)-----Step Time 3.092 (3.352)-----Loss 7.1491 (8.4736)\n",
      "Epoch 1/21-----Batch 10080/59476-----Step 840/100000-----Data Time 0.004 (0.005)-----Step Time 3.127 (3.346)-----Loss 7.7634 (8.4462)\n",
      "Epoch 1/21-----Batch 10320/59476-----Step 860/100000-----Data Time 0.003 (0.005)-----Step Time 3.094 (3.340)-----Loss 6.8342 (8.4198)\n",
      "Epoch 1/21-----Batch 10560/59476-----Step 880/100000-----Data Time 0.002 (0.005)-----Step Time 3.047 (3.335)-----Loss 8.1964 (8.3951)\n",
      "Epoch 1/21-----Batch 10800/59476-----Step 900/100000-----Data Time 0.004 (0.005)-----Step Time 3.076 (3.329)-----Loss 7.1672 (8.3704)\n",
      "Epoch 1/21-----Batch 11040/59476-----Step 920/100000-----Data Time 0.003 (0.005)-----Step Time 3.187 (3.325)-----Loss 7.3561 (8.3459)\n",
      "Epoch 1/21-----Batch 11280/59476-----Step 940/100000-----Data Time 0.003 (0.005)-----Step Time 3.066 (3.320)-----Loss 7.8040 (8.3201)\n",
      "Epoch 1/21-----Batch 11520/59476-----Step 960/100000-----Data Time 0.003 (0.005)-----Step Time 3.023 (3.316)-----Loss 7.8975 (8.2947)\n",
      "Epoch 1/21-----Batch 11760/59476-----Step 980/100000-----Data Time 0.004 (0.005)-----Step Time 3.146 (3.312)-----Loss 6.9242 (8.2709)\n",
      "Epoch 1/21-----Batch 12000/59476-----Step 1000/100000-----Data Time 0.004 (0.005)-----Step Time 3.073 (3.308)-----Loss 7.7126 (8.2470)\n",
      "Epoch 1/21-----Batch 12240/59476-----Step 1020/100000-----Data Time 0.004 (0.005)-----Step Time 3.066 (3.304)-----Loss 7.0606 (8.2235)\n",
      "Epoch 1/21-----Batch 12480/59476-----Step 1040/100000-----Data Time 0.003 (0.005)-----Step Time 3.087 (3.300)-----Loss 6.5426 (8.2005)\n",
      "Epoch 1/21-----Batch 12720/59476-----Step 1060/100000-----Data Time 0.003 (0.005)-----Step Time 3.122 (3.296)-----Loss 6.3877 (8.1776)\n",
      "Epoch 1/21-----Batch 12960/59476-----Step 1080/100000-----Data Time 0.003 (0.005)-----Step Time 3.109 (3.293)-----Loss 7.8927 (8.1549)\n",
      "Epoch 1/21-----Batch 13200/59476-----Step 1100/100000-----Data Time 0.003 (0.005)-----Step Time 3.077 (3.290)-----Loss 7.2501 (8.1331)\n",
      "Epoch 1/21-----Batch 13440/59476-----Step 1120/100000-----Data Time 0.008 (0.005)-----Step Time 3.221 (3.286)-----Loss 6.7423 (8.1121)\n",
      "Epoch 1/21-----Batch 13680/59476-----Step 1140/100000-----Data Time 0.003 (0.005)-----Step Time 3.146 (3.283)-----Loss 6.4423 (8.0912)\n",
      "Epoch 1/21-----Batch 13920/59476-----Step 1160/100000-----Data Time 0.003 (0.005)-----Step Time 3.134 (3.280)-----Loss 6.5129 (8.0706)\n",
      "Epoch 1/21-----Batch 14160/59476-----Step 1180/100000-----Data Time 0.003 (0.005)-----Step Time 3.080 (3.277)-----Loss 6.5961 (8.0504)\n",
      "Epoch 1/21-----Batch 14400/59476-----Step 1200/100000-----Data Time 0.003 (0.005)-----Step Time 3.080 (3.274)-----Loss 7.2222 (8.0296)\n",
      "Epoch 1/21-----Batch 14640/59476-----Step 1220/100000-----Data Time 0.004 (0.005)-----Step Time 3.103 (3.271)-----Loss 5.8240 (8.0097)\n",
      "Epoch 1/21-----Batch 14880/59476-----Step 1240/100000-----Data Time 0.003 (0.005)-----Step Time 3.545 (3.271)-----Loss 6.4560 (7.9896)\n",
      "Epoch 1/21-----Batch 15120/59476-----Step 1260/100000-----Data Time 0.004 (0.005)-----Step Time 3.120 (3.270)-----Loss 7.1339 (7.9697)\n",
      "Epoch 1/21-----Batch 15360/59476-----Step 1280/100000-----Data Time 0.004 (0.005)-----Step Time 2.999 (3.267)-----Loss 7.4462 (7.9500)\n",
      "Epoch 1/21-----Batch 15600/59476-----Step 1300/100000-----Data Time 0.003 (0.005)-----Step Time 3.148 (3.264)-----Loss 6.0758 (7.9315)\n",
      "Epoch 1/21-----Batch 15840/59476-----Step 1320/100000-----Data Time 0.005 (0.005)-----Step Time 3.116 (3.262)-----Loss 6.5485 (7.9125)\n",
      "Epoch 1/21-----Batch 16080/59476-----Step 1340/100000-----Data Time 0.001 (0.005)-----Step Time 2.942 (3.260)-----Loss 6.7508 (7.8937)\n",
      "Epoch 1/21-----Batch 16320/59476-----Step 1360/100000-----Data Time 0.003 (0.005)-----Step Time 3.071 (3.257)-----Loss 7.0759 (7.8746)\n",
      "Epoch 1/21-----Batch 16560/59476-----Step 1380/100000-----Data Time 0.004 (0.005)-----Step Time 3.024 (3.255)-----Loss 6.9872 (7.8567)\n",
      "Epoch 1/21-----Batch 16800/59476-----Step 1400/100000-----Data Time 0.004 (0.005)-----Step Time 3.101 (3.253)-----Loss 6.7804 (7.8378)\n",
      "Epoch 1/21-----Batch 17040/59476-----Step 1420/100000-----Data Time 0.003 (0.005)-----Step Time 3.304 (3.251)-----Loss 6.6357 (7.8191)\n",
      "Epoch 1/21-----Batch 17280/59476-----Step 1440/100000-----Data Time 0.003 (0.005)-----Step Time 3.002 (3.249)-----Loss 5.9958 (7.8008)\n",
      "Epoch 1/21-----Batch 17520/59476-----Step 1460/100000-----Data Time 0.003 (0.005)-----Step Time 3.065 (3.247)-----Loss 6.9235 (7.7822)\n",
      "Epoch 1/21-----Batch 17760/59476-----Step 1480/100000-----Data Time 0.004 (0.005)-----Step Time 3.044 (3.246)-----Loss 6.3121 (7.7632)\n",
      "Epoch 1/21-----Batch 18000/59476-----Step 1500/100000-----Data Time 0.003 (0.005)-----Step Time 3.105 (3.244)-----Loss 7.1328 (7.7456)\n",
      "Epoch 1/21-----Batch 18240/59476-----Step 1520/100000-----Data Time 0.003 (0.005)-----Step Time 3.164 (3.242)-----Loss 6.6274 (7.7269)\n",
      "Epoch 1/21-----Batch 18480/59476-----Step 1540/100000-----Data Time 0.003 (0.005)-----Step Time 3.151 (3.240)-----Loss 5.8441 (7.7091)\n",
      "Epoch 1/21-----Batch 18720/59476-----Step 1560/100000-----Data Time 0.003 (0.005)-----Step Time 3.098 (3.238)-----Loss 6.5349 (7.6919)\n",
      "Epoch 1/21-----Batch 18960/59476-----Step 1580/100000-----Data Time 0.003 (0.005)-----Step Time 3.078 (3.237)-----Loss 6.9034 (7.6752)\n",
      "Epoch 1/21-----Batch 19200/59476-----Step 1600/100000-----Data Time 0.004 (0.005)-----Step Time 3.060 (3.235)-----Loss 6.8721 (7.6586)\n",
      "Epoch 1/21-----Batch 19440/59476-----Step 1620/100000-----Data Time 0.003 (0.005)-----Step Time 3.044 (3.234)-----Loss 6.8004 (7.6415)\n",
      "Epoch 1/21-----Batch 19680/59476-----Step 1640/100000-----Data Time 0.004 (0.005)-----Step Time 3.060 (3.232)-----Loss 7.2118 (7.6242)\n",
      "Epoch 1/21-----Batch 19920/59476-----Step 1660/100000-----Data Time 0.005 (0.005)-----Step Time 3.128 (3.231)-----Loss 5.9123 (7.6073)\n",
      "Epoch 1/21-----Batch 20160/59476-----Step 1680/100000-----Data Time 0.006 (0.005)-----Step Time 3.120 (3.230)-----Loss 5.5627 (7.5909)\n",
      "Epoch 1/21-----Batch 20400/59476-----Step 1700/100000-----Data Time 0.004 (0.005)-----Step Time 3.021 (3.229)-----Loss 5.9267 (7.5738)\n",
      "Epoch 1/21-----Batch 20640/59476-----Step 1720/100000-----Data Time 0.004 (0.005)-----Step Time 3.169 (3.227)-----Loss 5.7834 (7.5568)\n",
      "Epoch 1/21-----Batch 20880/59476-----Step 1740/100000-----Data Time 0.004 (0.005)-----Step Time 3.105 (3.226)-----Loss 5.2744 (7.5401)\n",
      "Epoch 1/21-----Batch 21120/59476-----Step 1760/100000-----Data Time 0.003 (0.005)-----Step Time 3.123 (3.225)-----Loss 5.5278 (7.5226)\n",
      "Epoch 1/21-----Batch 21360/59476-----Step 1780/100000-----Data Time 0.004 (0.005)-----Step Time 3.116 (3.224)-----Loss 6.0169 (7.5062)\n",
      "Epoch 1/21-----Batch 21600/59476-----Step 1800/100000-----Data Time 0.004 (0.005)-----Step Time 3.131 (3.223)-----Loss 6.1686 (7.4894)\n",
      "Epoch 1/21-----Batch 21840/59476-----Step 1820/100000-----Data Time 0.004 (0.005)-----Step Time 3.080 (3.221)-----Loss 6.7092 (7.4718)\n",
      "Epoch 1/21-----Batch 22080/59476-----Step 1840/100000-----Data Time 0.003 (0.005)-----Step Time 3.104 (3.220)-----Loss 5.4731 (7.4557)\n",
      "Epoch 1/21-----Batch 22320/59476-----Step 1860/100000-----Data Time 0.004 (0.005)-----Step Time 3.074 (3.219)-----Loss 5.8234 (7.4394)\n",
      "Epoch 1/21-----Batch 22560/59476-----Step 1880/100000-----Data Time 0.003 (0.005)-----Step Time 3.135 (3.218)-----Loss 5.1977 (7.4232)\n",
      "Epoch 1/21-----Batch 22800/59476-----Step 1900/100000-----Data Time 0.003 (0.005)-----Step Time 3.166 (3.216)-----Loss 6.0247 (7.4058)\n",
      "Epoch 1/21-----Batch 23040/59476-----Step 1920/100000-----Data Time 0.003 (0.005)-----Step Time 3.101 (3.215)-----Loss 6.0807 (7.3899)\n",
      "Epoch 1/21-----Batch 23280/59476-----Step 1940/100000-----Data Time 0.004 (0.005)-----Step Time 3.074 (3.214)-----Loss 6.4267 (7.3731)\n",
      "Epoch 1/21-----Batch 23520/59476-----Step 1960/100000-----Data Time 0.003 (0.005)-----Step Time 3.083 (3.213)-----Loss 6.2416 (7.3568)\n",
      "Epoch 1/21-----Batch 23760/59476-----Step 1980/100000-----Data Time 0.003 (0.005)-----Step Time 3.104 (3.212)-----Loss 5.9865 (7.3405)\n",
      "Epoch 1/21-----Batch 24000/59476-----Step 2000/100000-----Data Time 0.004 (0.005)-----Step Time 3.405 (3.211)-----Loss 5.4767 (7.3238)\n",
      "Epoch 1/21-----Batch 24240/59476-----Step 2020/100000-----Data Time 0.003 (0.005)-----Step Time 3.112 (3.210)-----Loss 5.8573 (7.3072)\n",
      "Epoch 1/21-----Batch 24480/59476-----Step 2040/100000-----Data Time 0.003 (0.005)-----Step Time 3.062 (3.209)-----Loss 6.2516 (7.2915)\n",
      "Epoch 1/21-----Batch 24720/59476-----Step 2060/100000-----Data Time 0.003 (0.005)-----Step Time 3.112 (3.208)-----Loss 5.2717 (7.2754)\n",
      "Epoch 1/21-----Batch 24960/59476-----Step 2080/100000-----Data Time 0.003 (0.005)-----Step Time 3.041 (3.207)-----Loss 5.7448 (7.2601)\n",
      "Epoch 1/21-----Batch 25200/59476-----Step 2100/100000-----Data Time 0.004 (0.005)-----Step Time 3.078 (3.206)-----Loss 5.9997 (7.2444)\n",
      "Epoch 1/21-----Batch 25440/59476-----Step 2120/100000-----Data Time 0.003 (0.005)-----Step Time 3.121 (3.206)-----Loss 5.9393 (7.2283)\n",
      "Epoch 1/21-----Batch 25680/59476-----Step 2140/100000-----Data Time 0.003 (0.005)-----Step Time 3.090 (3.205)-----Loss 5.4642 (7.2129)\n",
      "Epoch 1/21-----Batch 25920/59476-----Step 2160/100000-----Data Time 0.003 (0.005)-----Step Time 3.086 (3.204)-----Loss 4.8583 (7.1975)\n",
      "Epoch 1/21-----Batch 26160/59476-----Step 2180/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.204)-----Loss 4.9873 (7.1818)\n",
      "Epoch 1/21-----Batch 26400/59476-----Step 2200/100000-----Data Time 0.003 (0.005)-----Step Time 3.111 (3.203)-----Loss 4.9056 (7.1662)\n",
      "Epoch 1/21-----Batch 26640/59476-----Step 2220/100000-----Data Time 0.003 (0.005)-----Step Time 3.109 (3.202)-----Loss 6.6106 (7.1508)\n",
      "Epoch 1/21-----Batch 26880/59476-----Step 2240/100000-----Data Time 0.003 (0.005)-----Step Time 3.029 (3.201)-----Loss 5.5312 (7.1352)\n",
      "Epoch 1/21-----Batch 27120/59476-----Step 2260/100000-----Data Time 0.003 (0.005)-----Step Time 3.096 (3.200)-----Loss 5.3951 (7.1199)\n",
      "Epoch 1/21-----Batch 27360/59476-----Step 2280/100000-----Data Time 0.003 (0.005)-----Step Time 3.032 (3.199)-----Loss 4.5848 (7.1054)\n",
      "Epoch 1/21-----Batch 27600/59476-----Step 2300/100000-----Data Time 0.003 (0.005)-----Step Time 3.120 (3.198)-----Loss 4.8452 (7.0909)\n",
      "Epoch 1/21-----Batch 27840/59476-----Step 2320/100000-----Data Time 0.003 (0.005)-----Step Time 3.089 (3.198)-----Loss 5.9244 (7.0758)\n",
      "Epoch 1/21-----Batch 28080/59476-----Step 2340/100000-----Data Time 0.003 (0.005)-----Step Time 3.090 (3.197)-----Loss 4.2877 (7.0607)\n",
      "Epoch 1/21-----Batch 28320/59476-----Step 2360/100000-----Data Time 0.003 (0.005)-----Step Time 3.119 (3.196)-----Loss 4.4952 (7.0460)\n",
      "Epoch 1/21-----Batch 28560/59476-----Step 2380/100000-----Data Time 0.003 (0.005)-----Step Time 3.119 (3.195)-----Loss 4.8012 (7.0311)\n",
      "Epoch 1/21-----Batch 28800/59476-----Step 2400/100000-----Data Time 0.005 (0.005)-----Step Time 3.155 (3.195)-----Loss 4.6039 (7.0156)\n",
      "Epoch 1/21-----Batch 29040/59476-----Step 2420/100000-----Data Time 0.003 (0.005)-----Step Time 3.099 (3.194)-----Loss 5.6768 (7.0004)\n",
      "Epoch 1/21-----Batch 29280/59476-----Step 2440/100000-----Data Time 0.004 (0.005)-----Step Time 3.154 (3.193)-----Loss 4.3362 (6.9853)\n",
      "Epoch 1/21-----Batch 29520/59476-----Step 2460/100000-----Data Time 0.003 (0.005)-----Step Time 3.119 (3.193)-----Loss 5.3070 (6.9706)\n",
      "Epoch 1/21-----Batch 29760/59476-----Step 2480/100000-----Data Time 0.004 (0.005)-----Step Time 3.094 (3.192)-----Loss 3.7518 (6.9554)\n",
      "Epoch 1/21-----Batch 30000/59476-----Step 2500/100000-----Data Time 0.003 (0.005)-----Step Time 3.132 (3.191)-----Loss 5.7067 (6.9411)\n",
      "Epoch 1/21-----Batch 30240/59476-----Step 2520/100000-----Data Time 0.003 (0.005)-----Step Time 3.044 (3.190)-----Loss 5.3704 (6.9269)\n",
      "Epoch 1/21-----Batch 30480/59476-----Step 2540/100000-----Data Time 0.003 (0.005)-----Step Time 3.125 (3.190)-----Loss 4.3692 (6.9123)\n",
      "Epoch 1/21-----Batch 30720/59476-----Step 2560/100000-----Data Time 0.003 (0.005)-----Step Time 3.176 (3.189)-----Loss 5.5351 (6.8977)\n",
      "Epoch 1/21-----Batch 30960/59476-----Step 2580/100000-----Data Time 0.003 (0.005)-----Step Time 3.096 (3.189)-----Loss 4.9567 (6.8828)\n",
      "Epoch 1/21-----Batch 31200/59476-----Step 2600/100000-----Data Time 0.003 (0.005)-----Step Time 3.036 (3.188)-----Loss 5.1296 (6.8678)\n",
      "Epoch 1/21-----Batch 31440/59476-----Step 2620/100000-----Data Time 0.003 (0.005)-----Step Time 3.154 (3.188)-----Loss 5.7256 (6.8543)\n",
      "Epoch 1/21-----Batch 31680/59476-----Step 2640/100000-----Data Time 0.003 (0.005)-----Step Time 3.065 (3.187)-----Loss 4.8133 (6.8402)\n",
      "Epoch 1/21-----Batch 31920/59476-----Step 2660/100000-----Data Time 0.003 (0.005)-----Step Time 3.070 (3.187)-----Loss 5.5302 (6.8263)\n",
      "Epoch 1/21-----Batch 32160/59476-----Step 2680/100000-----Data Time 0.004 (0.005)-----Step Time 3.031 (3.186)-----Loss 4.3274 (6.8125)\n",
      "Epoch 1/21-----Batch 32400/59476-----Step 2700/100000-----Data Time 0.003 (0.005)-----Step Time 3.091 (3.185)-----Loss 4.2570 (6.7989)\n",
      "Epoch 1/21-----Batch 32640/59476-----Step 2720/100000-----Data Time 0.004 (0.005)-----Step Time 3.072 (3.185)-----Loss 6.1747 (6.7849)\n",
      "Epoch 1/21-----Batch 32880/59476-----Step 2740/100000-----Data Time 0.003 (0.005)-----Step Time 3.067 (3.184)-----Loss 5.1762 (6.7711)\n",
      "Epoch 1/21-----Batch 33120/59476-----Step 2760/100000-----Data Time 0.003 (0.005)-----Step Time 3.394 (3.184)-----Loss 4.2967 (6.7575)\n",
      "Epoch 1/21-----Batch 33360/59476-----Step 2780/100000-----Data Time 0.003 (0.005)-----Step Time 3.132 (3.183)-----Loss 4.4277 (6.7427)\n",
      "Epoch 1/21-----Batch 33600/59476-----Step 2800/100000-----Data Time 0.003 (0.005)-----Step Time 3.049 (3.183)-----Loss 4.4055 (6.7299)\n",
      "Epoch 1/21-----Batch 33840/59476-----Step 2820/100000-----Data Time 0.003 (0.005)-----Step Time 3.145 (3.182)-----Loss 4.7869 (6.7167)\n",
      "Epoch 1/21-----Batch 34080/59476-----Step 2840/100000-----Data Time 0.003 (0.005)-----Step Time 3.046 (3.182)-----Loss 5.7552 (6.7029)\n",
      "Epoch 1/21-----Batch 34320/59476-----Step 2860/100000-----Data Time 0.003 (0.005)-----Step Time 3.058 (3.181)-----Loss 3.9192 (6.6891)\n",
      "Epoch 1/21-----Batch 34560/59476-----Step 2880/100000-----Data Time 0.003 (0.005)-----Step Time 3.069 (3.181)-----Loss 4.4175 (6.6761)\n",
      "Epoch 1/21-----Batch 34800/59476-----Step 2900/100000-----Data Time 0.003 (0.005)-----Step Time 3.025 (3.180)-----Loss 5.5308 (6.6629)\n",
      "Epoch 1/21-----Batch 35040/59476-----Step 2920/100000-----Data Time 0.003 (0.005)-----Step Time 3.070 (3.179)-----Loss 5.5725 (6.6499)\n",
      "Epoch 1/21-----Batch 35280/59476-----Step 2940/100000-----Data Time 0.003 (0.005)-----Step Time 2.975 (3.179)-----Loss 4.7112 (6.6372)\n",
      "Epoch 1/21-----Batch 35520/59476-----Step 2960/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.178)-----Loss 4.1937 (6.6238)\n",
      "Epoch 1/21-----Batch 35760/59476-----Step 2980/100000-----Data Time 0.003 (0.005)-----Step Time 3.010 (3.178)-----Loss 4.2151 (6.6105)\n",
      "Epoch 1/21-----Batch 36000/59476-----Step 3000/100000-----Data Time 0.003 (0.005)-----Step Time 3.170 (3.177)-----Loss 3.8432 (6.5975)\n",
      "Epoch 1/21-----Batch 36240/59476-----Step 3020/100000-----Data Time 0.004 (0.005)-----Step Time 3.091 (3.177)-----Loss 4.7487 (6.5849)\n",
      "Epoch 1/21-----Batch 36480/59476-----Step 3040/100000-----Data Time 0.003 (0.005)-----Step Time 3.179 (3.177)-----Loss 5.4063 (6.5717)\n",
      "Epoch 1/21-----Batch 36720/59476-----Step 3060/100000-----Data Time 0.003 (0.005)-----Step Time 3.116 (3.176)-----Loss 3.7041 (6.5583)\n",
      "Epoch 1/21-----Batch 36960/59476-----Step 3080/100000-----Data Time 0.004 (0.005)-----Step Time 3.134 (3.176)-----Loss 3.9622 (6.5453)\n",
      "Epoch 1/21-----Batch 37200/59476-----Step 3100/100000-----Data Time 0.003 (0.005)-----Step Time 3.149 (3.175)-----Loss 3.7991 (6.5320)\n",
      "Epoch 1/21-----Batch 37440/59476-----Step 3120/100000-----Data Time 0.003 (0.005)-----Step Time 3.091 (3.175)-----Loss 4.8134 (6.5194)\n",
      "Epoch 1/21-----Batch 37680/59476-----Step 3140/100000-----Data Time 0.003 (0.005)-----Step Time 3.174 (3.175)-----Loss 3.6196 (6.5069)\n",
      "Epoch 1/21-----Batch 37920/59476-----Step 3160/100000-----Data Time 0.003 (0.005)-----Step Time 3.067 (3.175)-----Loss 3.8979 (6.4939)\n",
      "Epoch 1/21-----Batch 38160/59476-----Step 3180/100000-----Data Time 0.003 (0.005)-----Step Time 3.271 (3.174)-----Loss 3.8132 (6.4817)\n",
      "Epoch 1/21-----Batch 38400/59476-----Step 3200/100000-----Data Time 0.009 (0.005)-----Step Time 3.056 (3.174)-----Loss 4.7477 (6.4687)\n",
      "Epoch 1/21-----Batch 38640/59476-----Step 3220/100000-----Data Time 0.004 (0.005)-----Step Time 3.074 (3.174)-----Loss 4.5081 (6.4565)\n",
      "Epoch 1/21-----Batch 38880/59476-----Step 3240/100000-----Data Time 0.003 (0.005)-----Step Time 3.076 (3.173)-----Loss 3.9431 (6.4441)\n",
      "Epoch 1/21-----Batch 39120/59476-----Step 3260/100000-----Data Time 0.005 (0.005)-----Step Time 3.062 (3.173)-----Loss 3.5450 (6.4315)\n",
      "Epoch 1/21-----Batch 39360/59476-----Step 3280/100000-----Data Time 0.003 (0.005)-----Step Time 3.026 (3.172)-----Loss 4.1907 (6.4193)\n",
      "Epoch 1/21-----Batch 39600/59476-----Step 3300/100000-----Data Time 0.005 (0.005)-----Step Time 3.085 (3.172)-----Loss 4.2161 (6.4073)\n",
      "Epoch 1/21-----Batch 39840/59476-----Step 3320/100000-----Data Time 0.003 (0.005)-----Step Time 3.058 (3.172)-----Loss 3.5234 (6.3953)\n",
      "Epoch 1/21-----Batch 40080/59476-----Step 3340/100000-----Data Time 0.003 (0.005)-----Step Time 3.113 (3.171)-----Loss 3.9888 (6.3834)\n",
      "Epoch 1/21-----Batch 40320/59476-----Step 3360/100000-----Data Time 0.004 (0.005)-----Step Time 3.089 (3.171)-----Loss 4.2092 (6.3713)\n",
      "Epoch 1/21-----Batch 40560/59476-----Step 3380/100000-----Data Time 0.003 (0.005)-----Step Time 3.263 (3.171)-----Loss 4.2001 (6.3588)\n",
      "Epoch 1/21-----Batch 40800/59476-----Step 3400/100000-----Data Time 0.004 (0.005)-----Step Time 3.157 (3.171)-----Loss 3.9226 (6.3472)\n",
      "Epoch 1/21-----Batch 41040/59476-----Step 3420/100000-----Data Time 0.004 (0.005)-----Step Time 3.069 (3.170)-----Loss 4.0513 (6.3359)\n",
      "Epoch 1/21-----Batch 41280/59476-----Step 3440/100000-----Data Time 0.004 (0.005)-----Step Time 3.109 (3.170)-----Loss 4.0264 (6.3240)\n",
      "Epoch 1/21-----Batch 41520/59476-----Step 3460/100000-----Data Time 0.004 (0.005)-----Step Time 3.229 (3.170)-----Loss 3.8746 (6.3123)\n",
      "Epoch 1/21-----Batch 41760/59476-----Step 3480/100000-----Data Time 0.003 (0.005)-----Step Time 3.058 (3.169)-----Loss 4.1199 (6.3011)\n",
      "Epoch 1/21-----Batch 42000/59476-----Step 3500/100000-----Data Time 0.003 (0.005)-----Step Time 3.085 (3.169)-----Loss 4.2868 (6.2899)\n",
      "Epoch 1/21-----Batch 42240/59476-----Step 3520/100000-----Data Time 0.003 (0.005)-----Step Time 3.113 (3.168)-----Loss 3.5916 (6.2786)\n",
      "Epoch 1/21-----Batch 42480/59476-----Step 3540/100000-----Data Time 0.006 (0.005)-----Step Time 3.046 (3.168)-----Loss 3.9637 (6.2676)\n",
      "Epoch 1/21-----Batch 42720/59476-----Step 3560/100000-----Data Time 0.003 (0.005)-----Step Time 3.178 (3.168)-----Loss 4.5624 (6.2564)\n",
      "Epoch 1/21-----Batch 42960/59476-----Step 3580/100000-----Data Time 0.005 (0.005)-----Step Time 3.181 (3.168)-----Loss 4.1155 (6.2451)\n",
      "Epoch 1/21-----Batch 43200/59476-----Step 3600/100000-----Data Time 0.003 (0.005)-----Step Time 3.103 (3.167)-----Loss 3.7614 (6.2343)\n",
      "Epoch 1/21-----Batch 43440/59476-----Step 3620/100000-----Data Time 0.004 (0.005)-----Step Time 3.105 (3.167)-----Loss 3.7739 (6.2232)\n",
      "Epoch 1/21-----Batch 43680/59476-----Step 3640/100000-----Data Time 0.003 (0.005)-----Step Time 3.341 (3.167)-----Loss 5.8778 (6.2123)\n",
      "Epoch 1/21-----Batch 43920/59476-----Step 3660/100000-----Data Time 0.003 (0.005)-----Step Time 3.107 (3.166)-----Loss 4.0273 (6.2014)\n",
      "Epoch 1/21-----Batch 44160/59476-----Step 3680/100000-----Data Time 0.003 (0.005)-----Step Time 3.114 (3.166)-----Loss 5.0497 (6.1908)\n",
      "Epoch 1/21-----Batch 44400/59476-----Step 3700/100000-----Data Time 0.003 (0.005)-----Step Time 3.141 (3.166)-----Loss 3.7094 (6.1801)\n",
      "Epoch 1/21-----Batch 44640/59476-----Step 3720/100000-----Data Time 0.003 (0.005)-----Step Time 3.024 (3.166)-----Loss 4.4572 (6.1692)\n",
      "Epoch 1/21-----Batch 44880/59476-----Step 3740/100000-----Data Time 0.003 (0.005)-----Step Time 3.109 (3.165)-----Loss 4.2130 (6.1586)\n",
      "Epoch 1/21-----Batch 45120/59476-----Step 3760/100000-----Data Time 0.003 (0.005)-----Step Time 3.152 (3.165)-----Loss 4.3007 (6.1485)\n",
      "Epoch 1/21-----Batch 45360/59476-----Step 3780/100000-----Data Time 0.003 (0.005)-----Step Time 3.122 (3.165)-----Loss 3.3945 (6.1380)\n",
      "Epoch 1/21-----Batch 45600/59476-----Step 3800/100000-----Data Time 0.003 (0.005)-----Step Time 3.051 (3.165)-----Loss 4.5164 (6.1282)\n",
      "Epoch 1/21-----Batch 45840/59476-----Step 3820/100000-----Data Time 0.003 (0.005)-----Step Time 3.183 (3.164)-----Loss 4.1259 (6.1181)\n",
      "Epoch 1/21-----Batch 46080/59476-----Step 3840/100000-----Data Time 0.002 (0.005)-----Step Time 2.916 (3.164)-----Loss 6.3922 (6.1075)\n",
      "Epoch 1/21-----Batch 46320/59476-----Step 3860/100000-----Data Time 0.003 (0.005)-----Step Time 3.156 (3.164)-----Loss 3.5257 (6.0978)\n",
      "Epoch 1/21-----Batch 46560/59476-----Step 3880/100000-----Data Time 0.003 (0.005)-----Step Time 3.222 (3.163)-----Loss 5.9875 (6.0877)\n",
      "Epoch 1/21-----Batch 46800/59476-----Step 3900/100000-----Data Time 0.003 (0.005)-----Step Time 3.152 (3.163)-----Loss 4.7065 (6.0779)\n",
      "Epoch 1/21-----Batch 47040/59476-----Step 3920/100000-----Data Time 0.004 (0.005)-----Step Time 3.059 (3.163)-----Loss 4.0901 (6.0677)\n",
      "Epoch 1/21-----Batch 47280/59476-----Step 3940/100000-----Data Time 0.003 (0.005)-----Step Time 3.164 (3.163)-----Loss 5.9541 (6.0582)\n",
      "Epoch 1/21-----Batch 47520/59476-----Step 3960/100000-----Data Time 0.003 (0.005)-----Step Time 3.099 (3.162)-----Loss 3.3423 (6.0484)\n",
      "Epoch 1/21-----Batch 47760/59476-----Step 3980/100000-----Data Time 0.003 (0.005)-----Step Time 3.116 (3.162)-----Loss 3.6719 (6.0388)\n",
      "Epoch 1/21-----Batch 48000/59476-----Step 4000/100000-----Data Time 0.003 (0.005)-----Step Time 3.268 (3.162)-----Loss 4.1376 (6.0292)\n",
      "Epoch 1/21-----Batch 48240/59476-----Step 4020/100000-----Data Time 0.003 (0.005)-----Step Time 3.128 (3.162)-----Loss 4.8644 (6.0195)\n",
      "Epoch 1/21-----Batch 48480/59476-----Step 4040/100000-----Data Time 0.004 (0.005)-----Step Time 3.053 (3.161)-----Loss 4.6547 (6.0103)\n",
      "Epoch 1/21-----Batch 48720/59476-----Step 4060/100000-----Data Time 0.003 (0.005)-----Step Time 3.037 (3.161)-----Loss 4.7127 (6.0008)\n",
      "Epoch 1/21-----Batch 48960/59476-----Step 4080/100000-----Data Time 0.003 (0.005)-----Step Time 3.140 (3.161)-----Loss 3.0795 (5.9915)\n",
      "Epoch 1/21-----Batch 49200/59476-----Step 4100/100000-----Data Time 0.003 (0.005)-----Step Time 3.121 (3.160)-----Loss 3.9896 (5.9821)\n",
      "Epoch 1/21-----Batch 49440/59476-----Step 4120/100000-----Data Time 0.004 (0.005)-----Step Time 3.043 (3.160)-----Loss 5.1465 (5.9729)\n",
      "Epoch 1/21-----Batch 49680/59476-----Step 4140/100000-----Data Time 0.003 (0.005)-----Step Time 3.145 (3.160)-----Loss 3.7612 (5.9635)\n",
      "Epoch 1/21-----Batch 49920/59476-----Step 4160/100000-----Data Time 0.005 (0.005)-----Step Time 3.115 (3.160)-----Loss 4.4825 (5.9545)\n",
      "Epoch 1/21-----Batch 50160/59476-----Step 4180/100000-----Data Time 0.003 (0.005)-----Step Time 3.101 (3.159)-----Loss 5.2427 (5.9456)\n",
      "Epoch 1/21-----Batch 50400/59476-----Step 4200/100000-----Data Time 0.002 (0.005)-----Step Time 3.080 (3.159)-----Loss 4.5329 (5.9365)\n",
      "Epoch 1/21-----Batch 50640/59476-----Step 4220/100000-----Data Time 0.004 (0.005)-----Step Time 3.067 (3.159)-----Loss 3.7128 (5.9272)\n",
      "Epoch 1/21-----Batch 50880/59476-----Step 4240/100000-----Data Time 0.003 (0.005)-----Step Time 3.040 (3.159)-----Loss 4.0297 (5.9184)\n",
      "Epoch 1/21-----Batch 51120/59476-----Step 4260/100000-----Data Time 0.004 (0.005)-----Step Time 2.995 (3.159)-----Loss 4.4645 (5.9096)\n",
      "Epoch 1/21-----Batch 51360/59476-----Step 4280/100000-----Data Time 0.009 (0.005)-----Step Time 3.225 (3.159)-----Loss 3.5322 (5.9004)\n",
      "Epoch 1/21-----Batch 51600/59476-----Step 4300/100000-----Data Time 0.002 (0.005)-----Step Time 3.100 (3.158)-----Loss 3.5287 (5.8918)\n",
      "Epoch 1/21-----Batch 51840/59476-----Step 4320/100000-----Data Time 0.004 (0.005)-----Step Time 3.065 (3.158)-----Loss 4.6742 (5.8832)\n",
      "Epoch 1/21-----Batch 52080/59476-----Step 4340/100000-----Data Time 0.003 (0.005)-----Step Time 3.069 (3.158)-----Loss 4.3942 (5.8742)\n",
      "Epoch 1/21-----Batch 52320/59476-----Step 4360/100000-----Data Time 0.004 (0.005)-----Step Time 3.031 (3.158)-----Loss 5.2514 (5.8658)\n",
      "Epoch 1/21-----Batch 52560/59476-----Step 4380/100000-----Data Time 0.004 (0.005)-----Step Time 3.084 (3.157)-----Loss 3.0289 (5.8573)\n",
      "Epoch 1/21-----Batch 52800/59476-----Step 4400/100000-----Data Time 0.004 (0.005)-----Step Time 3.128 (3.157)-----Loss 3.1339 (5.8490)\n",
      "Epoch 1/21-----Batch 53040/59476-----Step 4420/100000-----Data Time 0.002 (0.005)-----Step Time 3.094 (3.157)-----Loss 4.6845 (5.8405)\n",
      "Epoch 1/21-----Batch 53280/59476-----Step 4440/100000-----Data Time 0.003 (0.005)-----Step Time 3.154 (3.157)-----Loss 3.4253 (5.8320)\n",
      "Epoch 1/21-----Batch 53520/59476-----Step 4460/100000-----Data Time 0.003 (0.005)-----Step Time 3.197 (3.156)-----Loss 3.8544 (5.8239)\n",
      "Epoch 1/21-----Batch 53760/59476-----Step 4480/100000-----Data Time 0.003 (0.005)-----Step Time 3.066 (3.156)-----Loss 4.8927 (5.8158)\n",
      "Epoch 1/21-----Batch 54000/59476-----Step 4500/100000-----Data Time 0.004 (0.005)-----Step Time 3.043 (3.156)-----Loss 3.5596 (5.8076)\n",
      "Epoch 1/21-----Batch 54240/59476-----Step 4520/100000-----Data Time 0.004 (0.005)-----Step Time 3.151 (3.156)-----Loss 3.5058 (5.7994)\n",
      "Epoch 1/21-----Batch 54480/59476-----Step 4540/100000-----Data Time 0.004 (0.005)-----Step Time 3.096 (3.156)-----Loss 2.9597 (5.7914)\n",
      "Epoch 1/21-----Batch 54720/59476-----Step 4560/100000-----Data Time 0.004 (0.005)-----Step Time 3.078 (3.156)-----Loss 3.3175 (5.7834)\n",
      "Epoch 1/21-----Batch 54960/59476-----Step 4580/100000-----Data Time 0.003 (0.005)-----Step Time 3.064 (3.155)-----Loss 3.4930 (5.7756)\n",
      "Epoch 1/21-----Batch 55200/59476-----Step 4600/100000-----Data Time 0.003 (0.005)-----Step Time 3.164 (3.155)-----Loss 3.1094 (5.7673)\n",
      "Epoch 1/21-----Batch 55440/59476-----Step 4620/100000-----Data Time 0.003 (0.005)-----Step Time 3.049 (3.155)-----Loss 3.8448 (5.7594)\n",
      "Epoch 1/21-----Batch 55680/59476-----Step 4640/100000-----Data Time 0.003 (0.005)-----Step Time 3.072 (3.155)-----Loss 5.1152 (5.7514)\n",
      "Epoch 1/21-----Batch 55920/59476-----Step 4660/100000-----Data Time 0.003 (0.005)-----Step Time 3.224 (3.155)-----Loss 3.6646 (5.7434)\n",
      "Epoch 1/21-----Batch 56160/59476-----Step 4680/100000-----Data Time 0.004 (0.005)-----Step Time 3.060 (3.155)-----Loss 3.3457 (5.7353)\n",
      "Epoch 1/21-----Batch 56400/59476-----Step 4700/100000-----Data Time 0.003 (0.005)-----Step Time 3.090 (3.154)-----Loss 3.4939 (5.7282)\n",
      "Epoch 1/21-----Batch 56640/59476-----Step 4720/100000-----Data Time 0.005 (0.005)-----Step Time 3.191 (3.154)-----Loss 3.8400 (5.7202)\n",
      "Epoch 1/21-----Batch 56880/59476-----Step 4740/100000-----Data Time 0.004 (0.005)-----Step Time 3.173 (3.154)-----Loss 3.1623 (5.7126)\n",
      "Epoch 1/21-----Batch 57120/59476-----Step 4760/100000-----Data Time 0.004 (0.005)-----Step Time 3.054 (3.154)-----Loss 3.6781 (5.7048)\n",
      "Epoch 1/21-----Batch 57360/59476-----Step 4780/100000-----Data Time 0.003 (0.005)-----Step Time 3.062 (3.154)-----Loss 3.4868 (5.6974)\n",
      "Epoch 1/21-----Batch 57600/59476-----Step 4800/100000-----Data Time 0.003 (0.005)-----Step Time 3.086 (3.154)-----Loss 3.9651 (5.6899)\n",
      "Epoch 1/21-----Batch 57840/59476-----Step 4820/100000-----Data Time 0.003 (0.005)-----Step Time 3.050 (3.153)-----Loss 4.8006 (5.6824)\n",
      "Epoch 1/21-----Batch 58080/59476-----Step 4840/100000-----Data Time 0.004 (0.005)-----Step Time 3.029 (3.153)-----Loss 3.4472 (5.6749)\n",
      "Epoch 1/21-----Batch 58320/59476-----Step 4860/100000-----Data Time 0.007 (0.005)-----Step Time 3.019 (3.153)-----Loss 3.4800 (5.6676)\n",
      "Epoch 1/21-----Batch 58560/59476-----Step 4880/100000-----Data Time 0.003 (0.005)-----Step Time 3.130 (3.153)-----Loss 3.4549 (5.6604)\n",
      "Epoch 1/21-----Batch 58800/59476-----Step 4900/100000-----Data Time 0.003 (0.005)-----Step Time 3.005 (3.152)-----Loss 4.6015 (5.6533)\n",
      "Epoch 1/21-----Batch 59040/59476-----Step 4920/100000-----Data Time 0.003 (0.005)-----Step Time 3.029 (3.152)-----Loss 4.8722 (5.6459)\n",
      "Epoch 1/21-----Batch 59280/59476-----Step 4940/100000-----Data Time 0.003 (0.005)-----Step Time 3.184 (3.152)-----Loss 3.8836 (5.6390)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:37<00:00, 80.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss: 3.921\n",
      "\n",
      "\n",
      " Epoch #  1\n",
      "Epoch 2/21-----Batch 48/59476-----Step 4960/100000-----Data Time 0.003 (0.004)-----Step Time 2.964 (2.904)-----Loss 3.3859 (3.6551)\n",
      "Epoch 2/21-----Batch 288/59476-----Step 4980/100000-----Data Time 0.004 (0.005)-----Step Time 3.063 (3.038)-----Loss 3.6989 (3.8092)\n",
      "Epoch 2/21-----Batch 528/59476-----Step 5000/100000-----Data Time 0.005 (0.005)-----Step Time 3.110 (3.072)-----Loss 4.0231 (3.8118)\n",
      "Epoch 2/21-----Batch 768/59476-----Step 5020/100000-----Data Time 0.003 (0.005)-----Step Time 2.962 (3.075)-----Loss 3.9093 (3.8073)\n",
      "Epoch 2/21-----Batch 1008/59476-----Step 5040/100000-----Data Time 0.003 (0.005)-----Step Time 3.082 (3.078)-----Loss 3.7855 (3.8277)\n",
      "Epoch 2/21-----Batch 1248/59476-----Step 5060/100000-----Data Time 0.008 (0.005)-----Step Time 3.107 (3.082)-----Loss 3.5333 (3.8450)\n",
      "Epoch 2/21-----Batch 1488/59476-----Step 5080/100000-----Data Time 0.004 (0.005)-----Step Time 3.019 (3.084)-----Loss 3.2124 (3.8376)\n",
      "Epoch 2/21-----Batch 1728/59476-----Step 5100/100000-----Data Time 0.003 (0.005)-----Step Time 3.182 (3.089)-----Loss 3.8521 (3.8298)\n",
      "Epoch 2/21-----Batch 1968/59476-----Step 5120/100000-----Data Time 0.004 (0.005)-----Step Time 2.998 (3.089)-----Loss 3.1499 (3.8287)\n",
      "Epoch 2/21-----Batch 2208/59476-----Step 5140/100000-----Data Time 0.003 (0.005)-----Step Time 3.138 (3.090)-----Loss 3.7840 (3.8378)\n",
      "Epoch 2/21-----Batch 2448/59476-----Step 5160/100000-----Data Time 0.004 (0.005)-----Step Time 3.190 (3.092)-----Loss 4.3665 (3.8396)\n",
      "Epoch 2/21-----Batch 2688/59476-----Step 5180/100000-----Data Time 0.003 (0.005)-----Step Time 3.074 (3.094)-----Loss 4.4861 (3.8357)\n",
      "Epoch 2/21-----Batch 2928/59476-----Step 5200/100000-----Data Time 0.004 (0.005)-----Step Time 3.132 (3.093)-----Loss 3.2677 (3.8292)\n",
      "Epoch 2/21-----Batch 3168/59476-----Step 5220/100000-----Data Time 0.003 (0.005)-----Step Time 3.079 (3.094)-----Loss 4.1083 (3.8252)\n",
      "Epoch 2/21-----Batch 3408/59476-----Step 5240/100000-----Data Time 0.003 (0.005)-----Step Time 3.112 (3.093)-----Loss 4.1189 (3.8209)\n",
      "Epoch 2/21-----Batch 3648/59476-----Step 5260/100000-----Data Time 0.003 (0.005)-----Step Time 3.110 (3.094)-----Loss 3.6543 (3.8217)\n",
      "Epoch 2/21-----Batch 3888/59476-----Step 5280/100000-----Data Time 0.005 (0.005)-----Step Time 3.056 (3.095)-----Loss 3.8793 (3.8141)\n",
      "Epoch 2/21-----Batch 4128/59476-----Step 5300/100000-----Data Time 0.004 (0.005)-----Step Time 3.137 (3.096)-----Loss 3.6544 (3.8106)\n",
      "Epoch 2/21-----Batch 4368/59476-----Step 5320/100000-----Data Time 0.004 (0.005)-----Step Time 3.125 (3.097)-----Loss 3.7934 (3.8089)\n",
      "Epoch 2/21-----Batch 4608/59476-----Step 5340/100000-----Data Time 0.003 (0.005)-----Step Time 3.158 (3.098)-----Loss 4.8972 (3.8109)\n",
      "Epoch 2/21-----Batch 4848/59476-----Step 5360/100000-----Data Time 0.004 (0.005)-----Step Time 3.106 (3.098)-----Loss 3.6485 (3.8125)\n",
      "Epoch 2/21-----Batch 5088/59476-----Step 5380/100000-----Data Time 0.004 (0.005)-----Step Time 3.279 (3.099)-----Loss 3.0478 (3.8155)\n",
      "Epoch 2/21-----Batch 5328/59476-----Step 5400/100000-----Data Time 0.002 (0.005)-----Step Time 3.060 (3.099)-----Loss 3.5742 (3.8164)\n",
      "Epoch 2/21-----Batch 5568/59476-----Step 5420/100000-----Data Time 0.004 (0.005)-----Step Time 3.031 (3.099)-----Loss 2.9637 (3.8145)\n",
      "Epoch 2/21-----Batch 5808/59476-----Step 5440/100000-----Data Time 0.003 (0.005)-----Step Time 3.050 (3.100)-----Loss 3.4535 (3.8129)\n",
      "Epoch 2/21-----Batch 6048/59476-----Step 5460/100000-----Data Time 0.004 (0.005)-----Step Time 3.059 (3.100)-----Loss 4.4504 (3.8110)\n",
      "Epoch 2/21-----Batch 6288/59476-----Step 5480/100000-----Data Time 0.003 (0.005)-----Step Time 3.127 (3.101)-----Loss 5.0558 (3.8110)\n",
      "Epoch 2/21-----Batch 6528/59476-----Step 5500/100000-----Data Time 0.003 (0.005)-----Step Time 3.123 (3.102)-----Loss 3.5592 (3.8073)\n",
      "Epoch 2/21-----Batch 6768/59476-----Step 5520/100000-----Data Time 0.003 (0.005)-----Step Time 3.104 (3.103)-----Loss 3.9630 (3.8065)\n",
      "Epoch 2/21-----Batch 7008/59476-----Step 5540/100000-----Data Time 0.003 (0.005)-----Step Time 3.246 (3.103)-----Loss 4.2881 (3.8047)\n",
      "Epoch 2/21-----Batch 7248/59476-----Step 5560/100000-----Data Time 0.003 (0.005)-----Step Time 3.045 (3.104)-----Loss 3.7574 (3.8068)\n",
      "Epoch 2/21-----Batch 7488/59476-----Step 5580/100000-----Data Time 0.003 (0.005)-----Step Time 3.110 (3.104)-----Loss 3.7907 (3.8051)\n",
      "Epoch 2/21-----Batch 7728/59476-----Step 5600/100000-----Data Time 0.003 (0.005)-----Step Time 3.081 (3.104)-----Loss 4.1894 (3.8051)\n",
      "Epoch 2/21-----Batch 7968/59476-----Step 5620/100000-----Data Time 0.003 (0.005)-----Step Time 3.111 (3.104)-----Loss 4.5745 (3.8050)\n",
      "Epoch 2/21-----Batch 8208/59476-----Step 5640/100000-----Data Time 0.003 (0.005)-----Step Time 3.181 (3.104)-----Loss 3.5631 (3.8041)\n",
      "Epoch 2/21-----Batch 8448/59476-----Step 5660/100000-----Data Time 0.003 (0.005)-----Step Time 3.074 (3.104)-----Loss 4.6040 (3.8013)\n",
      "Epoch 2/21-----Batch 8688/59476-----Step 5680/100000-----Data Time 0.004 (0.005)-----Step Time 2.991 (3.105)-----Loss 3.1691 (3.7999)\n",
      "Epoch 2/21-----Batch 8928/59476-----Step 5700/100000-----Data Time 0.004 (0.005)-----Step Time 3.202 (3.105)-----Loss 4.1866 (3.8006)\n",
      "Epoch 2/21-----Batch 9168/59476-----Step 5720/100000-----Data Time 0.003 (0.005)-----Step Time 3.048 (3.106)-----Loss 4.9881 (3.7989)\n",
      "Epoch 2/21-----Batch 9408/59476-----Step 5740/100000-----Data Time 0.003 (0.005)-----Step Time 3.140 (3.106)-----Loss 3.2273 (3.7989)\n",
      "Epoch 2/21-----Batch 9648/59476-----Step 5760/100000-----Data Time 0.003 (0.005)-----Step Time 3.028 (3.106)-----Loss 3.5441 (3.7973)\n",
      "Epoch 2/21-----Batch 9888/59476-----Step 5780/100000-----Data Time 0.003 (0.005)-----Step Time 3.266 (3.106)-----Loss 3.5327 (3.7969)\n",
      "Epoch 2/21-----Batch 10128/59476-----Step 5800/100000-----Data Time 0.003 (0.005)-----Step Time 3.227 (3.106)-----Loss 2.9816 (3.7962)\n",
      "Epoch 2/21-----Batch 10368/59476-----Step 5820/100000-----Data Time 0.004 (0.005)-----Step Time 3.088 (3.107)-----Loss 4.2597 (3.7946)\n",
      "Epoch 2/21-----Batch 10608/59476-----Step 5840/100000-----Data Time 0.003 (0.005)-----Step Time 2.981 (3.107)-----Loss 4.0386 (3.7938)\n",
      "Epoch 2/21-----Batch 10848/59476-----Step 5860/100000-----Data Time 0.005 (0.005)-----Step Time 3.003 (3.107)-----Loss 3.3459 (3.7941)\n",
      "Epoch 2/21-----Batch 11088/59476-----Step 5880/100000-----Data Time 0.004 (0.005)-----Step Time 3.106 (3.107)-----Loss 3.9028 (3.7935)\n",
      "Epoch 2/21-----Batch 11328/59476-----Step 5900/100000-----Data Time 0.002 (0.005)-----Step Time 3.390 (3.107)-----Loss 4.5118 (3.7906)\n",
      "Epoch 2/21-----Batch 11568/59476-----Step 5920/100000-----Data Time 0.003 (0.005)-----Step Time 3.077 (3.108)-----Loss 5.5816 (3.7895)\n",
      "Epoch 2/21-----Batch 11808/59476-----Step 5940/100000-----Data Time 0.005 (0.005)-----Step Time 3.139 (3.108)-----Loss 2.4800 (3.7877)\n",
      "Epoch 2/21-----Batch 12048/59476-----Step 5960/100000-----Data Time 0.005 (0.005)-----Step Time 3.170 (3.108)-----Loss 4.2573 (3.7861)\n",
      "Epoch 2/21-----Batch 12288/59476-----Step 5980/100000-----Data Time 0.004 (0.005)-----Step Time 3.056 (3.108)-----Loss 4.4244 (3.7846)\n",
      "Epoch 2/21-----Batch 12528/59476-----Step 6000/100000-----Data Time 0.003 (0.005)-----Step Time 3.102 (3.108)-----Loss 3.7074 (3.7826)\n",
      "Epoch 2/21-----Batch 12768/59476-----Step 6020/100000-----Data Time 0.003 (0.005)-----Step Time 3.099 (3.109)-----Loss 3.4709 (3.7809)\n",
      "Epoch 2/21-----Batch 13008/59476-----Step 6040/100000-----Data Time 0.003 (0.005)-----Step Time 3.099 (3.109)-----Loss 3.0672 (3.7812)\n",
      "Epoch 2/21-----Batch 13248/59476-----Step 6060/100000-----Data Time 0.003 (0.005)-----Step Time 3.429 (3.109)-----Loss 4.8416 (3.7799)\n",
      "Epoch 2/21-----Batch 13488/59476-----Step 6080/100000-----Data Time 0.005 (0.005)-----Step Time 3.093 (3.109)-----Loss 4.6926 (3.7798)\n",
      "Epoch 2/21-----Batch 13728/59476-----Step 6100/100000-----Data Time 0.003 (0.005)-----Step Time 3.120 (3.109)-----Loss 3.5865 (3.7785)\n",
      "Epoch 2/21-----Batch 13968/59476-----Step 6120/100000-----Data Time 0.003 (0.005)-----Step Time 3.100 (3.109)-----Loss 4.3277 (3.7773)\n",
      "Epoch 2/21-----Batch 14208/59476-----Step 6140/100000-----Data Time 0.004 (0.005)-----Step Time 3.044 (3.109)-----Loss 4.0012 (3.7762)\n",
      "Epoch 2/21-----Batch 14448/59476-----Step 6160/100000-----Data Time 0.003 (0.005)-----Step Time 3.111 (3.109)-----Loss 3.4712 (3.7747)\n",
      "Epoch 2/21-----Batch 14688/59476-----Step 6180/100000-----Data Time 0.004 (0.005)-----Step Time 3.084 (3.109)-----Loss 4.3478 (3.7732)\n",
      "Epoch 2/21-----Batch 14928/59476-----Step 6200/100000-----Data Time 0.003 (0.005)-----Step Time 3.203 (3.109)-----Loss 3.6870 (3.7712)\n",
      "Epoch 2/21-----Batch 15168/59476-----Step 6220/100000-----Data Time 0.004 (0.005)-----Step Time 3.093 (3.109)-----Loss 3.7526 (3.7711)\n",
      "Epoch 2/21-----Batch 15408/59476-----Step 6240/100000-----Data Time 0.003 (0.005)-----Step Time 3.167 (3.109)-----Loss 4.4396 (3.7700)\n",
      "Epoch 2/21-----Batch 15648/59476-----Step 6260/100000-----Data Time 0.003 (0.005)-----Step Time 3.154 (3.109)-----Loss 4.2579 (3.7679)\n",
      "Epoch 2/21-----Batch 15888/59476-----Step 6280/100000-----Data Time 0.003 (0.005)-----Step Time 3.074 (3.110)-----Loss 2.9612 (3.7668)\n",
      "Epoch 2/21-----Batch 16128/59476-----Step 6300/100000-----Data Time 0.005 (0.005)-----Step Time 3.119 (3.110)-----Loss 3.2091 (3.7655)\n",
      "Epoch 2/21-----Batch 16368/59476-----Step 6320/100000-----Data Time 0.004 (0.005)-----Step Time 3.128 (3.110)-----Loss 3.7242 (3.7649)\n",
      "Epoch 2/21-----Batch 16608/59476-----Step 6340/100000-----Data Time 0.003 (0.005)-----Step Time 3.083 (3.110)-----Loss 4.5490 (3.7645)\n",
      "Epoch 2/21-----Batch 16848/59476-----Step 6360/100000-----Data Time 0.004 (0.005)-----Step Time 3.074 (3.110)-----Loss 3.2262 (3.7643)\n",
      "Epoch 2/21-----Batch 17088/59476-----Step 6380/100000-----Data Time 0.003 (0.005)-----Step Time 3.420 (3.110)-----Loss 4.5949 (3.7629)\n",
      "Epoch 2/21-----Batch 17328/59476-----Step 6400/100000-----Data Time 0.003 (0.005)-----Step Time 3.056 (3.110)-----Loss 3.6109 (3.7617)\n",
      "Epoch 2/21-----Batch 17568/59476-----Step 6420/100000-----Data Time 0.003 (0.005)-----Step Time 3.019 (3.110)-----Loss 3.0377 (3.7609)\n",
      "Epoch 2/21-----Batch 17808/59476-----Step 6440/100000-----Data Time 0.003 (0.005)-----Step Time 3.125 (3.110)-----Loss 4.2053 (3.7611)\n",
      "Epoch 2/21-----Batch 18048/59476-----Step 6460/100000-----Data Time 0.003 (0.005)-----Step Time 3.108 (3.110)-----Loss 3.8807 (3.7597)\n",
      "Epoch 2/21-----Batch 18288/59476-----Step 6480/100000-----Data Time 0.003 (0.005)-----Step Time 3.090 (3.110)-----Loss 3.5306 (3.7582)\n",
      "Epoch 2/21-----Batch 18528/59476-----Step 6500/100000-----Data Time 0.003 (0.005)-----Step Time 3.144 (3.110)-----Loss 3.4620 (3.7574)\n",
      "Epoch 2/21-----Batch 18768/59476-----Step 6520/100000-----Data Time 0.003 (0.005)-----Step Time 3.246 (3.110)-----Loss 3.7052 (3.7561)\n",
      "Epoch 2/21-----Batch 19008/59476-----Step 6540/100000-----Data Time 0.005 (0.005)-----Step Time 3.059 (3.111)-----Loss 4.4068 (3.7564)\n",
      "Epoch 2/21-----Batch 19248/59476-----Step 6560/100000-----Data Time 0.004 (0.005)-----Step Time 3.094 (3.111)-----Loss 3.6062 (3.7560)\n",
      "Epoch 2/21-----Batch 19488/59476-----Step 6580/100000-----Data Time 0.004 (0.005)-----Step Time 3.164 (3.111)-----Loss 3.4406 (3.7549)\n",
      "Epoch 2/21-----Batch 19728/59476-----Step 6600/100000-----Data Time 0.003 (0.005)-----Step Time 3.058 (3.111)-----Loss 3.0237 (3.7543)\n",
      "Epoch 2/21-----Batch 19968/59476-----Step 6620/100000-----Data Time 0.003 (0.005)-----Step Time 3.154 (3.111)-----Loss 3.4896 (3.7538)\n",
      "Epoch 2/21-----Batch 20208/59476-----Step 6640/100000-----Data Time 0.003 (0.005)-----Step Time 3.127 (3.111)-----Loss 3.2552 (3.7534)\n",
      "Epoch 2/21-----Batch 20448/59476-----Step 6660/100000-----Data Time 0.005 (0.005)-----Step Time 3.061 (3.111)-----Loss 3.7871 (3.7524)\n",
      "Epoch 2/21-----Batch 20688/59476-----Step 6680/100000-----Data Time 0.003 (0.005)-----Step Time 3.116 (3.111)-----Loss 3.7599 (3.7507)\n",
      "Epoch 2/21-----Batch 20928/59476-----Step 6700/100000-----Data Time 0.004 (0.005)-----Step Time 3.109 (3.111)-----Loss 4.5121 (3.7494)\n",
      "Epoch 2/21-----Batch 21168/59476-----Step 6720/100000-----Data Time 0.004 (0.005)-----Step Time 3.168 (3.111)-----Loss 2.8436 (3.7482)\n",
      "Epoch 2/21-----Batch 21408/59476-----Step 6740/100000-----Data Time 0.003 (0.005)-----Step Time 3.056 (3.111)-----Loss 3.1789 (3.7474)\n",
      "Epoch 2/21-----Batch 21648/59476-----Step 6760/100000-----Data Time 0.004 (0.005)-----Step Time 3.121 (3.111)-----Loss 4.1963 (3.7464)\n",
      "Epoch 2/21-----Batch 21888/59476-----Step 6780/100000-----Data Time 0.006 (0.005)-----Step Time 3.057 (3.111)-----Loss 3.2669 (3.7462)\n",
      "Epoch 2/21-----Batch 22128/59476-----Step 6800/100000-----Data Time 0.003 (0.005)-----Step Time 3.039 (3.111)-----Loss 3.7450 (3.7449)\n",
      "Epoch 2/21-----Batch 22368/59476-----Step 6820/100000-----Data Time 0.003 (0.005)-----Step Time 3.049 (3.111)-----Loss 2.9548 (3.7435)\n",
      "Epoch 2/21-----Batch 22608/59476-----Step 6840/100000-----Data Time 0.003 (0.005)-----Step Time 3.160 (3.111)-----Loss 4.4727 (3.7429)\n",
      "Epoch 2/21-----Batch 22848/59476-----Step 6860/100000-----Data Time 0.004 (0.005)-----Step Time 3.053 (3.111)-----Loss 3.3954 (3.7421)\n",
      "Epoch 2/21-----Batch 23088/59476-----Step 6880/100000-----Data Time 0.003 (0.005)-----Step Time 3.038 (3.112)-----Loss 2.7287 (3.7413)\n",
      "Epoch 2/21-----Batch 23328/59476-----Step 6900/100000-----Data Time 0.003 (0.005)-----Step Time 3.089 (3.112)-----Loss 4.1352 (3.7406)\n",
      "Epoch 2/21-----Batch 23568/59476-----Step 6920/100000-----Data Time 0.003 (0.005)-----Step Time 3.067 (3.112)-----Loss 2.8412 (3.7397)\n",
      "Epoch 2/21-----Batch 23808/59476-----Step 6940/100000-----Data Time 0.003 (0.005)-----Step Time 3.090 (3.111)-----Loss 2.9800 (3.7387)\n",
      "Epoch 2/21-----Batch 24048/59476-----Step 6960/100000-----Data Time 0.011 (0.005)-----Step Time 3.100 (3.112)-----Loss 3.1316 (3.7378)\n",
      "Epoch 2/21-----Batch 24288/59476-----Step 6980/100000-----Data Time 0.004 (0.005)-----Step Time 3.051 (3.112)-----Loss 3.4227 (3.7368)\n",
      "Epoch 2/21-----Batch 24528/59476-----Step 7000/100000-----Data Time 0.003 (0.005)-----Step Time 3.112 (3.112)-----Loss 3.5590 (3.7361)\n",
      "Epoch 2/21-----Batch 24768/59476-----Step 7020/100000-----Data Time 0.004 (0.005)-----Step Time 3.046 (3.112)-----Loss 3.5957 (3.7361)\n",
      "Epoch 2/21-----Batch 25008/59476-----Step 7040/100000-----Data Time 0.003 (0.005)-----Step Time 3.068 (3.112)-----Loss 3.4442 (3.7357)\n",
      "Epoch 2/21-----Batch 25248/59476-----Step 7060/100000-----Data Time 0.003 (0.005)-----Step Time 3.138 (3.112)-----Loss 3.8082 (3.7350)\n",
      "Epoch 2/21-----Batch 25488/59476-----Step 7080/100000-----Data Time 0.003 (0.005)-----Step Time 3.151 (3.112)-----Loss 3.4860 (3.7342)\n",
      "Epoch 2/21-----Batch 25728/59476-----Step 7100/100000-----Data Time 0.003 (0.005)-----Step Time 3.081 (3.112)-----Loss 3.2320 (3.7336)\n",
      "Epoch 2/21-----Batch 25968/59476-----Step 7120/100000-----Data Time 0.006 (0.005)-----Step Time 3.076 (3.112)-----Loss 3.9144 (3.7326)\n",
      "Epoch 2/21-----Batch 26208/59476-----Step 7140/100000-----Data Time 0.003 (0.005)-----Step Time 3.034 (3.112)-----Loss 4.5327 (3.7318)\n",
      "Epoch 2/21-----Batch 26448/59476-----Step 7160/100000-----Data Time 0.003 (0.005)-----Step Time 3.120 (3.112)-----Loss 3.4673 (3.7305)\n",
      "Epoch 2/21-----Batch 26688/59476-----Step 7180/100000-----Data Time 0.005 (0.005)-----Step Time 3.399 (3.112)-----Loss 3.3678 (3.7299)\n",
      "Epoch 2/21-----Batch 26928/59476-----Step 7200/100000-----Data Time 0.004 (0.005)-----Step Time 3.119 (3.112)-----Loss 4.2128 (3.7291)\n",
      "Epoch 2/21-----Batch 27168/59476-----Step 7220/100000-----Data Time 0.003 (0.005)-----Step Time 3.110 (3.112)-----Loss 3.9392 (3.7288)\n",
      "Epoch 2/21-----Batch 27408/59476-----Step 7240/100000-----Data Time 0.007 (0.005)-----Step Time 3.181 (3.113)-----Loss 3.3390 (3.7283)\n",
      "Epoch 2/21-----Batch 27648/59476-----Step 7260/100000-----Data Time 0.003 (0.005)-----Step Time 3.120 (3.113)-----Loss 3.7305 (3.7278)\n",
      "Epoch 2/21-----Batch 27888/59476-----Step 7280/100000-----Data Time 0.003 (0.005)-----Step Time 3.128 (3.113)-----Loss 3.2951 (3.7267)\n",
      "Epoch 2/21-----Batch 28128/59476-----Step 7300/100000-----Data Time 0.005 (0.005)-----Step Time 3.157 (3.113)-----Loss 2.8497 (3.7256)\n",
      "Epoch 2/21-----Batch 28368/59476-----Step 7320/100000-----Data Time 0.004 (0.005)-----Step Time 3.093 (3.113)-----Loss 3.4737 (3.7248)\n",
      "Epoch 2/21-----Batch 28608/59476-----Step 7340/100000-----Data Time 0.003 (0.005)-----Step Time 3.259 (3.114)-----Loss 4.2163 (3.7244)\n",
      "Epoch 2/21-----Batch 28848/59476-----Step 7360/100000-----Data Time 0.003 (0.005)-----Step Time 3.128 (3.114)-----Loss 4.0095 (3.7233)\n",
      "Epoch 2/21-----Batch 29088/59476-----Step 7380/100000-----Data Time 0.004 (0.005)-----Step Time 3.065 (3.113)-----Loss 2.7912 (3.7229)\n",
      "Epoch 2/21-----Batch 29328/59476-----Step 7400/100000-----Data Time 0.003 (0.005)-----Step Time 3.156 (3.113)-----Loss 2.8743 (3.7226)\n",
      "Epoch 2/21-----Batch 29568/59476-----Step 7420/100000-----Data Time 0.002 (0.005)-----Step Time 3.048 (3.113)-----Loss 3.4300 (3.7216)\n",
      "Epoch 2/21-----Batch 29808/59476-----Step 7440/100000-----Data Time 0.003 (0.005)-----Step Time 3.201 (3.114)-----Loss 3.7118 (3.7208)\n",
      "Epoch 2/21-----Batch 30048/59476-----Step 7460/100000-----Data Time 0.003 (0.005)-----Step Time 3.153 (3.114)-----Loss 3.3952 (3.7205)\n",
      "Epoch 2/21-----Batch 30288/59476-----Step 7480/100000-----Data Time 0.003 (0.005)-----Step Time 3.114 (3.113)-----Loss 4.1611 (3.7201)\n",
      "Epoch 2/21-----Batch 30528/59476-----Step 7500/100000-----Data Time 0.004 (0.005)-----Step Time 3.082 (3.114)-----Loss 4.4375 (3.7202)\n",
      "Epoch 2/21-----Batch 30768/59476-----Step 7520/100000-----Data Time 0.004 (0.005)-----Step Time 3.175 (3.113)-----Loss 3.8457 (3.7196)\n",
      "Epoch 2/21-----Batch 31008/59476-----Step 7540/100000-----Data Time 0.003 (0.005)-----Step Time 3.139 (3.113)-----Loss 3.3663 (3.7188)\n",
      "Epoch 2/21-----Batch 31248/59476-----Step 7560/100000-----Data Time 0.005 (0.005)-----Step Time 3.119 (3.113)-----Loss 3.2913 (3.7179)\n",
      "Epoch 2/21-----Batch 31488/59476-----Step 7580/100000-----Data Time 0.005 (0.005)-----Step Time 3.051 (3.113)-----Loss 4.9191 (3.7174)\n",
      "Epoch 2/21-----Batch 31728/59476-----Step 7600/100000-----Data Time 0.003 (0.005)-----Step Time 3.091 (3.113)-----Loss 2.9505 (3.7165)\n",
      "Epoch 2/21-----Batch 31968/59476-----Step 7620/100000-----Data Time 0.004 (0.005)-----Step Time 3.191 (3.113)-----Loss 3.8121 (3.7163)\n",
      "Epoch 2/21-----Batch 32208/59476-----Step 7640/100000-----Data Time 0.004 (0.005)-----Step Time 3.096 (3.113)-----Loss 4.3347 (3.7159)\n",
      "Epoch 2/21-----Batch 32448/59476-----Step 7660/100000-----Data Time 0.003 (0.005)-----Step Time 3.086 (3.113)-----Loss 3.6048 (3.7155)\n",
      "Epoch 2/21-----Batch 32688/59476-----Step 7680/100000-----Data Time 0.004 (0.005)-----Step Time 3.101 (3.113)-----Loss 3.6444 (3.7152)\n",
      "Epoch 2/21-----Batch 32928/59476-----Step 7700/100000-----Data Time 0.004 (0.005)-----Step Time 3.123 (3.113)-----Loss 4.1394 (3.7152)\n",
      "Epoch 2/21-----Batch 33168/59476-----Step 7720/100000-----Data Time 0.003 (0.005)-----Step Time 3.099 (3.113)-----Loss 3.3400 (3.7147)\n",
      "Epoch 2/21-----Batch 33408/59476-----Step 7740/100000-----Data Time 0.003 (0.005)-----Step Time 3.225 (3.113)-----Loss 3.7638 (3.7141)\n",
      "Epoch 2/21-----Batch 33648/59476-----Step 7760/100000-----Data Time 0.003 (0.005)-----Step Time 3.080 (3.113)-----Loss 3.3982 (3.7135)\n",
      "Epoch 2/21-----Batch 33888/59476-----Step 7780/100000-----Data Time 0.003 (0.005)-----Step Time 3.134 (3.113)-----Loss 4.5610 (3.7128)\n",
      "Epoch 2/21-----Batch 34128/59476-----Step 7800/100000-----Data Time 0.004 (0.005)-----Step Time 3.121 (3.113)-----Loss 4.0532 (3.7119)\n",
      "Epoch 2/21-----Batch 34368/59476-----Step 7820/100000-----Data Time 0.006 (0.005)-----Step Time 3.057 (3.113)-----Loss 2.4629 (3.7109)\n",
      "Epoch 2/21-----Batch 34608/59476-----Step 7840/100000-----Data Time 0.004 (0.005)-----Step Time 3.146 (3.113)-----Loss 3.5280 (3.7108)\n",
      "Epoch 2/21-----Batch 34848/59476-----Step 7860/100000-----Data Time 0.004 (0.005)-----Step Time 3.092 (3.113)-----Loss 4.1046 (3.7106)\n",
      "Epoch 2/21-----Batch 35088/59476-----Step 7880/100000-----Data Time 0.003 (0.005)-----Step Time 3.091 (3.113)-----Loss 4.3065 (3.7099)\n",
      "Epoch 2/21-----Batch 35328/59476-----Step 7900/100000-----Data Time 0.003 (0.005)-----Step Time 3.175 (3.113)-----Loss 3.3850 (3.7089)\n",
      "Epoch 2/21-----Batch 35568/59476-----Step 7920/100000-----Data Time 0.003 (0.005)-----Step Time 3.063 (3.113)-----Loss 3.0473 (3.7079)\n",
      "Epoch 2/21-----Batch 35808/59476-----Step 7940/100000-----Data Time 0.004 (0.005)-----Step Time 3.136 (3.113)-----Loss 2.9125 (3.7072)\n",
      "Epoch 2/21-----Batch 36048/59476-----Step 7960/100000-----Data Time 0.003 (0.005)-----Step Time 3.096 (3.113)-----Loss 3.7348 (3.7062)\n",
      "Epoch 2/21-----Batch 36288/59476-----Step 7980/100000-----Data Time 0.003 (0.005)-----Step Time 3.124 (3.113)-----Loss 3.2045 (3.7056)\n",
      "Epoch 2/21-----Batch 36528/59476-----Step 8000/100000-----Data Time 0.003 (0.005)-----Step Time 3.081 (3.113)-----Loss 4.2425 (3.7050)\n",
      "Epoch 2/21-----Batch 36768/59476-----Step 8020/100000-----Data Time 0.004 (0.005)-----Step Time 3.099 (3.113)-----Loss 2.6337 (3.7048)\n",
      "Epoch 2/21-----Batch 37008/59476-----Step 8040/100000-----Data Time 0.003 (0.005)-----Step Time 3.211 (3.113)-----Loss 3.9755 (3.7040)\n",
      "Epoch 2/21-----Batch 37248/59476-----Step 8060/100000-----Data Time 0.004 (0.005)-----Step Time 3.165 (3.114)-----Loss 3.4465 (3.7035)\n",
      "Epoch 2/21-----Batch 37488/59476-----Step 8080/100000-----Data Time 0.003 (0.005)-----Step Time 3.161 (3.113)-----Loss 2.8542 (3.7032)\n",
      "Epoch 2/21-----Batch 37728/59476-----Step 8100/100000-----Data Time 0.004 (0.005)-----Step Time 3.227 (3.113)-----Loss 4.2428 (3.7027)\n",
      "Epoch 2/21-----Batch 37968/59476-----Step 8120/100000-----Data Time 0.004 (0.005)-----Step Time 3.149 (3.113)-----Loss 3.2332 (3.7023)\n",
      "Epoch 2/21-----Batch 38208/59476-----Step 8140/100000-----Data Time 0.003 (0.005)-----Step Time 3.082 (3.114)-----Loss 3.6623 (3.7017)\n",
      "Epoch 2/21-----Batch 38448/59476-----Step 8160/100000-----Data Time 0.005 (0.005)-----Step Time 3.126 (3.113)-----Loss 3.8987 (3.7011)\n",
      "Epoch 2/21-----Batch 38688/59476-----Step 8180/100000-----Data Time 0.003 (0.005)-----Step Time 3.153 (3.113)-----Loss 3.6794 (3.6999)\n",
      "Epoch 2/21-----Batch 38928/59476-----Step 8200/100000-----Data Time 0.004 (0.005)-----Step Time 3.069 (3.113)-----Loss 3.5727 (3.6994)\n",
      "Epoch 2/21-----Batch 39168/59476-----Step 8220/100000-----Data Time 0.003 (0.005)-----Step Time 3.093 (3.113)-----Loss 3.1060 (3.6985)\n",
      "Epoch 2/21-----Batch 39408/59476-----Step 8240/100000-----Data Time 0.004 (0.005)-----Step Time 3.140 (3.113)-----Loss 3.1828 (3.6979)\n",
      "Epoch 2/21-----Batch 39648/59476-----Step 8260/100000-----Data Time 0.003 (0.005)-----Step Time 3.098 (3.113)-----Loss 3.0554 (3.6975)\n",
      "Epoch 2/21-----Batch 39888/59476-----Step 8280/100000-----Data Time 0.003 (0.005)-----Step Time 3.088 (3.113)-----Loss 4.0455 (3.6965)\n",
      "Epoch 2/21-----Batch 40128/59476-----Step 8300/100000-----Data Time 0.003 (0.005)-----Step Time 3.229 (3.113)-----Loss 3.3165 (3.6959)\n",
      "Epoch 2/21-----Batch 40368/59476-----Step 8320/100000-----Data Time 0.003 (0.005)-----Step Time 3.092 (3.113)-----Loss 4.2461 (3.6956)\n",
      "Epoch 2/21-----Batch 40608/59476-----Step 8340/100000-----Data Time 0.003 (0.005)-----Step Time 3.086 (3.113)-----Loss 3.4169 (3.6952)\n",
      "Epoch 2/21-----Batch 40848/59476-----Step 8360/100000-----Data Time 0.003 (0.005)-----Step Time 3.141 (3.113)-----Loss 3.5462 (3.6946)\n",
      "Epoch 2/21-----Batch 41088/59476-----Step 8380/100000-----Data Time 0.004 (0.005)-----Step Time 3.076 (3.113)-----Loss 3.0685 (3.6940)\n",
      "Epoch 2/21-----Batch 41328/59476-----Step 8400/100000-----Data Time 0.003 (0.005)-----Step Time 3.035 (3.113)-----Loss 2.9568 (3.6933)\n",
      "Epoch 2/21-----Batch 41568/59476-----Step 8420/100000-----Data Time 0.003 (0.005)-----Step Time 3.118 (3.113)-----Loss 3.6099 (3.6926)\n",
      "Epoch 2/21-----Batch 41808/59476-----Step 8440/100000-----Data Time 0.003 (0.005)-----Step Time 3.192 (3.113)-----Loss 4.6314 (3.6916)\n",
      "Epoch 2/21-----Batch 42048/59476-----Step 8460/100000-----Data Time 0.003 (0.005)-----Step Time 3.176 (3.113)-----Loss 4.5454 (3.6909)\n",
      "Epoch 2/21-----Batch 42288/59476-----Step 8480/100000-----Data Time 0.003 (0.005)-----Step Time 3.142 (3.113)-----Loss 3.4179 (3.6905)\n",
      "Epoch 2/21-----Batch 42528/59476-----Step 8500/100000-----Data Time 0.004 (0.005)-----Step Time 3.200 (3.113)-----Loss 3.8579 (3.6895)\n",
      "Epoch 2/21-----Batch 42768/59476-----Step 8520/100000-----Data Time 0.004 (0.005)-----Step Time 3.060 (3.113)-----Loss 3.5968 (3.6886)\n",
      "Epoch 2/21-----Batch 43008/59476-----Step 8540/100000-----Data Time 0.003 (0.005)-----Step Time 3.037 (3.113)-----Loss 3.3501 (3.6882)\n",
      "Epoch 2/21-----Batch 43248/59476-----Step 8560/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.114)-----Loss 2.9560 (3.6875)\n",
      "Epoch 2/21-----Batch 43488/59476-----Step 8580/100000-----Data Time 0.004 (0.005)-----Step Time 3.055 (3.114)-----Loss 2.8316 (3.6867)\n",
      "Epoch 2/21-----Batch 43728/59476-----Step 8600/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.114)-----Loss 2.5605 (3.6861)\n",
      "Epoch 2/21-----Batch 43968/59476-----Step 8620/100000-----Data Time 0.003 (0.005)-----Step Time 3.044 (3.114)-----Loss 2.9809 (3.6857)\n",
      "Epoch 2/21-----Batch 44208/59476-----Step 8640/100000-----Data Time 0.003 (0.005)-----Step Time 3.127 (3.114)-----Loss 3.4416 (3.6850)\n",
      "Epoch 2/21-----Batch 44448/59476-----Step 8660/100000-----Data Time 0.004 (0.005)-----Step Time 3.098 (3.114)-----Loss 2.5346 (3.6841)\n",
      "Epoch 2/21-----Batch 44688/59476-----Step 8680/100000-----Data Time 0.004 (0.005)-----Step Time 3.103 (3.114)-----Loss 3.8602 (3.6837)\n",
      "Epoch 2/21-----Batch 44928/59476-----Step 8700/100000-----Data Time 0.004 (0.005)-----Step Time 2.997 (3.114)-----Loss 2.8141 (3.6831)\n",
      "Epoch 2/21-----Batch 45168/59476-----Step 8720/100000-----Data Time 0.004 (0.005)-----Step Time 3.143 (3.114)-----Loss 2.6581 (3.6825)\n",
      "Epoch 2/21-----Batch 45408/59476-----Step 8740/100000-----Data Time 0.004 (0.005)-----Step Time 3.151 (3.114)-----Loss 3.4536 (3.6818)\n",
      "Epoch 2/21-----Batch 45648/59476-----Step 8760/100000-----Data Time 0.003 (0.005)-----Step Time 3.131 (3.114)-----Loss 3.4994 (3.6809)\n",
      "Epoch 2/21-----Batch 45888/59476-----Step 8780/100000-----Data Time 0.006 (0.005)-----Step Time 3.097 (3.114)-----Loss 3.6228 (3.6802)\n",
      "Epoch 2/21-----Batch 46128/59476-----Step 8800/100000-----Data Time 0.003 (0.005)-----Step Time 3.058 (3.114)-----Loss 5.2063 (3.6794)\n",
      "Epoch 2/21-----Batch 46368/59476-----Step 8820/100000-----Data Time 0.003 (0.005)-----Step Time 3.270 (3.114)-----Loss 3.5836 (3.6789)\n",
      "Epoch 2/21-----Batch 46608/59476-----Step 8840/100000-----Data Time 0.009 (0.005)-----Step Time 3.145 (3.114)-----Loss 3.3076 (3.6783)\n",
      "Epoch 2/21-----Batch 46848/59476-----Step 8860/100000-----Data Time 0.005 (0.005)-----Step Time 3.370 (3.114)-----Loss 3.1981 (3.6778)\n",
      "Epoch 2/21-----Batch 47088/59476-----Step 8880/100000-----Data Time 0.003 (0.005)-----Step Time 3.101 (3.114)-----Loss 3.9810 (3.6770)\n",
      "Epoch 2/21-----Batch 47328/59476-----Step 8900/100000-----Data Time 0.003 (0.005)-----Step Time 3.116 (3.114)-----Loss 3.3034 (3.6766)\n",
      "Epoch 2/21-----Batch 47568/59476-----Step 8920/100000-----Data Time 0.003 (0.005)-----Step Time 3.126 (3.114)-----Loss 3.6739 (3.6763)\n",
      "Epoch 2/21-----Batch 47808/59476-----Step 8940/100000-----Data Time 0.004 (0.005)-----Step Time 3.075 (3.114)-----Loss 3.3074 (3.6756)\n",
      "Epoch 2/21-----Batch 48048/59476-----Step 8960/100000-----Data Time 0.003 (0.005)-----Step Time 3.121 (3.114)-----Loss 4.0580 (3.6754)\n",
      "Epoch 2/21-----Batch 48288/59476-----Step 8980/100000-----Data Time 0.004 (0.005)-----Step Time 3.117 (3.114)-----Loss 3.4952 (3.6746)\n",
      "Epoch 2/21-----Batch 48528/59476-----Step 9000/100000-----Data Time 0.003 (0.005)-----Step Time 3.175 (3.114)-----Loss 3.1504 (3.6740)\n",
      "Epoch 2/21-----Batch 48768/59476-----Step 9020/100000-----Data Time 0.003 (0.005)-----Step Time 3.093 (3.114)-----Loss 3.8403 (3.6733)\n",
      "Epoch 2/21-----Batch 49008/59476-----Step 9040/100000-----Data Time 0.003 (0.005)-----Step Time 3.219 (3.114)-----Loss 3.8437 (3.6725)\n",
      "Epoch 2/21-----Batch 49248/59476-----Step 9060/100000-----Data Time 0.003 (0.005)-----Step Time 3.140 (3.114)-----Loss 3.8623 (3.6717)\n",
      "Epoch 2/21-----Batch 49488/59476-----Step 9080/100000-----Data Time 0.004 (0.005)-----Step Time 3.141 (3.114)-----Loss 4.9561 (3.6709)\n",
      "Epoch 2/21-----Batch 49728/59476-----Step 9100/100000-----Data Time 0.003 (0.005)-----Step Time 3.002 (3.114)-----Loss 3.2629 (3.6700)\n",
      "Epoch 2/21-----Batch 49968/59476-----Step 9120/100000-----Data Time 0.004 (0.005)-----Step Time 3.088 (3.114)-----Loss 3.0319 (3.6695)\n",
      "Epoch 2/21-----Batch 50208/59476-----Step 9140/100000-----Data Time 0.003 (0.005)-----Step Time 3.156 (3.114)-----Loss 3.3975 (3.6687)\n",
      "Epoch 2/21-----Batch 50448/59476-----Step 9160/100000-----Data Time 0.003 (0.005)-----Step Time 3.094 (3.114)-----Loss 4.2228 (3.6679)\n",
      "Epoch 2/21-----Batch 50688/59476-----Step 9180/100000-----Data Time 0.004 (0.005)-----Step Time 3.078 (3.114)-----Loss 2.7089 (3.6673)\n",
      "Epoch 2/21-----Batch 50928/59476-----Step 9200/100000-----Data Time 0.003 (0.005)-----Step Time 3.137 (3.114)-----Loss 3.7498 (3.6667)\n",
      "Epoch 2/21-----Batch 51168/59476-----Step 9220/100000-----Data Time 0.004 (0.005)-----Step Time 3.119 (3.115)-----Loss 3.7072 (3.6660)\n",
      "Epoch 2/21-----Batch 51408/59476-----Step 9240/100000-----Data Time 0.004 (0.005)-----Step Time 3.124 (3.115)-----Loss 3.1508 (3.6652)\n",
      "Epoch 2/21-----Batch 51648/59476-----Step 9260/100000-----Data Time 0.003 (0.005)-----Step Time 3.120 (3.115)-----Loss 3.2449 (3.6644)\n",
      "Epoch 2/21-----Batch 51888/59476-----Step 9280/100000-----Data Time 0.004 (0.005)-----Step Time 3.164 (3.115)-----Loss 3.1917 (3.6639)\n",
      "Epoch 2/21-----Batch 52128/59476-----Step 9300/100000-----Data Time 0.004 (0.005)-----Step Time 3.164 (3.115)-----Loss 3.3843 (3.6633)\n",
      "Epoch 2/21-----Batch 52368/59476-----Step 9320/100000-----Data Time 0.004 (0.005)-----Step Time 3.034 (3.115)-----Loss 3.4933 (3.6624)\n",
      "Epoch 2/21-----Batch 52608/59476-----Step 9340/100000-----Data Time 0.003 (0.005)-----Step Time 3.046 (3.115)-----Loss 3.0467 (3.6618)\n",
      "Epoch 2/21-----Batch 52848/59476-----Step 9360/100000-----Data Time 0.006 (0.005)-----Step Time 3.128 (3.115)-----Loss 4.3983 (3.6612)\n",
      "Epoch 2/21-----Batch 53088/59476-----Step 9380/100000-----Data Time 0.004 (0.005)-----Step Time 3.149 (3.115)-----Loss 3.4136 (3.6605)\n",
      "Epoch 2/21-----Batch 53328/59476-----Step 9400/100000-----Data Time 0.003 (0.005)-----Step Time 3.090 (3.115)-----Loss 3.4790 (3.6596)\n",
      "Epoch 2/21-----Batch 53568/59476-----Step 9420/100000-----Data Time 0.004 (0.005)-----Step Time 3.296 (3.115)-----Loss 2.8217 (3.6591)\n",
      "Epoch 2/21-----Batch 53808/59476-----Step 9440/100000-----Data Time 0.006 (0.005)-----Step Time 3.082 (3.115)-----Loss 3.0411 (3.6585)\n",
      "Epoch 2/21-----Batch 54048/59476-----Step 9460/100000-----Data Time 0.003 (0.005)-----Step Time 3.511 (3.115)-----Loss 4.0812 (3.6577)\n",
      "Epoch 2/21-----Batch 54288/59476-----Step 9480/100000-----Data Time 0.003 (0.005)-----Step Time 3.022 (3.115)-----Loss 2.8728 (3.6570)\n",
      "Epoch 2/21-----Batch 54528/59476-----Step 9500/100000-----Data Time 0.003 (0.005)-----Step Time 3.125 (3.115)-----Loss 3.1794 (3.6565)\n",
      "Epoch 2/21-----Batch 54768/59476-----Step 9520/100000-----Data Time 0.003 (0.005)-----Step Time 3.315 (3.115)-----Loss 3.1101 (3.6559)\n",
      "Epoch 2/21-----Batch 55008/59476-----Step 9540/100000-----Data Time 0.003 (0.005)-----Step Time 3.136 (3.115)-----Loss 3.0574 (3.6552)\n",
      "Epoch 2/21-----Batch 55248/59476-----Step 9560/100000-----Data Time 0.005 (0.005)-----Step Time 3.133 (3.115)-----Loss 3.0277 (3.6545)\n",
      "Epoch 2/21-----Batch 55488/59476-----Step 9580/100000-----Data Time 0.004 (0.005)-----Step Time 3.142 (3.115)-----Loss 3.8627 (3.6537)\n",
      "Epoch 2/21-----Batch 55728/59476-----Step 9600/100000-----Data Time 0.003 (0.005)-----Step Time 3.116 (3.115)-----Loss 4.7983 (3.6527)\n",
      "Epoch 2/21-----Batch 55968/59476-----Step 9620/100000-----Data Time 0.003 (0.005)-----Step Time 3.074 (3.115)-----Loss 3.2672 (3.6520)\n",
      "Epoch 2/21-----Batch 56208/59476-----Step 9640/100000-----Data Time 0.004 (0.005)-----Step Time 3.140 (3.116)-----Loss 4.0067 (3.6515)\n",
      "Epoch 2/21-----Batch 56448/59476-----Step 9660/100000-----Data Time 0.005 (0.005)-----Step Time 3.140 (3.116)-----Loss 3.3194 (3.6509)\n",
      "Epoch 2/21-----Batch 56688/59476-----Step 9680/100000-----Data Time 0.003 (0.005)-----Step Time 3.038 (3.115)-----Loss 4.3101 (3.6503)\n",
      "Epoch 2/21-----Batch 56928/59476-----Step 9700/100000-----Data Time 0.003 (0.005)-----Step Time 3.129 (3.116)-----Loss 3.2185 (3.6496)\n",
      "Epoch 2/21-----Batch 57168/59476-----Step 9720/100000-----Data Time 0.003 (0.005)-----Step Time 3.104 (3.116)-----Loss 3.2692 (3.6490)\n",
      "Epoch 2/21-----Batch 57408/59476-----Step 9740/100000-----Data Time 0.004 (0.005)-----Step Time 3.119 (3.116)-----Loss 4.1341 (3.6485)\n",
      "Epoch 2/21-----Batch 57648/59476-----Step 9760/100000-----Data Time 0.004 (0.005)-----Step Time 3.021 (3.116)-----Loss 3.2170 (3.6480)\n",
      "Epoch 2/21-----Batch 57888/59476-----Step 9780/100000-----Data Time 0.003 (0.005)-----Step Time 3.130 (3.116)-----Loss 4.4615 (3.6472)\n",
      "Epoch 2/21-----Batch 58128/59476-----Step 9800/100000-----Data Time 0.005 (0.005)-----Step Time 3.121 (3.116)-----Loss 3.3016 (3.6466)\n",
      "Epoch 2/21-----Batch 58368/59476-----Step 9820/100000-----Data Time 0.003 (0.005)-----Step Time 3.147 (3.116)-----Loss 4.1836 (3.6458)\n",
      "Epoch 2/21-----Batch 58608/59476-----Step 9840/100000-----Data Time 0.004 (0.005)-----Step Time 3.096 (3.116)-----Loss 3.9418 (3.6451)\n",
      "Epoch 2/21-----Batch 58848/59476-----Step 9860/100000-----Data Time 0.004 (0.005)-----Step Time 3.002 (3.116)-----Loss 3.2413 (3.6447)\n",
      "Epoch 2/21-----Batch 59088/59476-----Step 9880/100000-----Data Time 0.003 (0.005)-----Step Time 3.046 (3.116)-----Loss 3.6094 (3.6440)\n",
      "Epoch 2/21-----Batch 59328/59476-----Step 9900/100000-----Data Time 0.003 (0.005)-----Step Time 3.100 (3.116)-----Loss 4.8422 (3.6435)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:37<00:00, 81.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss: 3.471\n",
      "\n",
      "\n",
      " Epoch #  2\n",
      "Epoch 3/21-----Batch 96/59476-----Step 9920/100000-----Data Time 0.003 (0.004)-----Step Time 3.049 (2.973)-----Loss 3.1500 (3.5123)\n",
      "Epoch 3/21-----Batch 336/59476-----Step 9940/100000-----Data Time 0.003 (0.005)-----Step Time 3.064 (3.064)-----Loss 3.6707 (3.4468)\n",
      "Epoch 3/21-----Batch 576/59476-----Step 9960/100000-----Data Time 0.004 (0.005)-----Step Time 3.195 (3.094)-----Loss 4.2061 (3.4413)\n",
      "Epoch 3/21-----Batch 816/59476-----Step 9980/100000-----Data Time 0.004 (0.005)-----Step Time 3.086 (3.102)-----Loss 4.6861 (3.4418)\n",
      "Epoch 3/21-----Batch 1056/59476-----Step 10000/100000-----Data Time 0.003 (0.005)-----Step Time 3.139 (3.108)-----Loss 2.8131 (3.4270)\n",
      "Epoch 3/21-----Batch 1296/59476-----Step 10020/100000-----Data Time 0.003 (0.005)-----Step Time 3.130 (3.111)-----Loss 4.6388 (3.4281)\n",
      "Epoch 3/21-----Batch 1536/59476-----Step 10040/100000-----Data Time 0.003 (0.005)-----Step Time 3.119 (3.114)-----Loss 4.1857 (3.4381)\n",
      "Epoch 3/21-----Batch 1776/59476-----Step 10060/100000-----Data Time 0.006 (0.005)-----Step Time 3.254 (3.115)-----Loss 3.0134 (3.4367)\n",
      "Epoch 3/21-----Batch 2016/59476-----Step 10080/100000-----Data Time 0.003 (0.005)-----Step Time 3.175 (3.117)-----Loss 3.4551 (3.4466)\n",
      "Epoch 3/21-----Batch 2256/59476-----Step 10100/100000-----Data Time 0.003 (0.005)-----Step Time 3.122 (3.120)-----Loss 3.9411 (3.4479)\n",
      "Epoch 3/21-----Batch 2496/59476-----Step 10120/100000-----Data Time 0.003 (0.005)-----Step Time 3.170 (3.121)-----Loss 3.2525 (3.4483)\n",
      "Epoch 3/21-----Batch 2736/59476-----Step 10140/100000-----Data Time 0.003 (0.005)-----Step Time 3.141 (3.124)-----Loss 3.3110 (3.4535)\n",
      "Epoch 3/21-----Batch 2976/59476-----Step 10160/100000-----Data Time 0.003 (0.005)-----Step Time 3.128 (3.127)-----Loss 4.7485 (3.4537)\n",
      "Epoch 3/21-----Batch 3216/59476-----Step 10180/100000-----Data Time 0.003 (0.005)-----Step Time 3.074 (3.128)-----Loss 3.5680 (3.4581)\n",
      "Epoch 3/21-----Batch 3456/59476-----Step 10200/100000-----Data Time 0.005 (0.005)-----Step Time 3.171 (3.128)-----Loss 2.0438 (3.4563)\n",
      "Epoch 3/21-----Batch 3696/59476-----Step 10220/100000-----Data Time 0.004 (0.005)-----Step Time 3.367 (3.129)-----Loss 3.4344 (3.4517)\n",
      "Epoch 3/21-----Batch 3936/59476-----Step 10240/100000-----Data Time 0.003 (0.005)-----Step Time 3.195 (3.128)-----Loss 3.6754 (3.4502)\n",
      "Epoch 3/21-----Batch 4176/59476-----Step 10260/100000-----Data Time 0.003 (0.005)-----Step Time 3.139 (3.127)-----Loss 2.7763 (3.4465)\n",
      "Epoch 3/21-----Batch 4416/59476-----Step 10280/100000-----Data Time 0.003 (0.005)-----Step Time 3.082 (3.127)-----Loss 2.7979 (3.4476)\n",
      "Epoch 3/21-----Batch 4656/59476-----Step 10300/100000-----Data Time 0.004 (0.005)-----Step Time 3.188 (3.127)-----Loss 2.9077 (3.4478)\n",
      "Epoch 3/21-----Batch 4896/59476-----Step 10320/100000-----Data Time 0.004 (0.005)-----Step Time 3.054 (3.127)-----Loss 3.5132 (3.4467)\n",
      "Epoch 3/21-----Batch 5136/59476-----Step 10340/100000-----Data Time 0.004 (0.005)-----Step Time 3.693 (3.132)-----Loss 4.0062 (3.4452)\n",
      "Epoch 3/21-----Batch 5376/59476-----Step 10360/100000-----Data Time 0.003 (0.005)-----Step Time 3.671 (3.156)-----Loss 3.2697 (3.4432)\n",
      "Epoch 3/21-----Batch 5616/59476-----Step 10380/100000-----Data Time 0.004 (0.005)-----Step Time 3.670 (3.177)-----Loss 3.5255 (3.4435)\n",
      "Epoch 3/21-----Batch 5856/59476-----Step 10400/100000-----Data Time 0.005 (0.005)-----Step Time 3.724 (3.196)-----Loss 3.5763 (3.4437)\n",
      "Epoch 3/21-----Batch 6096/59476-----Step 10420/100000-----Data Time 0.004 (0.005)-----Step Time 3.540 (3.212)-----Loss 4.9912 (3.4429)\n",
      "Epoch 3/21-----Batch 6336/59476-----Step 10440/100000-----Data Time 0.003 (0.005)-----Step Time 3.192 (3.228)-----Loss 3.4120 (3.4416)\n",
      "Epoch 3/21-----Batch 6576/59476-----Step 10460/100000-----Data Time 0.003 (0.005)-----Step Time 3.132 (3.225)-----Loss 3.1338 (3.4429)\n",
      "Epoch 3/21-----Batch 6816/59476-----Step 10480/100000-----Data Time 0.004 (0.005)-----Step Time 3.123 (3.221)-----Loss 2.6343 (3.4408)\n",
      "Epoch 3/21-----Batch 7056/59476-----Step 10500/100000-----Data Time 0.004 (0.005)-----Step Time 3.196 (3.218)-----Loss 3.7811 (3.4388)\n",
      "Epoch 3/21-----Batch 7296/59476-----Step 10520/100000-----Data Time 0.004 (0.005)-----Step Time 3.168 (3.216)-----Loss 5.3801 (3.4377)\n",
      "Epoch 3/21-----Batch 7536/59476-----Step 10540/100000-----Data Time 0.003 (0.005)-----Step Time 3.092 (3.213)-----Loss 2.8050 (3.4373)\n",
      "Epoch 3/21-----Batch 7776/59476-----Step 10560/100000-----Data Time 0.003 (0.005)-----Step Time 3.026 (3.210)-----Loss 4.6533 (3.4364)\n",
      "Epoch 3/21-----Batch 8016/59476-----Step 10580/100000-----Data Time 0.003 (0.005)-----Step Time 3.052 (3.207)-----Loss 3.0098 (3.4351)\n",
      "Epoch 3/21-----Batch 8256/59476-----Step 10600/100000-----Data Time 0.005 (0.005)-----Step Time 3.156 (3.205)-----Loss 4.4860 (3.4340)\n",
      "Epoch 3/21-----Batch 8496/59476-----Step 10620/100000-----Data Time 0.003 (0.005)-----Step Time 3.102 (3.203)-----Loss 4.3578 (3.4330)\n",
      "Epoch 3/21-----Batch 8736/59476-----Step 10640/100000-----Data Time 0.003 (0.005)-----Step Time 3.160 (3.201)-----Loss 3.5260 (3.4325)\n",
      "Epoch 3/21-----Batch 8976/59476-----Step 10660/100000-----Data Time 0.007 (0.005)-----Step Time 3.114 (3.199)-----Loss 3.2490 (3.4336)\n",
      "Epoch 3/21-----Batch 9216/59476-----Step 10680/100000-----Data Time 0.003 (0.005)-----Step Time 3.122 (3.197)-----Loss 3.6849 (3.4339)\n",
      "Epoch 3/21-----Batch 9456/59476-----Step 10700/100000-----Data Time 0.003 (0.005)-----Step Time 3.120 (3.196)-----Loss 3.2899 (3.4343)\n",
      "Epoch 3/21-----Batch 9696/59476-----Step 10720/100000-----Data Time 0.007 (0.005)-----Step Time 3.194 (3.196)-----Loss 4.4982 (3.4349)\n",
      "Epoch 3/21-----Batch 9936/59476-----Step 10740/100000-----Data Time 0.003 (0.005)-----Step Time 3.080 (3.194)-----Loss 3.3399 (3.4351)\n",
      "Epoch 3/21-----Batch 10176/59476-----Step 10760/100000-----Data Time 0.003 (0.005)-----Step Time 3.158 (3.192)-----Loss 2.9143 (3.4357)\n",
      "Epoch 3/21-----Batch 10416/59476-----Step 10780/100000-----Data Time 0.003 (0.005)-----Step Time 3.116 (3.191)-----Loss 3.9568 (3.4354)\n",
      "Epoch 3/21-----Batch 10656/59476-----Step 10800/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.190)-----Loss 3.0005 (3.4360)\n",
      "Epoch 3/21-----Batch 10896/59476-----Step 10820/100000-----Data Time 0.003 (0.005)-----Step Time 3.239 (3.189)-----Loss 2.8645 (3.4365)\n",
      "Epoch 3/21-----Batch 11136/59476-----Step 10840/100000-----Data Time 0.003 (0.005)-----Step Time 3.160 (3.189)-----Loss 3.5588 (3.4360)\n",
      "Epoch 3/21-----Batch 11376/59476-----Step 10860/100000-----Data Time 0.003 (0.005)-----Step Time 3.326 (3.188)-----Loss 3.9241 (3.4367)\n",
      "Epoch 3/21-----Batch 11616/59476-----Step 10880/100000-----Data Time 0.003 (0.005)-----Step Time 3.163 (3.186)-----Loss 4.9388 (3.4359)\n",
      "Epoch 3/21-----Batch 11856/59476-----Step 10900/100000-----Data Time 0.003 (0.005)-----Step Time 3.142 (3.185)-----Loss 2.6346 (3.4347)\n",
      "Epoch 3/21-----Batch 12096/59476-----Step 10920/100000-----Data Time 0.005 (0.005)-----Step Time 3.177 (3.184)-----Loss 2.7735 (3.4336)\n",
      "Epoch 3/21-----Batch 12336/59476-----Step 10940/100000-----Data Time 0.004 (0.005)-----Step Time 3.150 (3.184)-----Loss 2.7525 (3.4327)\n",
      "Epoch 3/21-----Batch 12576/59476-----Step 10960/100000-----Data Time 0.004 (0.005)-----Step Time 3.135 (3.182)-----Loss 3.2187 (3.4323)\n",
      "Epoch 3/21-----Batch 12816/59476-----Step 10980/100000-----Data Time 0.005 (0.005)-----Step Time 3.114 (3.182)-----Loss 2.8023 (3.4300)\n",
      "Epoch 3/21-----Batch 13056/59476-----Step 11000/100000-----Data Time 0.003 (0.005)-----Step Time 3.116 (3.182)-----Loss 3.4455 (3.4300)\n",
      "Epoch 3/21-----Batch 13296/59476-----Step 11020/100000-----Data Time 0.003 (0.005)-----Step Time 3.480 (3.182)-----Loss 3.8002 (3.4316)\n",
      "Epoch 3/21-----Batch 13536/59476-----Step 11040/100000-----Data Time 0.004 (0.005)-----Step Time 3.203 (3.182)-----Loss 4.0157 (3.4309)\n",
      "Epoch 3/21-----Batch 13776/59476-----Step 11060/100000-----Data Time 0.003 (0.005)-----Step Time 3.152 (3.181)-----Loss 3.8884 (3.4294)\n",
      "Epoch 3/21-----Batch 14016/59476-----Step 11080/100000-----Data Time 0.004 (0.005)-----Step Time 3.150 (3.180)-----Loss 4.5917 (3.4296)\n",
      "Epoch 3/21-----Batch 14256/59476-----Step 11100/100000-----Data Time 0.004 (0.005)-----Step Time 3.150 (3.179)-----Loss 3.0791 (3.4279)\n",
      "Epoch 3/21-----Batch 14496/59476-----Step 11120/100000-----Data Time 0.003 (0.005)-----Step Time 3.175 (3.178)-----Loss 3.5274 (3.4276)\n",
      "Epoch 3/21-----Batch 14736/59476-----Step 11140/100000-----Data Time 0.003 (0.005)-----Step Time 3.027 (3.177)-----Loss 3.1484 (3.4274)\n",
      "Epoch 3/21-----Batch 14976/59476-----Step 11160/100000-----Data Time 0.003 (0.005)-----Step Time 3.069 (3.176)-----Loss 3.7639 (3.4273)\n",
      "Epoch 3/21-----Batch 15216/59476-----Step 11180/100000-----Data Time 0.004 (0.005)-----Step Time 3.146 (3.175)-----Loss 3.4082 (3.4269)\n",
      "Epoch 3/21-----Batch 15456/59476-----Step 11200/100000-----Data Time 0.003 (0.005)-----Step Time 3.085 (3.175)-----Loss 3.1471 (3.4254)\n",
      "Epoch 3/21-----Batch 15696/59476-----Step 11220/100000-----Data Time 0.003 (0.005)-----Step Time 3.167 (3.175)-----Loss 2.9098 (3.4250)\n",
      "Epoch 3/21-----Batch 15936/59476-----Step 11240/100000-----Data Time 0.003 (0.005)-----Step Time 3.167 (3.174)-----Loss 3.1147 (3.4249)\n",
      "Epoch 3/21-----Batch 16176/59476-----Step 11260/100000-----Data Time 0.003 (0.005)-----Step Time 3.215 (3.174)-----Loss 4.7292 (3.4246)\n",
      "Epoch 3/21-----Batch 16416/59476-----Step 11280/100000-----Data Time 0.003 (0.005)-----Step Time 3.139 (3.173)-----Loss 3.1339 (3.4241)\n",
      "Epoch 3/21-----Batch 16656/59476-----Step 11300/100000-----Data Time 0.002 (0.005)-----Step Time 3.151 (3.173)-----Loss 4.0672 (3.4236)\n",
      "Epoch 3/21-----Batch 16896/59476-----Step 11320/100000-----Data Time 0.004 (0.005)-----Step Time 3.080 (3.172)-----Loss 3.6329 (3.4236)\n",
      "Epoch 3/21-----Batch 17136/59476-----Step 11340/100000-----Data Time 0.003 (0.005)-----Step Time 3.144 (3.172)-----Loss 4.8322 (3.4231)\n",
      "Epoch 3/21-----Batch 17376/59476-----Step 11360/100000-----Data Time 0.008 (0.005)-----Step Time 3.282 (3.172)-----Loss 4.6701 (3.4233)\n",
      "Epoch 3/21-----Batch 17616/59476-----Step 11380/100000-----Data Time 0.003 (0.005)-----Step Time 3.373 (3.172)-----Loss 2.9804 (3.4233)\n",
      "Epoch 3/21-----Batch 17856/59476-----Step 11400/100000-----Data Time 0.004 (0.005)-----Step Time 3.254 (3.172)-----Loss 2.8350 (3.4230)\n",
      "Epoch 3/21-----Batch 18096/59476-----Step 11420/100000-----Data Time 0.003 (0.005)-----Step Time 3.178 (3.172)-----Loss 3.1969 (3.4225)\n",
      "Epoch 3/21-----Batch 18336/59476-----Step 11440/100000-----Data Time 0.003 (0.005)-----Step Time 3.169 (3.171)-----Loss 4.2958 (3.4224)\n",
      "Epoch 3/21-----Batch 18576/59476-----Step 11460/100000-----Data Time 0.004 (0.005)-----Step Time 3.011 (3.170)-----Loss 3.4942 (3.4220)\n",
      "Epoch 3/21-----Batch 18816/59476-----Step 11480/100000-----Data Time 0.003 (0.005)-----Step Time 3.052 (3.170)-----Loss 3.4136 (3.4211)\n",
      "Epoch 3/21-----Batch 19056/59476-----Step 11500/100000-----Data Time 0.003 (0.005)-----Step Time 3.094 (3.169)-----Loss 3.2779 (3.4208)\n",
      "Epoch 3/21-----Batch 19296/59476-----Step 11520/100000-----Data Time 0.003 (0.005)-----Step Time 3.120 (3.169)-----Loss 3.5998 (3.4199)\n",
      "Epoch 3/21-----Batch 19536/59476-----Step 11540/100000-----Data Time 0.003 (0.005)-----Step Time 3.193 (3.168)-----Loss 2.8159 (3.4187)\n",
      "Epoch 3/21-----Batch 19776/59476-----Step 11560/100000-----Data Time 0.003 (0.005)-----Step Time 3.064 (3.169)-----Loss 4.5166 (3.4187)\n",
      "Epoch 3/21-----Batch 20016/59476-----Step 11580/100000-----Data Time 0.003 (0.005)-----Step Time 3.027 (3.168)-----Loss 3.1209 (3.4188)\n",
      "Epoch 3/21-----Batch 20256/59476-----Step 11600/100000-----Data Time 0.003 (0.005)-----Step Time 3.093 (3.168)-----Loss 4.2230 (3.4184)\n",
      "Epoch 3/21-----Batch 20496/59476-----Step 11620/100000-----Data Time 0.004 (0.005)-----Step Time 3.170 (3.168)-----Loss 3.1303 (3.4178)\n",
      "Epoch 3/21-----Batch 20736/59476-----Step 11640/100000-----Data Time 0.003 (0.005)-----Step Time 3.240 (3.167)-----Loss 2.5227 (3.4176)\n",
      "Epoch 3/21-----Batch 20976/59476-----Step 11660/100000-----Data Time 0.004 (0.005)-----Step Time 3.039 (3.167)-----Loss 2.5753 (3.4172)\n",
      "Epoch 3/21-----Batch 21216/59476-----Step 11680/100000-----Data Time 0.003 (0.005)-----Step Time 3.060 (3.166)-----Loss 2.9976 (3.4169)\n",
      "Epoch 3/21-----Batch 21456/59476-----Step 11700/100000-----Data Time 0.003 (0.005)-----Step Time 3.180 (3.166)-----Loss 3.5174 (3.4167)\n",
      "Epoch 3/21-----Batch 21696/59476-----Step 11720/100000-----Data Time 0.003 (0.005)-----Step Time 3.052 (3.166)-----Loss 3.0829 (3.4162)\n",
      "Epoch 3/21-----Batch 21936/59476-----Step 11740/100000-----Data Time 0.003 (0.005)-----Step Time 3.096 (3.165)-----Loss 2.7763 (3.4166)\n",
      "Epoch 3/21-----Batch 22176/59476-----Step 11760/100000-----Data Time 0.004 (0.005)-----Step Time 3.158 (3.165)-----Loss 4.6305 (3.4162)\n",
      "Epoch 3/21-----Batch 22416/59476-----Step 11780/100000-----Data Time 0.004 (0.005)-----Step Time 3.779 (3.165)-----Loss 3.9049 (3.4150)\n",
      "Epoch 3/21-----Batch 22656/59476-----Step 11800/100000-----Data Time 0.004 (0.005)-----Step Time 3.567 (3.170)-----Loss 3.6605 (3.4143)\n",
      "Epoch 3/21-----Batch 22896/59476-----Step 11820/100000-----Data Time 0.004 (0.005)-----Step Time 3.871 (3.176)-----Loss 3.3424 (3.4136)\n",
      "Epoch 3/21-----Batch 23136/59476-----Step 11840/100000-----Data Time 0.003 (0.005)-----Step Time 3.564 (3.181)-----Loss 2.9122 (3.4136)\n",
      "Epoch 3/21-----Batch 23376/59476-----Step 11860/100000-----Data Time 0.003 (0.005)-----Step Time 3.629 (3.185)-----Loss 2.6930 (3.4127)\n",
      "Epoch 3/21-----Batch 23616/59476-----Step 11880/100000-----Data Time 0.003 (0.005)-----Step Time 3.638 (3.190)-----Loss 3.3417 (3.4125)\n",
      "Epoch 3/21-----Batch 23856/59476-----Step 11900/100000-----Data Time 0.004 (0.005)-----Step Time 3.666 (3.194)-----Loss 2.9859 (3.4127)\n",
      "Epoch 3/21-----Batch 24096/59476-----Step 11920/100000-----Data Time 0.005 (0.005)-----Step Time 4.009 (3.199)-----Loss 4.6443 (3.4123)\n",
      "Epoch 3/21-----Batch 24336/59476-----Step 11940/100000-----Data Time 0.003 (0.005)-----Step Time 3.892 (3.205)-----Loss 2.7953 (3.4120)\n",
      "Epoch 3/21-----Batch 24576/59476-----Step 11960/100000-----Data Time 0.003 (0.005)-----Step Time 3.756 (3.211)-----Loss 2.8603 (3.4115)\n",
      "Epoch 3/21-----Batch 24816/59476-----Step 11980/100000-----Data Time 0.004 (0.005)-----Step Time 3.243 (3.214)-----Loss 2.6820 (3.4113)\n",
      "Epoch 3/21-----Batch 25056/59476-----Step 12000/100000-----Data Time 0.003 (0.005)-----Step Time 3.428 (3.216)-----Loss 2.7682 (3.4115)\n",
      "Epoch 3/21-----Batch 25296/59476-----Step 12020/100000-----Data Time 0.003 (0.005)-----Step Time 3.271 (3.218)-----Loss 2.8751 (3.4115)\n",
      "Epoch 3/21-----Batch 25536/59476-----Step 12040/100000-----Data Time 0.003 (0.005)-----Step Time 3.386 (3.220)-----Loss 3.2809 (3.4116)\n",
      "Epoch 3/21-----Batch 25776/59476-----Step 12060/100000-----Data Time 0.004 (0.005)-----Step Time 3.226 (3.221)-----Loss 4.2496 (3.4118)\n",
      "Epoch 3/21-----Batch 26016/59476-----Step 12080/100000-----Data Time 0.003 (0.005)-----Step Time 3.133 (3.221)-----Loss 4.8574 (3.4120)\n",
      "Epoch 3/21-----Batch 26256/59476-----Step 12100/100000-----Data Time 0.003 (0.005)-----Step Time 3.151 (3.220)-----Loss 2.9719 (3.4119)\n",
      "Epoch 3/21-----Batch 26496/59476-----Step 12120/100000-----Data Time 0.003 (0.005)-----Step Time 3.206 (3.219)-----Loss 3.6960 (3.4114)\n",
      "Epoch 3/21-----Batch 26736/59476-----Step 12140/100000-----Data Time 0.003 (0.005)-----Step Time 3.135 (3.219)-----Loss 2.6393 (3.4111)\n",
      "Epoch 3/21-----Batch 26976/59476-----Step 12160/100000-----Data Time 0.003 (0.005)-----Step Time 3.232 (3.218)-----Loss 3.3703 (3.4104)\n",
      "Epoch 3/21-----Batch 27216/59476-----Step 12180/100000-----Data Time 0.005 (0.005)-----Step Time 3.081 (3.218)-----Loss 2.9986 (3.4105)\n",
      "Epoch 3/21-----Batch 27456/59476-----Step 12200/100000-----Data Time 0.003 (0.005)-----Step Time 3.088 (3.217)-----Loss 3.1942 (3.4105)\n",
      "Epoch 3/21-----Batch 27696/59476-----Step 12220/100000-----Data Time 0.003 (0.005)-----Step Time 3.230 (3.216)-----Loss 2.8106 (3.4103)\n",
      "Epoch 3/21-----Batch 27936/59476-----Step 12240/100000-----Data Time 0.003 (0.005)-----Step Time 3.119 (3.216)-----Loss 2.9429 (3.4095)\n",
      "Epoch 3/21-----Batch 28176/59476-----Step 12260/100000-----Data Time 0.006 (0.005)-----Step Time 3.100 (3.215)-----Loss 4.8887 (3.4092)\n",
      "Epoch 3/21-----Batch 28416/59476-----Step 12280/100000-----Data Time 0.006 (0.005)-----Step Time 3.127 (3.215)-----Loss 2.7681 (3.4087)\n",
      "Epoch 3/21-----Batch 28656/59476-----Step 12300/100000-----Data Time 0.003 (0.005)-----Step Time 3.138 (3.214)-----Loss 2.9104 (3.4083)\n",
      "Epoch 3/21-----Batch 28896/59476-----Step 12320/100000-----Data Time 0.003 (0.005)-----Step Time 3.093 (3.214)-----Loss 3.1338 (3.4082)\n",
      "Epoch 3/21-----Batch 29136/59476-----Step 12340/100000-----Data Time 0.009 (0.005)-----Step Time 3.128 (3.213)-----Loss 3.1883 (3.4077)\n",
      "Epoch 3/21-----Batch 29376/59476-----Step 12360/100000-----Data Time 0.003 (0.005)-----Step Time 3.034 (3.212)-----Loss 3.1947 (3.4074)\n",
      "Epoch 3/21-----Batch 29616/59476-----Step 12380/100000-----Data Time 0.003 (0.005)-----Step Time 3.117 (3.212)-----Loss 3.8139 (3.4066)\n",
      "Epoch 3/21-----Batch 29856/59476-----Step 12400/100000-----Data Time 0.003 (0.005)-----Step Time 3.175 (3.211)-----Loss 3.6119 (3.4064)\n",
      "Epoch 3/21-----Batch 30096/59476-----Step 12420/100000-----Data Time 0.003 (0.005)-----Step Time 3.146 (3.211)-----Loss 3.1018 (3.4057)\n",
      "Epoch 3/21-----Batch 30336/59476-----Step 12440/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.210)-----Loss 3.5467 (3.4055)\n",
      "Epoch 3/21-----Batch 30576/59476-----Step 12460/100000-----Data Time 0.006 (0.005)-----Step Time 3.314 (3.209)-----Loss 3.7260 (3.4048)\n",
      "Epoch 3/21-----Batch 30816/59476-----Step 12480/100000-----Data Time 0.004 (0.005)-----Step Time 3.119 (3.209)-----Loss 3.4285 (3.4040)\n",
      "Epoch 3/21-----Batch 31056/59476-----Step 12500/100000-----Data Time 0.003 (0.005)-----Step Time 3.052 (3.208)-----Loss 4.3646 (3.4033)\n",
      "Epoch 3/21-----Batch 31296/59476-----Step 12520/100000-----Data Time 0.003 (0.005)-----Step Time 3.097 (3.207)-----Loss 3.0647 (3.4032)\n",
      "Epoch 3/21-----Batch 31536/59476-----Step 12540/100000-----Data Time 0.004 (0.005)-----Step Time 3.267 (3.207)-----Loss 3.2266 (3.4032)\n",
      "Epoch 3/21-----Batch 31776/59476-----Step 12560/100000-----Data Time 0.005 (0.005)-----Step Time 3.207 (3.206)-----Loss 2.3269 (3.4028)\n",
      "Epoch 3/21-----Batch 32016/59476-----Step 12580/100000-----Data Time 0.004 (0.005)-----Step Time 3.101 (3.205)-----Loss 4.5830 (3.4022)\n",
      "Epoch 3/21-----Batch 32256/59476-----Step 12600/100000-----Data Time 0.004 (0.005)-----Step Time 3.087 (3.205)-----Loss 2.9952 (3.4017)\n",
      "Epoch 3/21-----Batch 32496/59476-----Step 12620/100000-----Data Time 0.003 (0.005)-----Step Time 3.152 (3.204)-----Loss 4.9314 (3.4017)\n",
      "Epoch 3/21-----Batch 32736/59476-----Step 12640/100000-----Data Time 0.003 (0.005)-----Step Time 3.104 (3.204)-----Loss 3.1531 (3.4010)\n",
      "Epoch 3/21-----Batch 32976/59476-----Step 12660/100000-----Data Time 0.003 (0.005)-----Step Time 3.174 (3.203)-----Loss 3.0011 (3.4004)\n",
      "Epoch 3/21-----Batch 33216/59476-----Step 12680/100000-----Data Time 0.003 (0.005)-----Step Time 3.083 (3.203)-----Loss 3.2569 (3.3999)\n",
      "Epoch 3/21-----Batch 33456/59476-----Step 12700/100000-----Data Time 0.003 (0.005)-----Step Time 3.041 (3.202)-----Loss 3.3919 (3.3996)\n",
      "Epoch 3/21-----Batch 33696/59476-----Step 12720/100000-----Data Time 0.003 (0.005)-----Step Time 3.112 (3.202)-----Loss 4.0225 (3.3996)\n",
      "Epoch 3/21-----Batch 33936/59476-----Step 12740/100000-----Data Time 0.004 (0.005)-----Step Time 3.148 (3.201)-----Loss 5.2378 (3.3995)\n",
      "Epoch 3/21-----Batch 34176/59476-----Step 12760/100000-----Data Time 0.004 (0.005)-----Step Time 3.187 (3.201)-----Loss 2.6344 (3.3994)\n",
      "Epoch 3/21-----Batch 34416/59476-----Step 12780/100000-----Data Time 0.003 (0.005)-----Step Time 3.038 (3.200)-----Loss 2.6650 (3.3989)\n",
      "Epoch 3/21-----Batch 34656/59476-----Step 12800/100000-----Data Time 0.004 (0.005)-----Step Time 3.154 (3.200)-----Loss 3.1736 (3.3982)\n",
      "Epoch 3/21-----Batch 34896/59476-----Step 12820/100000-----Data Time 0.003 (0.005)-----Step Time 3.136 (3.200)-----Loss 3.8372 (3.3981)\n",
      "Epoch 3/21-----Batch 35136/59476-----Step 12840/100000-----Data Time 0.003 (0.005)-----Step Time 3.053 (3.199)-----Loss 2.5663 (3.3974)\n",
      "Epoch 3/21-----Batch 35376/59476-----Step 12860/100000-----Data Time 0.003 (0.005)-----Step Time 3.170 (3.199)-----Loss 3.5902 (3.3969)\n",
      "Epoch 3/21-----Batch 35616/59476-----Step 12880/100000-----Data Time 0.004 (0.005)-----Step Time 3.137 (3.198)-----Loss 3.5979 (3.3959)\n",
      "Epoch 3/21-----Batch 35856/59476-----Step 12900/100000-----Data Time 0.003 (0.005)-----Step Time 3.059 (3.198)-----Loss 3.0995 (3.3955)\n",
      "Epoch 3/21-----Batch 36096/59476-----Step 12920/100000-----Data Time 0.003 (0.005)-----Step Time 3.153 (3.197)-----Loss 3.2093 (3.3953)\n",
      "Epoch 3/21-----Batch 36336/59476-----Step 12940/100000-----Data Time 0.003 (0.005)-----Step Time 3.143 (3.197)-----Loss 2.9010 (3.3947)\n",
      "Epoch 3/21-----Batch 36576/59476-----Step 12960/100000-----Data Time 0.003 (0.005)-----Step Time 3.132 (3.196)-----Loss 3.4037 (3.3944)\n",
      "Epoch 3/21-----Batch 36816/59476-----Step 12980/100000-----Data Time 0.003 (0.005)-----Step Time 3.152 (3.196)-----Loss 3.1004 (3.3944)\n",
      "Epoch 3/21-----Batch 37056/59476-----Step 13000/100000-----Data Time 0.004 (0.005)-----Step Time 3.109 (3.196)-----Loss 3.1977 (3.3938)\n",
      "Epoch 3/21-----Batch 37296/59476-----Step 13020/100000-----Data Time 0.004 (0.005)-----Step Time 3.216 (3.195)-----Loss 3.8803 (3.3934)\n",
      "Epoch 3/21-----Batch 37536/59476-----Step 13040/100000-----Data Time 0.003 (0.005)-----Step Time 3.093 (3.195)-----Loss 2.9678 (3.3928)\n",
      "Epoch 3/21-----Batch 37776/59476-----Step 13060/100000-----Data Time 0.003 (0.005)-----Step Time 3.173 (3.195)-----Loss 2.7496 (3.3924)\n",
      "Epoch 3/21-----Batch 38016/59476-----Step 13080/100000-----Data Time 0.003 (0.005)-----Step Time 3.021 (3.194)-----Loss 3.9323 (3.3927)\n",
      "Epoch 3/21-----Batch 38256/59476-----Step 13100/100000-----Data Time 0.004 (0.005)-----Step Time 3.307 (3.194)-----Loss 3.9256 (3.3925)\n",
      "Epoch 3/21-----Batch 38496/59476-----Step 13120/100000-----Data Time 0.003 (0.005)-----Step Time 3.109 (3.194)-----Loss 3.8258 (3.3922)\n",
      "Epoch 3/21-----Batch 38736/59476-----Step 13140/100000-----Data Time 0.004 (0.005)-----Step Time 3.072 (3.194)-----Loss 4.6199 (3.3924)\n",
      "Epoch 3/21-----Batch 38976/59476-----Step 13160/100000-----Data Time 0.003 (0.005)-----Step Time 3.198 (3.193)-----Loss 2.9627 (3.3921)\n",
      "Epoch 3/21-----Batch 39216/59476-----Step 13180/100000-----Data Time 0.004 (0.005)-----Step Time 3.138 (3.193)-----Loss 4.3159 (3.3918)\n",
      "Epoch 3/21-----Batch 39456/59476-----Step 13200/100000-----Data Time 0.004 (0.005)-----Step Time 3.153 (3.193)-----Loss 2.7383 (3.3911)\n",
      "Epoch 3/21-----Batch 39696/59476-----Step 13220/100000-----Data Time 0.003 (0.005)-----Step Time 3.124 (3.192)-----Loss 4.1730 (3.3905)\n",
      "Epoch 3/21-----Batch 39936/59476-----Step 13240/100000-----Data Time 0.003 (0.005)-----Step Time 3.037 (3.192)-----Loss 3.4434 (3.3901)\n",
      "Epoch 3/21-----Batch 40176/59476-----Step 13260/100000-----Data Time 0.003 (0.005)-----Step Time 3.186 (3.192)-----Loss 4.6473 (3.3896)\n",
      "Epoch 3/21-----Batch 40416/59476-----Step 13280/100000-----Data Time 0.003 (0.005)-----Step Time 3.187 (3.191)-----Loss 3.8479 (3.3891)\n",
      "Epoch 3/21-----Batch 40656/59476-----Step 13300/100000-----Data Time 0.004 (0.005)-----Step Time 3.268 (3.191)-----Loss 2.8066 (3.3887)\n",
      "Epoch 3/21-----Batch 40896/59476-----Step 13320/100000-----Data Time 0.003 (0.005)-----Step Time 3.060 (3.191)-----Loss 3.1335 (3.3883)\n",
      "Epoch 3/21-----Batch 41136/59476-----Step 13340/100000-----Data Time 0.003 (0.005)-----Step Time 3.149 (3.190)-----Loss 3.9981 (3.3880)\n",
      "Epoch 3/21-----Batch 41376/59476-----Step 13360/100000-----Data Time 0.003 (0.005)-----Step Time 3.180 (3.190)-----Loss 3.1076 (3.3874)\n",
      "Epoch 3/21-----Batch 41616/59476-----Step 13380/100000-----Data Time 0.003 (0.005)-----Step Time 3.141 (3.190)-----Loss 3.7725 (3.3872)\n",
      "Epoch 3/21-----Batch 41856/59476-----Step 13400/100000-----Data Time 0.004 (0.005)-----Step Time 3.191 (3.189)-----Loss 4.2952 (3.3869)\n",
      "Epoch 3/21-----Batch 42096/59476-----Step 13420/100000-----Data Time 0.004 (0.005)-----Step Time 3.158 (3.189)-----Loss 3.1748 (3.3865)\n",
      "Epoch 3/21-----Batch 42336/59476-----Step 13440/100000-----Data Time 0.003 (0.005)-----Step Time 3.178 (3.189)-----Loss 4.9934 (3.3864)\n",
      "Epoch 3/21-----Batch 42576/59476-----Step 13460/100000-----Data Time 0.004 (0.005)-----Step Time 3.094 (3.189)-----Loss 3.3286 (3.3861)\n",
      "Epoch 3/21-----Batch 42816/59476-----Step 13480/100000-----Data Time 0.005 (0.005)-----Step Time 3.423 (3.188)-----Loss 2.9530 (3.3858)\n",
      "Epoch 3/21-----Batch 43056/59476-----Step 13500/100000-----Data Time 0.004 (0.005)-----Step Time 3.314 (3.188)-----Loss 3.2278 (3.3854)\n",
      "Epoch 3/21-----Batch 43296/59476-----Step 13520/100000-----Data Time 0.003 (0.005)-----Step Time 3.176 (3.188)-----Loss 4.3969 (3.3852)\n",
      "Epoch 3/21-----Batch 43536/59476-----Step 13540/100000-----Data Time 0.006 (0.005)-----Step Time 3.133 (3.187)-----Loss 3.6147 (3.3850)\n",
      "Epoch 3/21-----Batch 43776/59476-----Step 13560/100000-----Data Time 0.004 (0.005)-----Step Time 3.068 (3.187)-----Loss 4.5459 (3.3850)\n",
      "Epoch 3/21-----Batch 44016/59476-----Step 13580/100000-----Data Time 0.003 (0.005)-----Step Time 3.307 (3.187)-----Loss 4.6358 (3.3848)\n",
      "Epoch 3/21-----Batch 44256/59476-----Step 13600/100000-----Data Time 0.003 (0.005)-----Step Time 3.083 (3.187)-----Loss 2.9065 (3.3842)\n",
      "Epoch 3/21-----Batch 44496/59476-----Step 13620/100000-----Data Time 0.005 (0.005)-----Step Time 3.159 (3.186)-----Loss 3.0678 (3.3840)\n",
      "Epoch 3/21-----Batch 44736/59476-----Step 13640/100000-----Data Time 0.003 (0.005)-----Step Time 3.045 (3.186)-----Loss 3.4786 (3.3838)\n",
      "Epoch 3/21-----Batch 44976/59476-----Step 13660/100000-----Data Time 0.004 (0.005)-----Step Time 3.108 (3.186)-----Loss 3.3644 (3.3836)\n",
      "Epoch 3/21-----Batch 45216/59476-----Step 13680/100000-----Data Time 0.003 (0.005)-----Step Time 3.117 (3.186)-----Loss 3.0476 (3.3831)\n",
      "Epoch 3/21-----Batch 45456/59476-----Step 13700/100000-----Data Time 0.005 (0.005)-----Step Time 3.178 (3.185)-----Loss 3.9087 (3.3829)\n",
      "Epoch 3/21-----Batch 45696/59476-----Step 13720/100000-----Data Time 0.003 (0.005)-----Step Time 3.378 (3.185)-----Loss 3.4898 (3.3824)\n",
      "Epoch 3/21-----Batch 45936/59476-----Step 13740/100000-----Data Time 0.006 (0.005)-----Step Time 3.140 (3.185)-----Loss 2.4644 (3.3820)\n",
      "Epoch 3/21-----Batch 46176/59476-----Step 13760/100000-----Data Time 0.003 (0.005)-----Step Time 3.128 (3.185)-----Loss 4.7965 (3.3818)\n",
      "Epoch 3/21-----Batch 46416/59476-----Step 13780/100000-----Data Time 0.003 (0.005)-----Step Time 3.142 (3.184)-----Loss 3.0008 (3.3815)\n",
      "Epoch 3/21-----Batch 46656/59476-----Step 13800/100000-----Data Time 0.004 (0.005)-----Step Time 3.110 (3.184)-----Loss 3.5113 (3.3811)\n",
      "Epoch 3/21-----Batch 46896/59476-----Step 13820/100000-----Data Time 0.004 (0.005)-----Step Time 3.113 (3.184)-----Loss 3.4885 (3.3807)\n",
      "Epoch 3/21-----Batch 47136/59476-----Step 13840/100000-----Data Time 0.003 (0.005)-----Step Time 3.061 (3.183)-----Loss 2.6158 (3.3806)\n",
      "Epoch 3/21-----Batch 47376/59476-----Step 13860/100000-----Data Time 0.004 (0.005)-----Step Time 3.104 (3.183)-----Loss 2.6049 (3.3803)\n",
      "Epoch 3/21-----Batch 47616/59476-----Step 13880/100000-----Data Time 0.003 (0.005)-----Step Time 3.103 (3.183)-----Loss 3.4980 (3.3802)\n",
      "Epoch 3/21-----Batch 47856/59476-----Step 13900/100000-----Data Time 0.006 (0.005)-----Step Time 3.149 (3.183)-----Loss 2.7497 (3.3800)\n",
      "Epoch 3/21-----Batch 48096/59476-----Step 13920/100000-----Data Time 0.003 (0.005)-----Step Time 3.099 (3.182)-----Loss 3.9493 (3.3793)\n",
      "Epoch 3/21-----Batch 48336/59476-----Step 13940/100000-----Data Time 0.003 (0.005)-----Step Time 3.083 (3.182)-----Loss 3.5606 (3.3788)\n",
      "Epoch 3/21-----Batch 48576/59476-----Step 13960/100000-----Data Time 0.009 (0.005)-----Step Time 3.142 (3.182)-----Loss 4.0271 (3.3784)\n",
      "Epoch 3/21-----Batch 48816/59476-----Step 13980/100000-----Data Time 0.003 (0.005)-----Step Time 3.141 (3.182)-----Loss 3.1296 (3.3784)\n",
      "Epoch 3/21-----Batch 49056/59476-----Step 14000/100000-----Data Time 0.004 (0.005)-----Step Time 3.171 (3.182)-----Loss 4.0995 (3.3775)\n",
      "Epoch 3/21-----Batch 49296/59476-----Step 14020/100000-----Data Time 0.003 (0.005)-----Step Time 3.235 (3.182)-----Loss 3.2064 (3.3772)\n",
      "Epoch 3/21-----Batch 49536/59476-----Step 14040/100000-----Data Time 0.003 (0.005)-----Step Time 3.569 (3.181)-----Loss 3.3801 (3.3768)\n",
      "Epoch 3/21-----Batch 49776/59476-----Step 14060/100000-----Data Time 0.004 (0.005)-----Step Time 3.363 (3.184)-----Loss 4.8395 (3.3765)\n",
      "Epoch 3/21-----Batch 50016/59476-----Step 14080/100000-----Data Time 0.004 (0.005)-----Step Time 3.565 (3.185)-----Loss 2.9066 (3.3763)\n",
      "Epoch 3/21-----Batch 50256/59476-----Step 14100/100000-----Data Time 0.004 (0.005)-----Step Time 3.662 (3.187)-----Loss 4.5430 (3.3759)\n",
      "Epoch 3/21-----Batch 50496/59476-----Step 14120/100000-----Data Time 0.003 (0.005)-----Step Time 3.781 (3.189)-----Loss 4.0352 (3.3757)\n",
      "Epoch 3/21-----Batch 50736/59476-----Step 14140/100000-----Data Time 0.005 (0.005)-----Step Time 3.391 (3.191)-----Loss 2.7900 (3.3753)\n",
      "Epoch 3/21-----Batch 50976/59476-----Step 14160/100000-----Data Time 0.005 (0.005)-----Step Time 3.421 (3.192)-----Loss 2.7931 (3.3750)\n",
      "Epoch 3/21-----Batch 51216/59476-----Step 14180/100000-----Data Time 0.003 (0.005)-----Step Time 3.418 (3.193)-----Loss 3.6633 (3.3748)\n",
      "Epoch 3/21-----Batch 51456/59476-----Step 14200/100000-----Data Time 0.004 (0.005)-----Step Time 3.366 (3.194)-----Loss 3.1649 (3.3743)\n",
      "Epoch 3/21-----Batch 51696/59476-----Step 14220/100000-----Data Time 0.003 (0.005)-----Step Time 3.522 (3.195)-----Loss 3.8185 (3.3741)\n",
      "Epoch 3/21-----Batch 51936/59476-----Step 14240/100000-----Data Time 0.003 (0.005)-----Step Time 3.429 (3.196)-----Loss 3.1931 (3.3737)\n",
      "Epoch 3/21-----Batch 52176/59476-----Step 14260/100000-----Data Time 0.004 (0.005)-----Step Time 3.469 (3.198)-----Loss 2.7834 (3.3733)\n",
      "Epoch 3/21-----Batch 52416/59476-----Step 14280/100000-----Data Time 0.004 (0.005)-----Step Time 3.326 (3.199)-----Loss 3.3812 (3.3731)\n",
      "Epoch 3/21-----Batch 52656/59476-----Step 14300/100000-----Data Time 0.003 (0.005)-----Step Time 3.433 (3.200)-----Loss 2.7498 (3.3730)\n",
      "Epoch 3/21-----Batch 52896/59476-----Step 14320/100000-----Data Time 0.004 (0.005)-----Step Time 3.365 (3.201)-----Loss 2.6926 (3.3724)\n",
      "Epoch 3/21-----Batch 53136/59476-----Step 14340/100000-----Data Time 0.003 (0.005)-----Step Time 3.431 (3.202)-----Loss 3.6966 (3.3724)\n",
      "Epoch 3/21-----Batch 53376/59476-----Step 14360/100000-----Data Time 0.004 (0.005)-----Step Time 3.527 (3.203)-----Loss 4.5449 (3.3720)\n",
      "Epoch 3/21-----Batch 53616/59476-----Step 14380/100000-----Data Time 0.005 (0.005)-----Step Time 3.417 (3.204)-----Loss 4.3316 (3.3717)\n",
      "Epoch 3/21-----Batch 53856/59476-----Step 14400/100000-----Data Time 0.004 (0.005)-----Step Time 3.160 (3.204)-----Loss 3.1514 (3.3715)\n",
      "Epoch 3/21-----Batch 54096/59476-----Step 14420/100000-----Data Time 0.003 (0.005)-----Step Time 3.135 (3.204)-----Loss 4.5065 (3.3712)\n",
      "Epoch 3/21-----Batch 54336/59476-----Step 14440/100000-----Data Time 0.004 (0.005)-----Step Time 3.039 (3.204)-----Loss 3.2131 (3.3709)\n",
      "Epoch 3/21-----Batch 54576/59476-----Step 14460/100000-----Data Time 0.005 (0.005)-----Step Time 3.105 (3.204)-----Loss 2.7465 (3.3710)\n",
      "Epoch 3/21-----Batch 54816/59476-----Step 14480/100000-----Data Time 0.003 (0.005)-----Step Time 3.209 (3.204)-----Loss 4.5111 (3.3706)\n",
      "Epoch 3/21-----Batch 55056/59476-----Step 14500/100000-----Data Time 0.003 (0.005)-----Step Time 3.112 (3.203)-----Loss 3.8743 (3.3707)\n",
      "Epoch 3/21-----Batch 55296/59476-----Step 14520/100000-----Data Time 0.005 (0.005)-----Step Time 3.102 (3.203)-----Loss 3.0933 (3.3703)\n",
      "Epoch 3/21-----Batch 55536/59476-----Step 14540/100000-----Data Time 0.004 (0.005)-----Step Time 3.188 (3.203)-----Loss 3.3035 (3.3700)\n",
      "Epoch 3/21-----Batch 55776/59476-----Step 14560/100000-----Data Time 0.004 (0.005)-----Step Time 3.143 (3.203)-----Loss 2.6236 (3.3697)\n",
      "Epoch 3/21-----Batch 56016/59476-----Step 14580/100000-----Data Time 0.004 (0.005)-----Step Time 3.185 (3.202)-----Loss 3.4197 (3.3693)\n",
      "Epoch 3/21-----Batch 56256/59476-----Step 14600/100000-----Data Time 0.004 (0.005)-----Step Time 3.090 (3.202)-----Loss 4.3359 (3.3690)\n",
      "Epoch 3/21-----Batch 56496/59476-----Step 14620/100000-----Data Time 0.004 (0.005)-----Step Time 3.143 (3.202)-----Loss 3.0705 (3.3687)\n",
      "Epoch 3/21-----Batch 56736/59476-----Step 14640/100000-----Data Time 0.003 (0.005)-----Step Time 3.127 (3.201)-----Loss 3.3137 (3.3680)\n",
      "Epoch 3/21-----Batch 56976/59476-----Step 14660/100000-----Data Time 0.003 (0.005)-----Step Time 3.052 (3.201)-----Loss 4.3911 (3.3674)\n",
      "Epoch 3/21-----Batch 57216/59476-----Step 14680/100000-----Data Time 0.003 (0.005)-----Step Time 3.044 (3.201)-----Loss 3.1373 (3.3670)\n",
      "Epoch 3/21-----Batch 57456/59476-----Step 14700/100000-----Data Time 0.003 (0.005)-----Step Time 3.156 (3.201)-----Loss 3.0257 (3.3667)\n",
      "Epoch 3/21-----Batch 57696/59476-----Step 14720/100000-----Data Time 0.003 (0.005)-----Step Time 3.183 (3.200)-----Loss 2.9690 (3.3664)\n",
      "Epoch 3/21-----Batch 57936/59476-----Step 14740/100000-----Data Time 0.003 (0.005)-----Step Time 3.250 (3.200)-----Loss 3.0063 (3.3661)\n",
      "Epoch 3/21-----Batch 58176/59476-----Step 14760/100000-----Data Time 0.003 (0.005)-----Step Time 3.100 (3.200)-----Loss 2.6498 (3.3658)\n",
      "Epoch 3/21-----Batch 58416/59476-----Step 14780/100000-----Data Time 0.004 (0.005)-----Step Time 3.128 (3.200)-----Loss 4.7659 (3.3655)\n",
      "Epoch 3/21-----Batch 58656/59476-----Step 14800/100000-----Data Time 0.005 (0.005)-----Step Time 3.672 (3.199)-----Loss 3.0839 (3.3654)\n",
      "Epoch 3/21-----Batch 58896/59476-----Step 14820/100000-----Data Time 0.003 (0.005)-----Step Time 3.154 (3.199)-----Loss 3.2081 (3.3653)\n",
      "Epoch 3/21-----Batch 59136/59476-----Step 14840/100000-----Data Time 0.003 (0.005)-----Step Time 3.070 (3.199)-----Loss 2.5965 (3.3651)\n",
      "Epoch 3/21-----Batch 59376/59476-----Step 14860/100000-----Data Time 0.004 (0.005)-----Step Time 3.113 (3.199)-----Loss 2.9968 (3.3646)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:36<00:00, 81.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss: 3.278\n",
      "\n",
      "\n",
      " Epoch #  3\n",
      "Epoch 4/21-----Batch 132/59476-----Step 14880/100000-----Data Time 0.003 (0.004)-----Step Time 3.068 (3.005)-----Loss 2.4667 (3.1923)\n",
      "Epoch 4/21-----Batch 372/59476-----Step 14900/100000-----Data Time 0.003 (0.005)-----Step Time 3.096 (3.078)-----Loss 3.4567 (3.2843)\n",
      "Epoch 4/21-----Batch 612/59476-----Step 14920/100000-----Data Time 0.003 (0.005)-----Step Time 3.063 (3.094)-----Loss 3.2776 (3.2627)\n",
      "Epoch 4/21-----Batch 852/59476-----Step 14940/100000-----Data Time 0.004 (0.005)-----Step Time 3.318 (3.102)-----Loss 2.9825 (3.2572)\n",
      "Epoch 4/21-----Batch 1092/59476-----Step 14960/100000-----Data Time 0.003 (0.005)-----Step Time 3.093 (3.110)-----Loss 4.2817 (3.2493)\n",
      "Epoch 4/21-----Batch 1332/59476-----Step 14980/100000-----Data Time 0.004 (0.005)-----Step Time 3.118 (3.114)-----Loss 2.7308 (3.2501)\n",
      "Epoch 4/21-----Batch 1572/59476-----Step 15000/100000-----Data Time 0.003 (0.005)-----Step Time 3.028 (3.116)-----Loss 3.0558 (3.2472)\n",
      "Epoch 4/21-----Batch 1812/59476-----Step 15020/100000-----Data Time 0.003 (0.005)-----Step Time 3.096 (3.118)-----Loss 3.4348 (3.2399)\n",
      "Epoch 4/21-----Batch 2052/59476-----Step 15040/100000-----Data Time 0.003 (0.005)-----Step Time 3.007 (3.117)-----Loss 3.4422 (3.2432)\n",
      "Epoch 4/21-----Batch 2292/59476-----Step 15060/100000-----Data Time 0.003 (0.005)-----Step Time 3.102 (3.123)-----Loss 2.5899 (3.2432)\n",
      "Epoch 4/21-----Batch 2532/59476-----Step 15080/100000-----Data Time 0.007 (0.005)-----Step Time 3.059 (3.125)-----Loss 3.3814 (3.2403)\n",
      "Epoch 4/21-----Batch 2772/59476-----Step 15100/100000-----Data Time 0.004 (0.005)-----Step Time 3.049 (3.124)-----Loss 2.9098 (3.2402)\n",
      "Epoch 4/21-----Batch 3012/59476-----Step 15120/100000-----Data Time 0.004 (0.005)-----Step Time 3.119 (3.125)-----Loss 3.0862 (3.2445)\n",
      "Epoch 4/21-----Batch 3252/59476-----Step 15140/100000-----Data Time 0.004 (0.005)-----Step Time 3.099 (3.125)-----Loss 3.4642 (3.2494)\n",
      "Epoch 4/21-----Batch 3492/59476-----Step 15160/100000-----Data Time 0.003 (0.005)-----Step Time 3.078 (3.124)-----Loss 3.1104 (3.2508)\n",
      "Epoch 4/21-----Batch 3732/59476-----Step 15180/100000-----Data Time 0.003 (0.005)-----Step Time 3.129 (3.124)-----Loss 3.1804 (3.2499)\n",
      "Epoch 4/21-----Batch 3972/59476-----Step 15200/100000-----Data Time 0.004 (0.005)-----Step Time 3.114 (3.126)-----Loss 3.0706 (3.2506)\n",
      "Epoch 4/21-----Batch 4212/59476-----Step 15220/100000-----Data Time 0.003 (0.005)-----Step Time 3.516 (3.127)-----Loss 2.5574 (3.2483)\n",
      "Epoch 4/21-----Batch 4452/59476-----Step 15240/100000-----Data Time 0.004 (0.005)-----Step Time 3.130 (3.128)-----Loss 4.6279 (3.2522)\n",
      "Epoch 4/21-----Batch 4692/59476-----Step 15260/100000-----Data Time 0.004 (0.005)-----Step Time 3.089 (3.128)-----Loss 3.3592 (3.2484)\n",
      "Epoch 4/21-----Batch 4932/59476-----Step 15280/100000-----Data Time 0.003 (0.005)-----Step Time 3.151 (3.130)-----Loss 3.9843 (3.2472)\n",
      "Epoch 4/21-----Batch 5172/59476-----Step 15300/100000-----Data Time 0.003 (0.005)-----Step Time 3.489 (3.131)-----Loss 2.5463 (3.2472)\n",
      "Epoch 4/21-----Batch 5412/59476-----Step 15320/100000-----Data Time 0.003 (0.005)-----Step Time 3.147 (3.132)-----Loss 2.9747 (3.2460)\n",
      "Epoch 4/21-----Batch 5652/59476-----Step 15340/100000-----Data Time 0.003 (0.005)-----Step Time 3.164 (3.131)-----Loss 3.1891 (3.2467)\n",
      "Epoch 4/21-----Batch 5892/59476-----Step 15360/100000-----Data Time 0.004 (0.005)-----Step Time 3.203 (3.132)-----Loss 3.1940 (3.2466)\n",
      "Epoch 4/21-----Batch 6132/59476-----Step 15380/100000-----Data Time 0.003 (0.005)-----Step Time 3.259 (3.132)-----Loss 3.4181 (3.2471)\n",
      "Epoch 4/21-----Batch 6372/59476-----Step 15400/100000-----Data Time 0.003 (0.005)-----Step Time 3.063 (3.132)-----Loss 4.9157 (3.2467)\n",
      "Epoch 4/21-----Batch 6612/59476-----Step 15420/100000-----Data Time 0.003 (0.005)-----Step Time 3.151 (3.131)-----Loss 3.2226 (3.2481)\n",
      "Epoch 4/21-----Batch 6852/59476-----Step 15440/100000-----Data Time 0.004 (0.005)-----Step Time 2.993 (3.130)-----Loss 3.0105 (3.2488)\n",
      "Epoch 4/21-----Batch 7092/59476-----Step 15460/100000-----Data Time 0.003 (0.005)-----Step Time 3.053 (3.130)-----Loss 2.4458 (3.2482)\n",
      "Epoch 4/21-----Batch 7332/59476-----Step 15480/100000-----Data Time 0.003 (0.005)-----Step Time 3.321 (3.130)-----Loss 3.1238 (3.2479)\n",
      "Epoch 4/21-----Batch 7572/59476-----Step 15500/100000-----Data Time 0.004 (0.005)-----Step Time 3.062 (3.130)-----Loss 2.9198 (3.2472)\n",
      "Epoch 4/21-----Batch 7812/59476-----Step 15520/100000-----Data Time 0.004 (0.005)-----Step Time 3.117 (3.130)-----Loss 3.1582 (3.2458)\n",
      "Epoch 4/21-----Batch 8052/59476-----Step 15540/100000-----Data Time 0.003 (0.005)-----Step Time 3.111 (3.129)-----Loss 3.5146 (3.2443)\n",
      "Epoch 4/21-----Batch 8292/59476-----Step 15560/100000-----Data Time 0.003 (0.005)-----Step Time 3.265 (3.130)-----Loss 2.5806 (3.2437)\n",
      "Epoch 4/21-----Batch 8532/59476-----Step 15580/100000-----Data Time 0.004 (0.005)-----Step Time 3.174 (3.130)-----Loss 3.3676 (3.2443)\n",
      "Epoch 4/21-----Batch 8772/59476-----Step 15600/100000-----Data Time 0.003 (0.005)-----Step Time 3.228 (3.130)-----Loss 4.4649 (3.2443)\n",
      "Epoch 4/21-----Batch 9012/59476-----Step 15620/100000-----Data Time 0.003 (0.005)-----Step Time 3.105 (3.130)-----Loss 4.7905 (3.2439)\n",
      "Epoch 4/21-----Batch 9252/59476-----Step 15640/100000-----Data Time 0.003 (0.005)-----Step Time 3.131 (3.130)-----Loss 3.1874 (3.2452)\n",
      "Epoch 4/21-----Batch 9492/59476-----Step 15660/100000-----Data Time 0.003 (0.005)-----Step Time 3.189 (3.130)-----Loss 2.9586 (3.2433)\n",
      "Epoch 4/21-----Batch 9732/59476-----Step 15680/100000-----Data Time 0.007 (0.005)-----Step Time 3.004 (3.130)-----Loss 2.5657 (3.2423)\n",
      "Epoch 4/21-----Batch 9972/59476-----Step 15700/100000-----Data Time 0.003 (0.005)-----Step Time 3.130 (3.130)-----Loss 2.9926 (3.2431)\n",
      "Epoch 4/21-----Batch 10212/59476-----Step 15720/100000-----Data Time 0.004 (0.005)-----Step Time 3.179 (3.130)-----Loss 3.2473 (3.2432)\n",
      "Epoch 4/21-----Batch 10452/59476-----Step 15740/100000-----Data Time 0.003 (0.005)-----Step Time 3.163 (3.130)-----Loss 4.9196 (3.2434)\n",
      "Epoch 4/21-----Batch 10692/59476-----Step 15760/100000-----Data Time 0.005 (0.005)-----Step Time 3.154 (3.129)-----Loss 2.9143 (3.2433)\n",
      "Epoch 4/21-----Batch 10932/59476-----Step 15780/100000-----Data Time 0.003 (0.005)-----Step Time 3.058 (3.129)-----Loss 3.9026 (3.2441)\n",
      "Epoch 4/21-----Batch 11172/59476-----Step 15800/100000-----Data Time 0.006 (0.005)-----Step Time 3.097 (3.129)-----Loss 2.9510 (3.2434)\n",
      "Epoch 4/21-----Batch 11412/59476-----Step 15820/100000-----Data Time 0.003 (0.005)-----Step Time 3.147 (3.129)-----Loss 2.1168 (3.2449)\n",
      "Epoch 4/21-----Batch 11652/59476-----Step 15840/100000-----Data Time 0.003 (0.005)-----Step Time 3.274 (3.130)-----Loss 3.6904 (3.2452)\n",
      "Epoch 4/21-----Batch 11892/59476-----Step 15860/100000-----Data Time 0.009 (0.005)-----Step Time 3.140 (3.129)-----Loss 2.8658 (3.2446)\n",
      "Epoch 4/21-----Batch 12132/59476-----Step 15880/100000-----Data Time 0.003 (0.005)-----Step Time 3.098 (3.129)-----Loss 2.6812 (3.2461)\n",
      "Epoch 4/21-----Batch 12372/59476-----Step 15900/100000-----Data Time 0.003 (0.005)-----Step Time 3.390 (3.130)-----Loss 2.7285 (3.2464)\n",
      "Epoch 4/21-----Batch 12612/59476-----Step 15920/100000-----Data Time 0.003 (0.005)-----Step Time 3.656 (3.140)-----Loss 3.3694 (3.2464)\n",
      "Epoch 4/21-----Batch 12852/59476-----Step 15940/100000-----Data Time 0.004 (0.005)-----Step Time 3.702 (3.150)-----Loss 2.9636 (3.2476)\n",
      "Epoch 4/21-----Batch 13092/59476-----Step 15960/100000-----Data Time 0.003 (0.005)-----Step Time 3.387 (3.157)-----Loss 2.4678 (3.2475)\n",
      "Epoch 4/21-----Batch 13332/59476-----Step 15980/100000-----Data Time 0.005 (0.005)-----Step Time 3.477 (3.163)-----Loss 2.5599 (3.2471)\n",
      "Epoch 4/21-----Batch 13572/59476-----Step 16000/100000-----Data Time 0.003 (0.005)-----Step Time 3.546 (3.171)-----Loss 2.6970 (3.2472)\n",
      "Epoch 4/21-----Batch 13812/59476-----Step 16020/100000-----Data Time 0.004 (0.005)-----Step Time 3.681 (3.180)-----Loss 2.6291 (3.2472)\n",
      "Epoch 4/21-----Batch 14052/59476-----Step 16040/100000-----Data Time 0.004 (0.005)-----Step Time 3.766 (3.187)-----Loss 3.7638 (3.2466)\n",
      "Epoch 4/21-----Batch 14292/59476-----Step 16060/100000-----Data Time 0.003 (0.005)-----Step Time 3.546 (3.198)-----Loss 2.6814 (3.2464)\n",
      "Epoch 4/21-----Batch 14532/59476-----Step 16080/100000-----Data Time 0.004 (0.005)-----Step Time 4.106 (3.209)-----Loss 3.1220 (3.2463)\n",
      "Epoch 4/21-----Batch 14772/59476-----Step 16100/100000-----Data Time 0.004 (0.005)-----Step Time 3.868 (3.218)-----Loss 3.4032 (3.2462)\n",
      "Epoch 4/21-----Batch 15012/59476-----Step 16120/100000-----Data Time 0.003 (0.005)-----Step Time 3.482 (3.224)-----Loss 3.4001 (3.2454)\n",
      "Epoch 4/21-----Batch 15252/59476-----Step 16140/100000-----Data Time 0.005 (0.005)-----Step Time 3.605 (3.229)-----Loss 2.9133 (3.2460)\n",
      "Epoch 4/21-----Batch 15492/59476-----Step 16160/100000-----Data Time 0.006 (0.005)-----Step Time 3.594 (3.234)-----Loss 3.5870 (3.2463)\n",
      "Epoch 4/21-----Batch 15732/59476-----Step 16180/100000-----Data Time 0.003 (0.005)-----Step Time 3.442 (3.238)-----Loss 2.7689 (3.2457)\n",
      "Epoch 4/21-----Batch 15972/59476-----Step 16200/100000-----Data Time 0.007 (0.005)-----Step Time 3.925 (3.248)-----Loss 4.0739 (3.2458)\n",
      "Epoch 4/21-----Batch 16212/59476-----Step 16220/100000-----Data Time 0.010 (0.005)-----Step Time 3.816 (3.260)-----Loss 3.3268 (3.2459)\n",
      "Epoch 4/21-----Batch 16452/59476-----Step 16240/100000-----Data Time 0.004 (0.005)-----Step Time 3.450 (3.264)-----Loss 2.6587 (3.2448)\n",
      "Epoch 4/21-----Batch 16692/59476-----Step 16260/100000-----Data Time 0.003 (0.005)-----Step Time 3.411 (3.267)-----Loss 3.0051 (3.2442)\n",
      "Epoch 4/21-----Batch 16932/59476-----Step 16280/100000-----Data Time 0.003 (0.005)-----Step Time 3.344 (3.269)-----Loss 3.8480 (3.2442)\n",
      "Epoch 4/21-----Batch 17172/59476-----Step 16300/100000-----Data Time 0.003 (0.005)-----Step Time 3.410 (3.271)-----Loss 2.6775 (3.2455)\n",
      "Epoch 4/21-----Batch 17412/59476-----Step 16320/100000-----Data Time 0.006 (0.005)-----Step Time 3.174 (3.273)-----Loss 3.0491 (3.2450)\n",
      "Epoch 4/21-----Batch 17652/59476-----Step 16340/100000-----Data Time 0.003 (0.005)-----Step Time 4.264 (3.278)-----Loss 2.7372 (3.2447)\n",
      "Epoch 4/21-----Batch 17892/59476-----Step 16360/100000-----Data Time 0.005 (0.005)-----Step Time 4.259 (3.290)-----Loss 2.9922 (3.2458)\n",
      "Epoch 4/21-----Batch 18132/59476-----Step 16380/100000-----Data Time 0.003 (0.005)-----Step Time 4.047 (3.303)-----Loss 2.7698 (3.2463)\n",
      "Epoch 4/21-----Batch 18372/59476-----Step 16400/100000-----Data Time 0.003 (0.005)-----Step Time 3.929 (3.313)-----Loss 2.8620 (3.2460)\n",
      "Epoch 4/21-----Batch 18612/59476-----Step 16420/100000-----Data Time 0.005 (0.005)-----Step Time 3.964 (3.321)-----Loss 2.9399 (3.2456)\n",
      "Epoch 4/21-----Batch 18852/59476-----Step 16440/100000-----Data Time 0.003 (0.005)-----Step Time 3.905 (3.329)-----Loss 3.5880 (3.2459)\n",
      "Epoch 4/21-----Batch 19092/59476-----Step 16460/100000-----Data Time 0.004 (0.005)-----Step Time 4.147 (3.339)-----Loss 3.0975 (3.2460)\n",
      "Epoch 4/21-----Batch 19332/59476-----Step 16480/100000-----Data Time 0.004 (0.005)-----Step Time 3.989 (3.349)-----Loss 2.8305 (3.2462)\n",
      "Epoch 4/21-----Batch 19572/59476-----Step 16500/100000-----Data Time 0.004 (0.005)-----Step Time 4.128 (3.358)-----Loss 3.0761 (3.2460)\n",
      "Epoch 4/21-----Batch 19812/59476-----Step 16520/100000-----Data Time 0.003 (0.006)-----Step Time 3.627 (3.791)-----Loss 3.1025 (3.2458)\n",
      "Epoch 4/21-----Batch 20052/59476-----Step 16540/100000-----Data Time 0.006 (0.006)-----Step Time 4.212 (3.793)-----Loss 3.0422 (3.2456)\n",
      "Epoch 4/21-----Batch 20292/59476-----Step 16560/100000-----Data Time 0.003 (0.006)-----Step Time 3.884 (3.796)-----Loss 2.9729 (3.2454)\n",
      "Epoch 4/21-----Batch 20532/59476-----Step 16580/100000-----Data Time 0.004 (0.006)-----Step Time 3.485 (3.896)-----Loss 3.2534 (3.2452)\n",
      "Epoch 4/21-----Batch 20772/59476-----Step 16600/100000-----Data Time 0.003 (0.006)-----Step Time 4.248 (3.899)-----Loss 3.5153 (3.2448)\n",
      "Epoch 4/21-----Batch 21012/59476-----Step 16620/100000-----Data Time 0.008 (0.006)-----Step Time 4.295 (3.901)-----Loss 3.7542 (3.2454)\n",
      "Epoch 4/21-----Batch 21252/59476-----Step 16640/100000-----Data Time 0.003 (0.006)-----Step Time 3.262 (3.893)-----Loss 3.9498 (3.2453)\n",
      "Epoch 4/21-----Batch 21492/59476-----Step 16660/100000-----Data Time 0.004 (0.006)-----Step Time 4.069 (3.891)-----Loss 3.1363 (3.2456)\n",
      "Epoch 4/21-----Batch 21732/59476-----Step 16680/100000-----Data Time 0.006 (0.006)-----Step Time 4.230 (3.893)-----Loss 2.9482 (3.2451)\n",
      "Epoch 4/21-----Batch 21972/59476-----Step 16700/100000-----Data Time 0.004 (0.006)-----Step Time 4.185 (3.896)-----Loss 2.8196 (3.2446)\n",
      "Epoch 4/21-----Batch 22212/59476-----Step 16720/100000-----Data Time 0.003 (0.006)-----Step Time 3.943 (3.899)-----Loss 2.7454 (3.2440)\n",
      "Epoch 4/21-----Batch 22452/59476-----Step 16740/100000-----Data Time 0.003 (0.006)-----Step Time 3.003 (3.894)-----Loss 3.8087 (3.2444)\n",
      "Epoch 4/21-----Batch 22692/59476-----Step 16760/100000-----Data Time 0.003 (0.006)-----Step Time 3.102 (3.886)-----Loss 2.6911 (3.2440)\n",
      "Epoch 4/21-----Batch 22932/59476-----Step 16780/100000-----Data Time 0.004 (0.006)-----Step Time 3.116 (3.878)-----Loss 2.6294 (3.2435)\n",
      "Epoch 4/21-----Batch 23172/59476-----Step 16800/100000-----Data Time 0.004 (0.006)-----Step Time 3.230 (3.870)-----Loss 4.2614 (3.2435)\n",
      "Epoch 4/21-----Batch 23412/59476-----Step 16820/100000-----Data Time 0.003 (0.006)-----Step Time 2.995 (3.862)-----Loss 3.3462 (3.2432)\n",
      "Epoch 4/21-----Batch 23652/59476-----Step 16840/100000-----Data Time 0.003 (0.006)-----Step Time 3.054 (3.855)-----Loss 3.4074 (3.2433)\n",
      "Epoch 4/21-----Batch 23892/59476-----Step 16860/100000-----Data Time 0.003 (0.006)-----Step Time 3.061 (3.847)-----Loss 2.6561 (3.2427)\n",
      "Epoch 4/21-----Batch 24132/59476-----Step 16880/100000-----Data Time 0.003 (0.006)-----Step Time 3.173 (3.840)-----Loss 2.8749 (3.2428)\n",
      "Epoch 4/21-----Batch 24372/59476-----Step 16900/100000-----Data Time 0.003 (0.006)-----Step Time 3.130 (3.833)-----Loss 3.3737 (3.2421)\n",
      "Epoch 4/21-----Batch 24612/59476-----Step 16920/100000-----Data Time 0.003 (0.006)-----Step Time 3.086 (3.826)-----Loss 3.3458 (3.2421)\n",
      "Epoch 4/21-----Batch 24852/59476-----Step 16940/100000-----Data Time 0.005 (0.006)-----Step Time 3.099 (3.819)-----Loss 2.8109 (3.2424)\n",
      "Epoch 4/21-----Batch 25092/59476-----Step 16960/100000-----Data Time 0.003 (0.006)-----Step Time 3.065 (3.813)-----Loss 3.1233 (3.2418)\n",
      "Epoch 4/21-----Batch 25332/59476-----Step 16980/100000-----Data Time 0.004 (0.006)-----Step Time 3.037 (3.806)-----Loss 3.9261 (3.2415)\n",
      "Epoch 4/21-----Batch 25572/59476-----Step 17000/100000-----Data Time 0.003 (0.006)-----Step Time 3.141 (3.800)-----Loss 2.9390 (3.2415)\n",
      "Epoch 4/21-----Batch 25812/59476-----Step 17020/100000-----Data Time 0.003 (0.006)-----Step Time 3.164 (3.794)-----Loss 3.3906 (3.2415)\n",
      "Epoch 4/21-----Batch 26052/59476-----Step 17040/100000-----Data Time 0.003 (0.006)-----Step Time 3.107 (3.787)-----Loss 2.7783 (3.2417)\n",
      "Epoch 4/21-----Batch 26292/59476-----Step 17060/100000-----Data Time 0.003 (0.006)-----Step Time 3.051 (3.781)-----Loss 2.6289 (3.2420)\n",
      "Epoch 4/21-----Batch 26532/59476-----Step 17080/100000-----Data Time 0.004 (0.006)-----Step Time 3.033 (3.776)-----Loss 2.9434 (3.2423)\n",
      "Epoch 4/21-----Batch 26772/59476-----Step 17100/100000-----Data Time 0.003 (0.006)-----Step Time 3.000 (3.770)-----Loss 2.6576 (3.2420)\n",
      "Epoch 4/21-----Batch 27012/59476-----Step 17120/100000-----Data Time 0.003 (0.006)-----Step Time 3.274 (3.764)-----Loss 3.6526 (3.2422)\n",
      "Epoch 4/21-----Batch 27252/59476-----Step 17140/100000-----Data Time 0.002 (0.006)-----Step Time 3.361 (3.759)-----Loss 4.1908 (3.2419)\n",
      "Epoch 4/21-----Batch 27492/59476-----Step 17160/100000-----Data Time 0.003 (0.006)-----Step Time 3.240 (3.753)-----Loss 2.9586 (3.2416)\n",
      "Epoch 4/21-----Batch 27732/59476-----Step 17180/100000-----Data Time 0.003 (0.006)-----Step Time 3.140 (3.748)-----Loss 3.8014 (3.2419)\n",
      "Epoch 4/21-----Batch 27972/59476-----Step 17200/100000-----Data Time 0.003 (0.006)-----Step Time 3.121 (3.743)-----Loss 2.5421 (3.2416)\n",
      "Epoch 4/21-----Batch 28212/59476-----Step 17220/100000-----Data Time 0.003 (0.006)-----Step Time 3.139 (3.738)-----Loss 3.4237 (3.2417)\n",
      "Epoch 4/21-----Batch 28452/59476-----Step 17240/100000-----Data Time 0.003 (0.006)-----Step Time 3.049 (3.732)-----Loss 2.8960 (3.2410)\n",
      "Epoch 4/21-----Batch 28692/59476-----Step 17260/100000-----Data Time 0.003 (0.006)-----Step Time 3.063 (3.727)-----Loss 3.4872 (3.2412)\n",
      "Epoch 4/21-----Batch 28932/59476-----Step 17280/100000-----Data Time 0.003 (0.006)-----Step Time 3.126 (3.722)-----Loss 2.6933 (3.2410)\n",
      "Epoch 4/21-----Batch 29172/59476-----Step 17300/100000-----Data Time 0.004 (0.006)-----Step Time 3.098 (3.717)-----Loss 3.2914 (3.2408)\n",
      "Epoch 4/21-----Batch 29412/59476-----Step 17320/100000-----Data Time 0.003 (0.006)-----Step Time 3.044 (3.713)-----Loss 4.3994 (3.2414)\n",
      "Epoch 4/21-----Batch 29652/59476-----Step 17340/100000-----Data Time 0.003 (0.006)-----Step Time 3.152 (3.708)-----Loss 4.7946 (3.2412)\n",
      "Epoch 4/21-----Batch 29892/59476-----Step 17360/100000-----Data Time 0.003 (0.006)-----Step Time 3.076 (3.703)-----Loss 3.7635 (3.2411)\n",
      "Epoch 4/21-----Batch 30132/59476-----Step 17380/100000-----Data Time 0.003 (0.006)-----Step Time 3.141 (3.699)-----Loss 4.2930 (3.2409)\n",
      "Epoch 4/21-----Batch 30372/59476-----Step 17400/100000-----Data Time 0.004 (0.006)-----Step Time 3.249 (3.694)-----Loss 2.7423 (3.2408)\n",
      "Epoch 4/21-----Batch 30612/59476-----Step 17420/100000-----Data Time 0.003 (0.006)-----Step Time 3.168 (3.690)-----Loss 3.0770 (3.2410)\n",
      "Epoch 4/21-----Batch 30852/59476-----Step 17440/100000-----Data Time 0.002 (0.006)-----Step Time 2.991 (3.685)-----Loss 3.7595 (3.2414)\n",
      "Epoch 4/21-----Batch 31092/59476-----Step 17460/100000-----Data Time 0.004 (0.006)-----Step Time 3.093 (3.681)-----Loss 2.8805 (3.2411)\n",
      "Epoch 4/21-----Batch 31332/59476-----Step 17480/100000-----Data Time 0.003 (0.006)-----Step Time 3.136 (3.677)-----Loss 4.6384 (3.2407)\n",
      "Epoch 4/21-----Batch 31572/59476-----Step 17500/100000-----Data Time 0.003 (0.006)-----Step Time 3.252 (3.673)-----Loss 3.0831 (3.2407)\n",
      "Epoch 4/21-----Batch 31812/59476-----Step 17520/100000-----Data Time 0.003 (0.006)-----Step Time 3.179 (3.668)-----Loss 3.0695 (3.2406)\n",
      "Epoch 4/21-----Batch 32052/59476-----Step 17540/100000-----Data Time 0.002 (0.006)-----Step Time 3.042 (3.664)-----Loss 4.2256 (3.2403)\n",
      "Epoch 4/21-----Batch 32292/59476-----Step 17560/100000-----Data Time 0.003 (0.006)-----Step Time 3.191 (3.660)-----Loss 3.0126 (3.2398)\n",
      "Epoch 4/21-----Batch 32532/59476-----Step 17580/100000-----Data Time 0.003 (0.005)-----Step Time 3.193 (3.656)-----Loss 3.4236 (3.2400)\n",
      "Epoch 4/21-----Batch 32772/59476-----Step 17600/100000-----Data Time 0.005 (0.005)-----Step Time 3.030 (3.652)-----Loss 2.9289 (3.2400)\n",
      "Epoch 4/21-----Batch 33012/59476-----Step 17620/100000-----Data Time 0.004 (0.005)-----Step Time 3.137 (3.649)-----Loss 3.3731 (3.2396)\n",
      "Epoch 4/21-----Batch 33252/59476-----Step 17640/100000-----Data Time 0.004 (0.005)-----Step Time 3.118 (3.645)-----Loss 3.4368 (3.2395)\n",
      "Epoch 4/21-----Batch 33492/59476-----Step 17660/100000-----Data Time 0.003 (0.005)-----Step Time 3.131 (3.641)-----Loss 3.4151 (3.2395)\n",
      "Epoch 4/21-----Batch 33732/59476-----Step 17680/100000-----Data Time 0.003 (0.005)-----Step Time 3.206 (3.637)-----Loss 2.7920 (3.2393)\n",
      "Epoch 4/21-----Batch 33972/59476-----Step 17700/100000-----Data Time 0.003 (0.005)-----Step Time 3.264 (3.634)-----Loss 2.9235 (3.2391)\n",
      "Epoch 4/21-----Batch 34212/59476-----Step 17720/100000-----Data Time 0.003 (0.005)-----Step Time 3.096 (3.631)-----Loss 2.6640 (3.2390)\n",
      "Epoch 4/21-----Batch 34452/59476-----Step 17740/100000-----Data Time 0.003 (0.005)-----Step Time 3.121 (3.627)-----Loss 4.1590 (3.2387)\n",
      "Epoch 4/21-----Batch 34692/59476-----Step 17760/100000-----Data Time 0.003 (0.005)-----Step Time 3.113 (3.624)-----Loss 3.0925 (3.2389)\n",
      "Epoch 4/21-----Batch 34932/59476-----Step 17780/100000-----Data Time 0.010 (0.005)-----Step Time 3.072 (3.620)-----Loss 2.8616 (3.2386)\n",
      "Epoch 4/21-----Batch 35172/59476-----Step 17800/100000-----Data Time 0.004 (0.005)-----Step Time 3.211 (3.617)-----Loss 3.1211 (3.2383)\n",
      "Epoch 4/21-----Batch 35412/59476-----Step 17820/100000-----Data Time 0.003 (0.005)-----Step Time 2.943 (3.614)-----Loss 2.5213 (3.2383)\n",
      "Epoch 4/21-----Batch 35652/59476-----Step 17840/100000-----Data Time 0.003 (0.005)-----Step Time 3.161 (3.610)-----Loss 2.6013 (3.2383)\n",
      "Epoch 4/21-----Batch 35892/59476-----Step 17860/100000-----Data Time 0.003 (0.005)-----Step Time 3.142 (3.607)-----Loss 2.9871 (3.2385)\n",
      "Epoch 4/21-----Batch 36132/59476-----Step 17880/100000-----Data Time 0.004 (0.005)-----Step Time 3.106 (3.604)-----Loss 3.2420 (3.2381)\n",
      "Epoch 4/21-----Batch 36372/59476-----Step 17900/100000-----Data Time 0.003 (0.005)-----Step Time 3.082 (3.601)-----Loss 2.5158 (3.2379)\n",
      "Epoch 4/21-----Batch 36612/59476-----Step 17920/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.598)-----Loss 3.4293 (3.2380)\n",
      "Epoch 4/21-----Batch 36852/59476-----Step 17940/100000-----Data Time 0.003 (0.005)-----Step Time 3.059 (3.595)-----Loss 3.7997 (3.2377)\n",
      "Epoch 4/21-----Batch 37092/59476-----Step 17960/100000-----Data Time 0.003 (0.005)-----Step Time 3.080 (3.591)-----Loss 3.6383 (3.2376)\n",
      "Epoch 4/21-----Batch 37332/59476-----Step 17980/100000-----Data Time 0.003 (0.005)-----Step Time 3.076 (3.588)-----Loss 2.5822 (3.2375)\n",
      "Epoch 4/21-----Batch 37572/59476-----Step 18000/100000-----Data Time 0.003 (0.005)-----Step Time 3.304 (3.586)-----Loss 3.4676 (3.2375)\n",
      "Epoch 4/21-----Batch 37812/59476-----Step 18020/100000-----Data Time 0.003 (0.005)-----Step Time 3.103 (3.583)-----Loss 3.4812 (3.2377)\n",
      "Epoch 4/21-----Batch 38052/59476-----Step 18040/100000-----Data Time 0.003 (0.005)-----Step Time 3.169 (3.580)-----Loss 3.4746 (3.2378)\n",
      "Epoch 4/21-----Batch 38292/59476-----Step 18060/100000-----Data Time 0.004 (0.005)-----Step Time 3.153 (3.577)-----Loss 2.9009 (3.2382)\n",
      "Epoch 4/21-----Batch 38532/59476-----Step 18080/100000-----Data Time 0.004 (0.005)-----Step Time 3.161 (3.575)-----Loss 2.6439 (3.2381)\n",
      "Epoch 4/21-----Batch 38772/59476-----Step 18100/100000-----Data Time 0.003 (0.005)-----Step Time 3.185 (3.572)-----Loss 2.8262 (3.2379)\n",
      "Epoch 4/21-----Batch 39012/59476-----Step 18120/100000-----Data Time 0.003 (0.005)-----Step Time 3.095 (3.569)-----Loss 2.9035 (3.2377)\n",
      "Epoch 4/21-----Batch 39252/59476-----Step 18140/100000-----Data Time 0.005 (0.005)-----Step Time 3.077 (3.566)-----Loss 2.7753 (3.2378)\n",
      "Epoch 4/21-----Batch 39492/59476-----Step 18160/100000-----Data Time 0.003 (0.005)-----Step Time 3.147 (3.564)-----Loss 2.7026 (3.2377)\n",
      "Epoch 4/21-----Batch 39732/59476-----Step 18180/100000-----Data Time 0.003 (0.005)-----Step Time 3.097 (3.561)-----Loss 3.8538 (3.2370)\n",
      "Epoch 4/21-----Batch 39972/59476-----Step 18200/100000-----Data Time 0.003 (0.005)-----Step Time 3.112 (3.559)-----Loss 3.2183 (3.2367)\n",
      "Epoch 4/21-----Batch 40212/59476-----Step 18220/100000-----Data Time 0.003 (0.005)-----Step Time 3.125 (3.556)-----Loss 4.3319 (3.2364)\n",
      "Epoch 4/21-----Batch 40452/59476-----Step 18240/100000-----Data Time 0.003 (0.005)-----Step Time 3.281 (3.553)-----Loss 2.6399 (3.2363)\n",
      "Epoch 4/21-----Batch 40692/59476-----Step 18260/100000-----Data Time 0.010 (0.005)-----Step Time 3.115 (3.551)-----Loss 4.0376 (3.2361)\n",
      "Epoch 4/21-----Batch 40932/59476-----Step 18280/100000-----Data Time 0.003 (0.005)-----Step Time 3.143 (3.549)-----Loss 3.4048 (3.2363)\n",
      "Epoch 4/21-----Batch 41172/59476-----Step 18300/100000-----Data Time 0.003 (0.005)-----Step Time 3.063 (3.546)-----Loss 3.1972 (3.2361)\n",
      "Epoch 4/21-----Batch 41412/59476-----Step 18320/100000-----Data Time 0.004 (0.005)-----Step Time 3.108 (3.544)-----Loss 3.4763 (3.2362)\n",
      "Epoch 4/21-----Batch 41652/59476-----Step 18340/100000-----Data Time 0.003 (0.005)-----Step Time 3.048 (3.541)-----Loss 3.5483 (3.2359)\n",
      "Epoch 4/21-----Batch 41892/59476-----Step 18360/100000-----Data Time 0.003 (0.005)-----Step Time 3.088 (3.539)-----Loss 2.9193 (3.2359)\n",
      "Epoch 4/21-----Batch 42132/59476-----Step 18380/100000-----Data Time 0.007 (0.005)-----Step Time 3.108 (3.537)-----Loss 1.7131 (3.2354)\n",
      "Epoch 4/21-----Batch 42372/59476-----Step 18400/100000-----Data Time 0.003 (0.005)-----Step Time 3.141 (3.534)-----Loss 3.3471 (3.2353)\n",
      "Epoch 4/21-----Batch 42612/59476-----Step 18420/100000-----Data Time 0.003 (0.005)-----Step Time 3.207 (3.532)-----Loss 3.2665 (3.2350)\n",
      "Epoch 4/21-----Batch 42852/59476-----Step 18440/100000-----Data Time 0.004 (0.005)-----Step Time 3.068 (3.530)-----Loss 3.3025 (3.2345)\n",
      "Epoch 4/21-----Batch 43092/59476-----Step 18460/100000-----Data Time 0.004 (0.005)-----Step Time 3.115 (3.528)-----Loss 4.4196 (3.2345)\n",
      "Epoch 4/21-----Batch 43332/59476-----Step 18480/100000-----Data Time 0.003 (0.005)-----Step Time 3.106 (3.525)-----Loss 3.2136 (3.2347)\n",
      "Epoch 4/21-----Batch 43572/59476-----Step 18500/100000-----Data Time 0.003 (0.005)-----Step Time 3.172 (3.523)-----Loss 3.7651 (3.2345)\n",
      "Epoch 4/21-----Batch 43812/59476-----Step 18520/100000-----Data Time 0.004 (0.005)-----Step Time 3.133 (3.521)-----Loss 3.2055 (3.2345)\n",
      "Epoch 4/21-----Batch 44052/59476-----Step 18540/100000-----Data Time 0.003 (0.005)-----Step Time 3.077 (3.519)-----Loss 4.6451 (3.2344)\n",
      "Epoch 4/21-----Batch 44292/59476-----Step 18560/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.517)-----Loss 3.1773 (3.2343)\n",
      "Epoch 4/21-----Batch 44532/59476-----Step 18580/100000-----Data Time 0.003 (0.005)-----Step Time 3.118 (3.515)-----Loss 3.0364 (3.2344)\n",
      "Epoch 4/21-----Batch 44772/59476-----Step 18600/100000-----Data Time 0.005 (0.005)-----Step Time 3.014 (3.512)-----Loss 2.9708 (3.2345)\n",
      "Epoch 4/21-----Batch 45012/59476-----Step 18620/100000-----Data Time 0.005 (0.005)-----Step Time 3.152 (3.510)-----Loss 2.7081 (3.2344)\n",
      "Epoch 4/21-----Batch 45252/59476-----Step 18640/100000-----Data Time 0.003 (0.005)-----Step Time 3.113 (3.508)-----Loss 2.9073 (3.2341)\n",
      "Epoch 4/21-----Batch 45492/59476-----Step 18660/100000-----Data Time 0.003 (0.005)-----Step Time 3.037 (3.506)-----Loss 3.5909 (3.2340)\n",
      "Epoch 4/21-----Batch 45732/59476-----Step 18680/100000-----Data Time 0.004 (0.005)-----Step Time 3.113 (3.504)-----Loss 2.8300 (3.2342)\n",
      "Epoch 4/21-----Batch 45972/59476-----Step 18700/100000-----Data Time 0.003 (0.005)-----Step Time 3.083 (3.502)-----Loss 3.2020 (3.2340)\n",
      "Epoch 4/21-----Batch 46212/59476-----Step 18720/100000-----Data Time 0.003 (0.005)-----Step Time 3.135 (3.500)-----Loss 3.1040 (3.2340)\n",
      "Epoch 4/21-----Batch 46452/59476-----Step 18740/100000-----Data Time 0.003 (0.005)-----Step Time 3.103 (3.498)-----Loss 2.4088 (3.2340)\n",
      "Epoch 4/21-----Batch 46692/59476-----Step 18760/100000-----Data Time 0.005 (0.005)-----Step Time 3.187 (3.496)-----Loss 3.0826 (3.2340)\n",
      "Epoch 4/21-----Batch 46932/59476-----Step 18780/100000-----Data Time 0.004 (0.005)-----Step Time 3.489 (3.494)-----Loss 2.9969 (3.2337)\n",
      "Epoch 4/21-----Batch 47172/59476-----Step 18800/100000-----Data Time 0.004 (0.005)-----Step Time 3.094 (3.492)-----Loss 2.8570 (3.2338)\n",
      "Epoch 4/21-----Batch 47412/59476-----Step 18820/100000-----Data Time 0.003 (0.005)-----Step Time 3.146 (3.491)-----Loss 3.3985 (3.2334)\n",
      "Epoch 4/21-----Batch 47652/59476-----Step 18840/100000-----Data Time 0.004 (0.005)-----Step Time 3.107 (3.489)-----Loss 3.6650 (3.2333)\n",
      "Epoch 4/21-----Batch 47892/59476-----Step 18860/100000-----Data Time 0.003 (0.005)-----Step Time 3.207 (3.487)-----Loss 2.6987 (3.2331)\n",
      "Epoch 4/21-----Batch 48132/59476-----Step 18880/100000-----Data Time 0.003 (0.005)-----Step Time 3.121 (3.485)-----Loss 2.5021 (3.2329)\n",
      "Epoch 4/21-----Batch 48372/59476-----Step 18900/100000-----Data Time 0.005 (0.005)-----Step Time 3.086 (3.483)-----Loss 3.0226 (3.2327)\n",
      "Epoch 4/21-----Batch 48612/59476-----Step 18920/100000-----Data Time 0.004 (0.005)-----Step Time 3.088 (3.481)-----Loss 2.8149 (3.2323)\n",
      "Epoch 4/21-----Batch 48852/59476-----Step 18940/100000-----Data Time 0.003 (0.005)-----Step Time 3.118 (3.480)-----Loss 3.0779 (3.2323)\n",
      "Epoch 4/21-----Batch 49092/59476-----Step 18960/100000-----Data Time 0.003 (0.005)-----Step Time 3.182 (3.478)-----Loss 3.1085 (3.2321)\n",
      "Epoch 4/21-----Batch 49332/59476-----Step 18980/100000-----Data Time 0.004 (0.005)-----Step Time 3.181 (3.476)-----Loss 2.6187 (3.2321)\n",
      "Epoch 4/21-----Batch 49572/59476-----Step 19000/100000-----Data Time 0.004 (0.005)-----Step Time 3.044 (3.474)-----Loss 2.7584 (3.2318)\n",
      "Epoch 4/21-----Batch 49812/59476-----Step 19020/100000-----Data Time 0.005 (0.005)-----Step Time 3.080 (3.473)-----Loss 2.9483 (3.2321)\n",
      "Epoch 4/21-----Batch 50052/59476-----Step 19040/100000-----Data Time 0.003 (0.005)-----Step Time 3.145 (3.471)-----Loss 3.7493 (3.2320)\n",
      "Epoch 4/21-----Batch 50292/59476-----Step 19060/100000-----Data Time 0.003 (0.005)-----Step Time 3.088 (3.469)-----Loss 3.1807 (3.2320)\n",
      "Epoch 4/21-----Batch 50532/59476-----Step 19080/100000-----Data Time 0.004 (0.005)-----Step Time 3.172 (3.468)-----Loss 2.9832 (3.2319)\n",
      "Epoch 4/21-----Batch 50772/59476-----Step 19100/100000-----Data Time 0.003 (0.005)-----Step Time 3.126 (3.466)-----Loss 2.8977 (3.2318)\n",
      "Epoch 4/21-----Batch 51012/59476-----Step 19120/100000-----Data Time 0.005 (0.005)-----Step Time 3.074 (3.465)-----Loss 3.0894 (3.2316)\n",
      "Epoch 4/21-----Batch 51252/59476-----Step 19140/100000-----Data Time 0.004 (0.005)-----Step Time 3.174 (3.463)-----Loss 3.4059 (3.2315)\n",
      "Epoch 4/21-----Batch 51492/59476-----Step 19160/100000-----Data Time 0.003 (0.005)-----Step Time 3.170 (3.461)-----Loss 3.1100 (3.2314)\n",
      "Epoch 4/21-----Batch 51732/59476-----Step 19180/100000-----Data Time 0.003 (0.005)-----Step Time 3.165 (3.460)-----Loss 3.4269 (3.2313)\n",
      "Epoch 4/21-----Batch 51972/59476-----Step 19200/100000-----Data Time 0.003 (0.005)-----Step Time 3.158 (3.458)-----Loss 3.9959 (3.2311)\n",
      "Epoch 4/21-----Batch 52212/59476-----Step 19220/100000-----Data Time 0.004 (0.005)-----Step Time 3.225 (3.457)-----Loss 2.7241 (3.2310)\n",
      "Epoch 4/21-----Batch 52452/59476-----Step 19240/100000-----Data Time 0.003 (0.005)-----Step Time 3.125 (3.455)-----Loss 3.2351 (3.2315)\n",
      "Epoch 4/21-----Batch 52692/59476-----Step 19260/100000-----Data Time 0.006 (0.005)-----Step Time 3.082 (3.454)-----Loss 3.1676 (3.2315)\n",
      "Epoch 4/21-----Batch 52932/59476-----Step 19280/100000-----Data Time 0.003 (0.005)-----Step Time 3.051 (3.452)-----Loss 4.2228 (3.2316)\n",
      "Epoch 4/21-----Batch 53172/59476-----Step 19300/100000-----Data Time 0.004 (0.005)-----Step Time 3.081 (3.451)-----Loss 3.7285 (3.2313)\n",
      "Epoch 4/21-----Batch 53412/59476-----Step 19320/100000-----Data Time 0.003 (0.005)-----Step Time 3.065 (3.449)-----Loss 3.4537 (3.2313)\n",
      "Epoch 4/21-----Batch 53652/59476-----Step 19340/100000-----Data Time 0.003 (0.005)-----Step Time 3.088 (3.448)-----Loss 2.9590 (3.2314)\n",
      "Epoch 4/21-----Batch 53892/59476-----Step 19360/100000-----Data Time 0.003 (0.005)-----Step Time 3.058 (3.446)-----Loss 3.0764 (3.2315)\n",
      "Epoch 4/21-----Batch 54132/59476-----Step 19380/100000-----Data Time 0.004 (0.005)-----Step Time 3.090 (3.445)-----Loss 3.3020 (3.2314)\n",
      "Epoch 4/21-----Batch 54372/59476-----Step 19400/100000-----Data Time 0.003 (0.005)-----Step Time 3.080 (3.444)-----Loss 3.2733 (3.2311)\n",
      "Epoch 4/21-----Batch 54612/59476-----Step 19420/100000-----Data Time 0.003 (0.005)-----Step Time 3.164 (3.442)-----Loss 2.7465 (3.2310)\n",
      "Epoch 4/21-----Batch 54852/59476-----Step 19440/100000-----Data Time 0.003 (0.005)-----Step Time 3.155 (3.441)-----Loss 3.0518 (3.2307)\n",
      "Epoch 4/21-----Batch 55092/59476-----Step 19460/100000-----Data Time 0.004 (0.005)-----Step Time 3.252 (3.440)-----Loss 2.8512 (3.2305)\n",
      "Epoch 4/21-----Batch 55332/59476-----Step 19480/100000-----Data Time 0.003 (0.005)-----Step Time 3.127 (3.438)-----Loss 3.0430 (3.2304)\n",
      "Epoch 4/21-----Batch 55572/59476-----Step 19500/100000-----Data Time 0.003 (0.005)-----Step Time 3.241 (3.437)-----Loss 4.1813 (3.2303)\n",
      "Epoch 4/21-----Batch 55812/59476-----Step 19520/100000-----Data Time 0.003 (0.005)-----Step Time 3.111 (3.436)-----Loss 3.2713 (3.2304)\n",
      "Epoch 4/21-----Batch 56052/59476-----Step 19540/100000-----Data Time 0.003 (0.005)-----Step Time 3.139 (3.434)-----Loss 2.9549 (3.2305)\n",
      "Epoch 4/21-----Batch 56292/59476-----Step 19560/100000-----Data Time 0.003 (0.005)-----Step Time 3.085 (3.433)-----Loss 2.5912 (3.2301)\n",
      "Epoch 4/21-----Batch 56532/59476-----Step 19580/100000-----Data Time 0.003 (0.005)-----Step Time 3.119 (3.432)-----Loss 3.6144 (3.2299)\n",
      "Epoch 4/21-----Batch 56772/59476-----Step 19600/100000-----Data Time 0.003 (0.005)-----Step Time 3.067 (3.430)-----Loss 3.5640 (3.2300)\n",
      "Epoch 4/21-----Batch 57012/59476-----Step 19620/100000-----Data Time 0.002 (0.005)-----Step Time 3.102 (3.429)-----Loss 3.6036 (3.2302)\n",
      "Epoch 4/21-----Batch 57252/59476-----Step 19640/100000-----Data Time 0.003 (0.005)-----Step Time 3.188 (3.428)-----Loss 3.4073 (3.2300)\n",
      "Epoch 4/21-----Batch 57492/59476-----Step 19660/100000-----Data Time 0.004 (0.005)-----Step Time 3.193 (3.427)-----Loss 2.6338 (3.2297)\n",
      "Epoch 4/21-----Batch 57732/59476-----Step 19680/100000-----Data Time 0.003 (0.005)-----Step Time 3.117 (3.425)-----Loss 2.7189 (3.2297)\n",
      "Epoch 4/21-----Batch 57972/59476-----Step 19700/100000-----Data Time 0.003 (0.005)-----Step Time 3.067 (3.424)-----Loss 2.5622 (3.2298)\n",
      "Epoch 4/21-----Batch 58212/59476-----Step 19720/100000-----Data Time 0.004 (0.005)-----Step Time 3.112 (3.423)-----Loss 2.7813 (3.2297)\n",
      "Epoch 4/21-----Batch 58452/59476-----Step 19740/100000-----Data Time 0.003 (0.005)-----Step Time 3.061 (3.422)-----Loss 2.4973 (3.2295)\n",
      "Epoch 4/21-----Batch 58692/59476-----Step 19760/100000-----Data Time 0.003 (0.005)-----Step Time 3.468 (3.420)-----Loss 2.7854 (3.2296)\n",
      "Epoch 4/21-----Batch 58932/59476-----Step 19780/100000-----Data Time 0.003 (0.005)-----Step Time 3.074 (3.419)-----Loss 2.4892 (3.2293)\n",
      "Epoch 4/21-----Batch 59172/59476-----Step 19800/100000-----Data Time 0.003 (0.005)-----Step Time 3.021 (3.418)-----Loss 3.7747 (3.2290)\n",
      "Epoch 4/21-----Batch 59412/59476-----Step 19820/100000-----Data Time 0.003 (0.005)-----Step Time 3.057 (3.417)-----Loss 3.0408 (3.2288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:36<00:00, 81.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss: 3.176\n",
      "\n",
      "\n",
      " Epoch #  4\n",
      "Epoch 5/21-----Batch 180/59476-----Step 19840/100000-----Data Time 0.010 (0.005)-----Step Time 3.101 (3.013)-----Loss 3.9186 (3.1666)\n",
      "Epoch 5/21-----Batch 420/59476-----Step 19860/100000-----Data Time 0.003 (0.005)-----Step Time 3.036 (3.050)-----Loss 2.9571 (3.1441)\n",
      "Epoch 5/21-----Batch 660/59476-----Step 19880/100000-----Data Time 0.003 (0.005)-----Step Time 3.068 (3.075)-----Loss 2.7363 (3.1422)\n",
      "Epoch 5/21-----Batch 900/59476-----Step 19900/100000-----Data Time 0.003 (0.005)-----Step Time 3.144 (3.084)-----Loss 3.0166 (3.1436)\n",
      "Epoch 5/21-----Batch 1140/59476-----Step 19920/100000-----Data Time 0.004 (0.005)-----Step Time 3.085 (3.091)-----Loss 3.0148 (3.1489)\n",
      "Epoch 5/21-----Batch 1380/59476-----Step 19940/100000-----Data Time 0.003 (0.005)-----Step Time 3.210 (3.096)-----Loss 4.3437 (3.1633)\n",
      "Epoch 5/21-----Batch 1620/59476-----Step 19960/100000-----Data Time 0.003 (0.005)-----Step Time 3.031 (3.094)-----Loss 2.7845 (3.1577)\n",
      "Epoch 5/21-----Batch 1860/59476-----Step 19980/100000-----Data Time 0.003 (0.005)-----Step Time 3.148 (3.096)-----Loss 3.2271 (3.1538)\n",
      "Epoch 5/21-----Batch 2100/59476-----Step 20000/100000-----Data Time 0.004 (0.005)-----Step Time 3.122 (3.097)-----Loss 2.8864 (3.1504)\n",
      "Epoch 5/21-----Batch 2340/59476-----Step 20020/100000-----Data Time 0.004 (0.005)-----Step Time 3.015 (3.099)-----Loss 3.2658 (3.1459)\n",
      "Epoch 5/21-----Batch 2580/59476-----Step 20040/100000-----Data Time 0.004 (0.005)-----Step Time 3.014 (3.100)-----Loss 3.4415 (3.1498)\n",
      "Epoch 5/21-----Batch 2820/59476-----Step 20060/100000-----Data Time 0.004 (0.005)-----Step Time 3.061 (3.102)-----Loss 2.2887 (3.1518)\n",
      "Epoch 5/21-----Batch 3060/59476-----Step 20080/100000-----Data Time 0.003 (0.005)-----Step Time 3.064 (3.103)-----Loss 2.7677 (3.1527)\n",
      "Epoch 5/21-----Batch 3300/59476-----Step 20100/100000-----Data Time 0.004 (0.005)-----Step Time 3.010 (3.104)-----Loss 3.2592 (3.1544)\n",
      "Epoch 5/21-----Batch 3540/59476-----Step 20120/100000-----Data Time 0.008 (0.005)-----Step Time 3.081 (3.104)-----Loss 3.6114 (3.1542)\n",
      "Epoch 5/21-----Batch 3780/59476-----Step 20140/100000-----Data Time 0.003 (0.005)-----Step Time 3.017 (3.103)-----Loss 3.5781 (3.1509)\n",
      "Epoch 5/21-----Batch 4020/59476-----Step 20160/100000-----Data Time 0.003 (0.005)-----Step Time 3.099 (3.103)-----Loss 2.6063 (3.1488)\n",
      "Epoch 5/21-----Batch 4260/59476-----Step 20180/100000-----Data Time 0.005 (0.005)-----Step Time 3.068 (3.103)-----Loss 2.4369 (3.1496)\n",
      "Epoch 5/21-----Batch 4500/59476-----Step 20200/100000-----Data Time 0.003 (0.005)-----Step Time 3.033 (3.105)-----Loss 3.0924 (3.1499)\n",
      "Epoch 5/21-----Batch 4740/59476-----Step 20220/100000-----Data Time 0.004 (0.005)-----Step Time 3.119 (3.106)-----Loss 3.0677 (3.1508)\n",
      "Epoch 5/21-----Batch 4980/59476-----Step 20240/100000-----Data Time 0.003 (0.005)-----Step Time 3.116 (3.106)-----Loss 3.5280 (3.1499)\n",
      "Epoch 5/21-----Batch 5220/59476-----Step 20260/100000-----Data Time 0.003 (0.005)-----Step Time 3.045 (3.107)-----Loss 3.3646 (3.1489)\n",
      "Epoch 5/21-----Batch 5460/59476-----Step 20280/100000-----Data Time 0.003 (0.005)-----Step Time 3.055 (3.107)-----Loss 2.8869 (3.1483)\n",
      "Epoch 5/21-----Batch 5700/59476-----Step 20300/100000-----Data Time 0.003 (0.005)-----Step Time 3.064 (3.108)-----Loss 2.9387 (3.1486)\n",
      "Epoch 5/21-----Batch 5940/59476-----Step 20320/100000-----Data Time 0.003 (0.005)-----Step Time 3.078 (3.107)-----Loss 3.1641 (3.1488)\n",
      "Epoch 5/21-----Batch 6180/59476-----Step 20340/100000-----Data Time 0.004 (0.005)-----Step Time 3.117 (3.108)-----Loss 2.6111 (3.1489)\n",
      "Epoch 5/21-----Batch 6420/59476-----Step 20360/100000-----Data Time 0.004 (0.005)-----Step Time 3.126 (3.108)-----Loss 4.0943 (3.1470)\n",
      "Epoch 5/21-----Batch 6660/59476-----Step 20380/100000-----Data Time 0.003 (0.005)-----Step Time 3.107 (3.108)-----Loss 3.1270 (3.1475)\n",
      "Epoch 5/21-----Batch 6900/59476-----Step 20400/100000-----Data Time 0.003 (0.005)-----Step Time 3.126 (3.108)-----Loss 3.0048 (3.1477)\n",
      "Epoch 5/21-----Batch 7140/59476-----Step 20420/100000-----Data Time 0.009 (0.005)-----Step Time 3.040 (3.108)-----Loss 3.4997 (3.1468)\n",
      "Epoch 5/21-----Batch 7380/59476-----Step 20440/100000-----Data Time 0.003 (0.005)-----Step Time 3.120 (3.108)-----Loss 3.4522 (3.1463)\n",
      "Epoch 5/21-----Batch 7620/59476-----Step 20460/100000-----Data Time 0.005 (0.005)-----Step Time 3.137 (3.108)-----Loss 2.9702 (3.1456)\n",
      "Epoch 5/21-----Batch 7860/59476-----Step 20480/100000-----Data Time 0.004 (0.005)-----Step Time 3.133 (3.108)-----Loss 4.6100 (3.1483)\n",
      "Epoch 5/21-----Batch 8100/59476-----Step 20500/100000-----Data Time 0.003 (0.005)-----Step Time 3.164 (3.107)-----Loss 4.5171 (3.1495)\n",
      "Epoch 5/21-----Batch 8340/59476-----Step 20520/100000-----Data Time 0.003 (0.005)-----Step Time 3.089 (3.107)-----Loss 3.4193 (3.1516)\n",
      "Epoch 5/21-----Batch 8580/59476-----Step 20540/100000-----Data Time 0.003 (0.005)-----Step Time 3.101 (3.108)-----Loss 3.3385 (3.1521)\n",
      "Epoch 5/21-----Batch 8820/59476-----Step 20560/100000-----Data Time 0.003 (0.005)-----Step Time 3.135 (3.107)-----Loss 2.7731 (3.1532)\n",
      "Epoch 5/21-----Batch 9060/59476-----Step 20580/100000-----Data Time 0.003 (0.005)-----Step Time 3.030 (3.108)-----Loss 4.8191 (3.1532)\n",
      "Epoch 5/21-----Batch 9300/59476-----Step 20600/100000-----Data Time 0.004 (0.005)-----Step Time 3.073 (3.108)-----Loss 3.1972 (3.1525)\n",
      "Epoch 5/21-----Batch 9540/59476-----Step 20620/100000-----Data Time 0.003 (0.005)-----Step Time 3.328 (3.109)-----Loss 3.1926 (3.1536)\n",
      "Epoch 5/21-----Batch 9780/59476-----Step 20640/100000-----Data Time 0.004 (0.005)-----Step Time 3.003 (3.109)-----Loss 2.9366 (3.1536)\n",
      "Epoch 5/21-----Batch 10020/59476-----Step 20660/100000-----Data Time 0.006 (0.005)-----Step Time 3.086 (3.110)-----Loss 2.0409 (3.1537)\n",
      "Epoch 5/21-----Batch 10260/59476-----Step 20680/100000-----Data Time 0.004 (0.005)-----Step Time 3.116 (3.110)-----Loss 3.4263 (3.1545)\n",
      "Epoch 5/21-----Batch 10500/59476-----Step 20700/100000-----Data Time 0.003 (0.005)-----Step Time 3.080 (3.111)-----Loss 3.1636 (3.1552)\n",
      "Epoch 5/21-----Batch 10740/59476-----Step 20720/100000-----Data Time 0.003 (0.005)-----Step Time 3.159 (3.110)-----Loss 2.4606 (3.1555)\n",
      "Epoch 5/21-----Batch 10980/59476-----Step 20740/100000-----Data Time 0.003 (0.005)-----Step Time 3.109 (3.111)-----Loss 2.8748 (3.1570)\n",
      "Epoch 5/21-----Batch 11220/59476-----Step 20760/100000-----Data Time 0.003 (0.005)-----Step Time 3.141 (3.111)-----Loss 2.8289 (3.1578)\n",
      "Epoch 5/21-----Batch 11460/59476-----Step 20780/100000-----Data Time 0.003 (0.005)-----Step Time 3.141 (3.111)-----Loss 4.1966 (3.1580)\n",
      "Epoch 5/21-----Batch 11700/59476-----Step 20800/100000-----Data Time 0.006 (0.005)-----Step Time 3.153 (3.111)-----Loss 2.7435 (3.1580)\n",
      "Epoch 5/21-----Batch 11940/59476-----Step 20820/100000-----Data Time 0.004 (0.005)-----Step Time 3.060 (3.111)-----Loss 3.0299 (3.1568)\n",
      "Epoch 5/21-----Batch 12180/59476-----Step 20840/100000-----Data Time 0.003 (0.005)-----Step Time 3.364 (3.112)-----Loss 3.0168 (3.1565)\n",
      "Epoch 5/21-----Batch 12420/59476-----Step 20860/100000-----Data Time 0.003 (0.005)-----Step Time 3.132 (3.112)-----Loss 3.7064 (3.1553)\n",
      "Epoch 5/21-----Batch 12660/59476-----Step 20880/100000-----Data Time 0.003 (0.005)-----Step Time 3.117 (3.111)-----Loss 3.1417 (3.1574)\n",
      "Epoch 5/21-----Batch 12900/59476-----Step 20900/100000-----Data Time 0.003 (0.005)-----Step Time 3.071 (3.112)-----Loss 4.2482 (3.1581)\n",
      "Epoch 5/21-----Batch 13140/59476-----Step 20920/100000-----Data Time 0.003 (0.005)-----Step Time 3.087 (3.112)-----Loss 3.2128 (3.1587)\n",
      "Epoch 5/21-----Batch 13380/59476-----Step 20940/100000-----Data Time 0.004 (0.005)-----Step Time 3.071 (3.112)-----Loss 2.3487 (3.1582)\n",
      "Epoch 5/21-----Batch 13620/59476-----Step 20960/100000-----Data Time 0.006 (0.005)-----Step Time 3.100 (3.112)-----Loss 3.5581 (3.1576)\n",
      "Epoch 5/21-----Batch 13860/59476-----Step 20980/100000-----Data Time 0.004 (0.005)-----Step Time 3.057 (3.111)-----Loss 3.6136 (3.1573)\n",
      "Epoch 5/21-----Batch 14100/59476-----Step 21000/100000-----Data Time 0.004 (0.005)-----Step Time 3.121 (3.112)-----Loss 3.6307 (3.1564)\n",
      "Epoch 5/21-----Batch 14340/59476-----Step 21020/100000-----Data Time 0.003 (0.005)-----Step Time 3.020 (3.112)-----Loss 2.9847 (3.1563)\n",
      "Epoch 5/21-----Batch 14580/59476-----Step 21040/100000-----Data Time 0.003 (0.005)-----Step Time 3.258 (3.112)-----Loss 3.1356 (3.1559)\n",
      "Epoch 5/21-----Batch 14820/59476-----Step 21060/100000-----Data Time 0.003 (0.005)-----Step Time 3.113 (3.113)-----Loss 3.4389 (3.1564)\n",
      "Epoch 5/21-----Batch 15060/59476-----Step 21080/100000-----Data Time 0.003 (0.005)-----Step Time 3.138 (3.113)-----Loss 2.7200 (3.1569)\n",
      "Epoch 5/21-----Batch 15300/59476-----Step 21100/100000-----Data Time 0.003 (0.005)-----Step Time 3.083 (3.113)-----Loss 3.5213 (3.1561)\n",
      "Epoch 5/21-----Batch 15540/59476-----Step 21120/100000-----Data Time 0.003 (0.005)-----Step Time 3.144 (3.114)-----Loss 3.8040 (3.1556)\n",
      "Epoch 5/21-----Batch 15780/59476-----Step 21140/100000-----Data Time 0.003 (0.005)-----Step Time 3.154 (3.114)-----Loss 2.8913 (3.1566)\n",
      "Epoch 5/21-----Batch 16020/59476-----Step 21160/100000-----Data Time 0.004 (0.005)-----Step Time 3.046 (3.114)-----Loss 3.6580 (3.1568)\n",
      "Epoch 5/21-----Batch 16260/59476-----Step 21180/100000-----Data Time 0.003 (0.005)-----Step Time 2.979 (3.114)-----Loss 2.8204 (3.1573)\n",
      "Epoch 5/21-----Batch 16500/59476-----Step 21200/100000-----Data Time 0.003 (0.005)-----Step Time 3.050 (3.114)-----Loss 3.0531 (3.1575)\n",
      "Epoch 5/21-----Batch 16740/59476-----Step 21220/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.114)-----Loss 2.7110 (3.1570)\n",
      "Epoch 5/21-----Batch 16980/59476-----Step 21240/100000-----Data Time 0.004 (0.005)-----Step Time 3.095 (3.114)-----Loss 3.1193 (3.1570)\n",
      "Epoch 5/21-----Batch 17220/59476-----Step 21260/100000-----Data Time 0.003 (0.005)-----Step Time 3.162 (3.114)-----Loss 3.0804 (3.1574)\n",
      "Epoch 5/21-----Batch 17460/59476-----Step 21280/100000-----Data Time 0.004 (0.005)-----Step Time 3.219 (3.114)-----Loss 2.5931 (3.1578)\n",
      "Epoch 5/21-----Batch 17700/59476-----Step 21300/100000-----Data Time 0.005 (0.005)-----Step Time 3.133 (3.114)-----Loss 2.8882 (3.1577)\n",
      "Epoch 5/21-----Batch 17940/59476-----Step 21320/100000-----Data Time 0.003 (0.005)-----Step Time 3.018 (3.114)-----Loss 2.8305 (3.1575)\n",
      "Epoch 5/21-----Batch 18180/59476-----Step 21340/100000-----Data Time 0.003 (0.005)-----Step Time 3.237 (3.114)-----Loss 4.5382 (3.1577)\n",
      "Epoch 5/21-----Batch 18420/59476-----Step 21360/100000-----Data Time 0.003 (0.005)-----Step Time 3.173 (3.114)-----Loss 4.2778 (3.1576)\n",
      "Epoch 5/21-----Batch 18660/59476-----Step 21380/100000-----Data Time 0.003 (0.005)-----Step Time 3.081 (3.114)-----Loss 2.5648 (3.1582)\n",
      "Epoch 5/21-----Batch 18900/59476-----Step 21400/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.114)-----Loss 3.0887 (3.1583)\n",
      "Epoch 5/21-----Batch 19140/59476-----Step 21420/100000-----Data Time 0.006 (0.005)-----Step Time 3.104 (3.114)-----Loss 3.2586 (3.1586)\n",
      "Epoch 5/21-----Batch 19380/59476-----Step 21440/100000-----Data Time 0.004 (0.005)-----Step Time 3.024 (3.114)-----Loss 2.6138 (3.1590)\n",
      "Epoch 5/21-----Batch 19620/59476-----Step 21460/100000-----Data Time 0.003 (0.005)-----Step Time 3.151 (3.114)-----Loss 2.9174 (3.1581)\n",
      "Epoch 5/21-----Batch 19860/59476-----Step 21480/100000-----Data Time 0.004 (0.005)-----Step Time 3.029 (3.113)-----Loss 4.7490 (3.1588)\n",
      "Epoch 5/21-----Batch 20100/59476-----Step 21500/100000-----Data Time 0.003 (0.005)-----Step Time 3.123 (3.113)-----Loss 3.8563 (3.1590)\n",
      "Epoch 5/21-----Batch 20340/59476-----Step 21520/100000-----Data Time 0.003 (0.005)-----Step Time 3.129 (3.113)-----Loss 2.7239 (3.1585)\n",
      "Epoch 5/21-----Batch 20580/59476-----Step 21540/100000-----Data Time 0.003 (0.005)-----Step Time 3.236 (3.113)-----Loss 4.9107 (3.1579)\n",
      "Epoch 5/21-----Batch 20820/59476-----Step 21560/100000-----Data Time 0.003 (0.005)-----Step Time 3.089 (3.113)-----Loss 4.3484 (3.1578)\n",
      "Epoch 5/21-----Batch 21060/59476-----Step 21580/100000-----Data Time 0.004 (0.005)-----Step Time 3.060 (3.113)-----Loss 4.0556 (3.1578)\n",
      "Epoch 5/21-----Batch 21300/59476-----Step 21600/100000-----Data Time 0.003 (0.005)-----Step Time 3.068 (3.113)-----Loss 2.7897 (3.1577)\n",
      "Epoch 5/21-----Batch 21540/59476-----Step 21620/100000-----Data Time 0.003 (0.005)-----Step Time 3.097 (3.113)-----Loss 2.8452 (3.1576)\n",
      "Epoch 5/21-----Batch 21780/59476-----Step 21640/100000-----Data Time 0.003 (0.005)-----Step Time 3.076 (3.113)-----Loss 2.9751 (3.1577)\n",
      "Epoch 5/21-----Batch 22020/59476-----Step 21660/100000-----Data Time 0.007 (0.005)-----Step Time 3.158 (3.113)-----Loss 2.5278 (3.1571)\n",
      "Epoch 5/21-----Batch 22260/59476-----Step 21680/100000-----Data Time 0.003 (0.005)-----Step Time 3.104 (3.113)-----Loss 2.8967 (3.1576)\n",
      "Epoch 5/21-----Batch 22500/59476-----Step 21700/100000-----Data Time 0.003 (0.005)-----Step Time 3.131 (3.113)-----Loss 3.9395 (3.1581)\n",
      "Epoch 5/21-----Batch 22740/59476-----Step 21720/100000-----Data Time 0.004 (0.005)-----Step Time 2.970 (3.113)-----Loss 3.5752 (3.1582)\n",
      "Epoch 5/21-----Batch 22980/59476-----Step 21740/100000-----Data Time 0.010 (0.005)-----Step Time 3.211 (3.113)-----Loss 2.7343 (3.1577)\n",
      "Epoch 5/21-----Batch 23220/59476-----Step 21760/100000-----Data Time 0.003 (0.005)-----Step Time 3.002 (3.113)-----Loss 3.3614 (3.1577)\n",
      "Epoch 5/21-----Batch 23460/59476-----Step 21780/100000-----Data Time 0.003 (0.005)-----Step Time 3.196 (3.113)-----Loss 3.8879 (3.1576)\n",
      "Epoch 5/21-----Batch 23700/59476-----Step 21800/100000-----Data Time 0.003 (0.005)-----Step Time 3.032 (3.112)-----Loss 4.0741 (3.1577)\n",
      "Epoch 5/21-----Batch 23940/59476-----Step 21820/100000-----Data Time 0.004 (0.005)-----Step Time 3.136 (3.113)-----Loss 3.1587 (3.1581)\n",
      "Epoch 5/21-----Batch 24180/59476-----Step 21840/100000-----Data Time 0.003 (0.005)-----Step Time 3.345 (3.113)-----Loss 3.5345 (3.1578)\n",
      "Epoch 5/21-----Batch 24420/59476-----Step 21860/100000-----Data Time 0.004 (0.005)-----Step Time 3.081 (3.112)-----Loss 2.8821 (3.1579)\n",
      "Epoch 5/21-----Batch 24660/59476-----Step 21880/100000-----Data Time 0.004 (0.005)-----Step Time 3.153 (3.113)-----Loss 3.8045 (3.1580)\n",
      "Epoch 5/21-----Batch 24900/59476-----Step 21900/100000-----Data Time 0.003 (0.005)-----Step Time 3.145 (3.113)-----Loss 2.6036 (3.1583)\n",
      "Epoch 5/21-----Batch 25140/59476-----Step 21920/100000-----Data Time 0.004 (0.005)-----Step Time 3.171 (3.112)-----Loss 2.9799 (3.1578)\n",
      "Epoch 5/21-----Batch 25380/59476-----Step 21940/100000-----Data Time 0.004 (0.005)-----Step Time 3.098 (3.112)-----Loss 3.0537 (3.1582)\n",
      "Epoch 5/21-----Batch 25620/59476-----Step 21960/100000-----Data Time 0.003 (0.005)-----Step Time 3.053 (3.113)-----Loss 4.1569 (3.1583)\n",
      "Epoch 5/21-----Batch 25860/59476-----Step 21980/100000-----Data Time 0.003 (0.005)-----Step Time 3.112 (3.113)-----Loss 3.4173 (3.1587)\n",
      "Epoch 5/21-----Batch 26100/59476-----Step 22000/100000-----Data Time 0.004 (0.005)-----Step Time 3.084 (3.113)-----Loss 3.0446 (3.1586)\n",
      "Epoch 5/21-----Batch 26340/59476-----Step 22020/100000-----Data Time 0.004 (0.005)-----Step Time 3.047 (3.113)-----Loss 2.6032 (3.1580)\n",
      "Epoch 5/21-----Batch 26580/59476-----Step 22040/100000-----Data Time 0.004 (0.005)-----Step Time 3.119 (3.113)-----Loss 3.4400 (3.1582)\n",
      "Epoch 5/21-----Batch 26820/59476-----Step 22060/100000-----Data Time 0.004 (0.005)-----Step Time 3.164 (3.113)-----Loss 2.9251 (3.1583)\n",
      "Epoch 5/21-----Batch 27060/59476-----Step 22080/100000-----Data Time 0.005 (0.005)-----Step Time 3.246 (3.113)-----Loss 2.8247 (3.1576)\n",
      "Epoch 5/21-----Batch 27300/59476-----Step 22100/100000-----Data Time 0.003 (0.005)-----Step Time 3.153 (3.113)-----Loss 2.4174 (3.1581)\n",
      "Epoch 5/21-----Batch 27540/59476-----Step 22120/100000-----Data Time 0.002 (0.005)-----Step Time 3.080 (3.113)-----Loss 4.3027 (3.1584)\n",
      "Epoch 5/21-----Batch 27780/59476-----Step 22140/100000-----Data Time 0.003 (0.005)-----Step Time 3.119 (3.113)-----Loss 2.8685 (3.1586)\n",
      "Epoch 5/21-----Batch 28020/59476-----Step 22160/100000-----Data Time 0.003 (0.005)-----Step Time 3.016 (3.112)-----Loss 2.9720 (3.1586)\n",
      "Epoch 5/21-----Batch 28260/59476-----Step 22180/100000-----Data Time 0.004 (0.005)-----Step Time 3.014 (3.112)-----Loss 3.0310 (3.1584)\n",
      "Epoch 5/21-----Batch 28500/59476-----Step 22200/100000-----Data Time 0.003 (0.005)-----Step Time 3.145 (3.112)-----Loss 2.5129 (3.1580)\n",
      "Epoch 5/21-----Batch 28740/59476-----Step 22220/100000-----Data Time 0.003 (0.005)-----Step Time 3.145 (3.112)-----Loss 3.3632 (3.1583)\n",
      "Epoch 5/21-----Batch 28980/59476-----Step 22240/100000-----Data Time 0.003 (0.005)-----Step Time 3.090 (3.113)-----Loss 3.5368 (3.1588)\n",
      "Epoch 5/21-----Batch 29220/59476-----Step 22260/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.113)-----Loss 3.4220 (3.1585)\n",
      "Epoch 5/21-----Batch 29460/59476-----Step 22280/100000-----Data Time 0.003 (0.005)-----Step Time 3.125 (3.113)-----Loss 2.4940 (3.1587)\n",
      "Epoch 5/21-----Batch 29700/59476-----Step 22300/100000-----Data Time 0.008 (0.005)-----Step Time 3.078 (3.113)-----Loss 3.0931 (3.1584)\n",
      "Epoch 5/21-----Batch 29940/59476-----Step 22320/100000-----Data Time 0.003 (0.005)-----Step Time 3.085 (3.113)-----Loss 3.3023 (3.1584)\n",
      "Epoch 5/21-----Batch 30180/59476-----Step 22340/100000-----Data Time 0.003 (0.005)-----Step Time 3.101 (3.113)-----Loss 2.7975 (3.1586)\n",
      "Epoch 5/21-----Batch 30420/59476-----Step 22360/100000-----Data Time 0.003 (0.005)-----Step Time 3.292 (3.113)-----Loss 3.2690 (3.1582)\n",
      "Epoch 5/21-----Batch 30660/59476-----Step 22380/100000-----Data Time 0.003 (0.005)-----Step Time 3.067 (3.113)-----Loss 2.8992 (3.1581)\n",
      "Epoch 5/21-----Batch 30900/59476-----Step 22400/100000-----Data Time 0.004 (0.005)-----Step Time 2.863 (3.113)-----Loss 3.1603 (3.1579)\n",
      "Epoch 5/21-----Batch 31140/59476-----Step 22420/100000-----Data Time 0.003 (0.005)-----Step Time 3.229 (3.113)-----Loss 3.3784 (3.1577)\n",
      "Epoch 5/21-----Batch 31380/59476-----Step 22440/100000-----Data Time 0.003 (0.005)-----Step Time 3.146 (3.113)-----Loss 3.3738 (3.1578)\n",
      "Epoch 5/21-----Batch 31620/59476-----Step 22460/100000-----Data Time 0.004 (0.005)-----Step Time 3.243 (3.113)-----Loss 2.8448 (3.1576)\n",
      "Epoch 5/21-----Batch 31860/59476-----Step 22480/100000-----Data Time 0.004 (0.005)-----Step Time 3.119 (3.113)-----Loss 3.3337 (3.1573)\n",
      "Epoch 5/21-----Batch 32100/59476-----Step 22500/100000-----Data Time 0.003 (0.005)-----Step Time 3.394 (3.113)-----Loss 3.7175 (3.1570)\n",
      "Epoch 5/21-----Batch 32340/59476-----Step 22520/100000-----Data Time 0.003 (0.005)-----Step Time 3.081 (3.114)-----Loss 3.6390 (3.1571)\n",
      "Epoch 5/21-----Batch 32580/59476-----Step 22540/100000-----Data Time 0.003 (0.005)-----Step Time 3.081 (3.113)-----Loss 3.4015 (3.1569)\n",
      "Epoch 5/21-----Batch 32820/59476-----Step 22560/100000-----Data Time 0.003 (0.005)-----Step Time 3.114 (3.113)-----Loss 2.6621 (3.1570)\n",
      "Epoch 5/21-----Batch 33060/59476-----Step 22580/100000-----Data Time 0.003 (0.005)-----Step Time 3.188 (3.113)-----Loss 3.6234 (3.1570)\n",
      "Epoch 5/21-----Batch 33300/59476-----Step 22600/100000-----Data Time 0.004 (0.005)-----Step Time 3.070 (3.113)-----Loss 3.0976 (3.1569)\n",
      "Epoch 5/21-----Batch 33540/59476-----Step 22620/100000-----Data Time 0.003 (0.005)-----Step Time 3.093 (3.113)-----Loss 3.1165 (3.1567)\n",
      "Epoch 5/21-----Batch 33780/59476-----Step 22640/100000-----Data Time 0.007 (0.005)-----Step Time 3.077 (3.113)-----Loss 2.8187 (3.1568)\n",
      "Epoch 5/21-----Batch 34020/59476-----Step 22660/100000-----Data Time 0.003 (0.005)-----Step Time 3.132 (3.113)-----Loss 2.4865 (3.1569)\n",
      "Epoch 5/21-----Batch 34260/59476-----Step 22680/100000-----Data Time 0.003 (0.005)-----Step Time 3.124 (3.113)-----Loss 2.8296 (3.1566)\n",
      "Epoch 5/21-----Batch 34500/59476-----Step 22700/100000-----Data Time 0.003 (0.005)-----Step Time 3.131 (3.113)-----Loss 3.0430 (3.1567)\n",
      "Epoch 5/21-----Batch 34740/59476-----Step 22720/100000-----Data Time 0.005 (0.005)-----Step Time 3.135 (3.113)-----Loss 3.1309 (3.1565)\n",
      "Epoch 5/21-----Batch 34980/59476-----Step 22740/100000-----Data Time 0.003 (0.005)-----Step Time 3.009 (3.113)-----Loss 4.3041 (3.1565)\n",
      "Epoch 5/21-----Batch 35220/59476-----Step 22760/100000-----Data Time 0.003 (0.005)-----Step Time 3.089 (3.113)-----Loss 3.4396 (3.1564)\n",
      "Epoch 5/21-----Batch 35460/59476-----Step 22780/100000-----Data Time 0.003 (0.005)-----Step Time 3.050 (3.113)-----Loss 3.1953 (3.1561)\n",
      "Epoch 5/21-----Batch 35700/59476-----Step 22800/100000-----Data Time 0.003 (0.005)-----Step Time 3.040 (3.113)-----Loss 2.4312 (3.1559)\n",
      "Epoch 5/21-----Batch 35940/59476-----Step 22820/100000-----Data Time 0.004 (0.005)-----Step Time 3.004 (3.113)-----Loss 3.0311 (3.1557)\n",
      "Epoch 5/21-----Batch 36180/59476-----Step 22840/100000-----Data Time 0.003 (0.005)-----Step Time 3.110 (3.113)-----Loss 2.4135 (3.1556)\n",
      "Epoch 5/21-----Batch 36420/59476-----Step 22860/100000-----Data Time 0.005 (0.005)-----Step Time 3.061 (3.113)-----Loss 2.8867 (3.1552)\n",
      "Epoch 5/21-----Batch 36660/59476-----Step 22880/100000-----Data Time 0.003 (0.005)-----Step Time 3.064 (3.113)-----Loss 2.8100 (3.1553)\n",
      "Epoch 5/21-----Batch 36900/59476-----Step 22900/100000-----Data Time 0.003 (0.005)-----Step Time 3.092 (3.113)-----Loss 4.1175 (3.1558)\n",
      "Epoch 5/21-----Batch 37140/59476-----Step 22920/100000-----Data Time 0.010 (0.005)-----Step Time 3.061 (3.113)-----Loss 3.4639 (3.1559)\n",
      "Epoch 5/21-----Batch 37380/59476-----Step 22940/100000-----Data Time 0.004 (0.005)-----Step Time 3.196 (3.113)-----Loss 3.9195 (3.1557)\n",
      "Epoch 5/21-----Batch 37620/59476-----Step 22960/100000-----Data Time 0.003 (0.005)-----Step Time 3.040 (3.113)-----Loss 3.0540 (3.1559)\n",
      "Epoch 5/21-----Batch 37860/59476-----Step 22980/100000-----Data Time 0.004 (0.005)-----Step Time 3.074 (3.113)-----Loss 2.7693 (3.1556)\n",
      "Epoch 5/21-----Batch 38100/59476-----Step 23000/100000-----Data Time 0.005 (0.005)-----Step Time 3.033 (3.113)-----Loss 3.1107 (3.1553)\n",
      "Epoch 5/21-----Batch 38340/59476-----Step 23020/100000-----Data Time 0.003 (0.005)-----Step Time 3.078 (3.113)-----Loss 2.4785 (3.1555)\n",
      "Epoch 5/21-----Batch 38580/59476-----Step 23040/100000-----Data Time 0.003 (0.005)-----Step Time 3.063 (3.113)-----Loss 2.6100 (3.1556)\n",
      "Epoch 5/21-----Batch 38820/59476-----Step 23060/100000-----Data Time 0.003 (0.005)-----Step Time 3.186 (3.113)-----Loss 3.2580 (3.1556)\n",
      "Epoch 5/21-----Batch 39060/59476-----Step 23080/100000-----Data Time 0.004 (0.005)-----Step Time 3.183 (3.113)-----Loss 3.5127 (3.1560)\n",
      "Epoch 5/21-----Batch 39300/59476-----Step 23100/100000-----Data Time 0.003 (0.005)-----Step Time 3.090 (3.113)-----Loss 3.1986 (3.1562)\n",
      "Epoch 5/21-----Batch 39540/59476-----Step 23120/100000-----Data Time 0.003 (0.005)-----Step Time 3.121 (3.113)-----Loss 3.0041 (3.1564)\n",
      "Epoch 5/21-----Batch 39780/59476-----Step 23140/100000-----Data Time 0.003 (0.005)-----Step Time 3.462 (3.113)-----Loss 2.4458 (3.1563)\n",
      "Epoch 5/21-----Batch 40020/59476-----Step 23160/100000-----Data Time 0.003 (0.005)-----Step Time 3.106 (3.113)-----Loss 2.5953 (3.1567)\n",
      "Epoch 5/21-----Batch 40260/59476-----Step 23180/100000-----Data Time 0.003 (0.005)-----Step Time 3.118 (3.113)-----Loss 2.9713 (3.1564)\n",
      "Epoch 5/21-----Batch 40500/59476-----Step 23200/100000-----Data Time 0.003 (0.005)-----Step Time 3.264 (3.113)-----Loss 3.5732 (3.1565)\n",
      "Epoch 5/21-----Batch 40740/59476-----Step 23220/100000-----Data Time 0.004 (0.005)-----Step Time 3.109 (3.113)-----Loss 2.5962 (3.1562)\n",
      "Epoch 5/21-----Batch 40980/59476-----Step 23240/100000-----Data Time 0.004 (0.005)-----Step Time 3.166 (3.113)-----Loss 3.0915 (3.1561)\n",
      "Epoch 5/21-----Batch 41220/59476-----Step 23260/100000-----Data Time 0.003 (0.005)-----Step Time 3.087 (3.113)-----Loss 2.8331 (3.1558)\n",
      "Epoch 5/21-----Batch 41460/59476-----Step 23280/100000-----Data Time 0.004 (0.005)-----Step Time 3.217 (3.113)-----Loss 2.4850 (3.1555)\n",
      "Epoch 5/21-----Batch 41700/59476-----Step 23300/100000-----Data Time 0.003 (0.005)-----Step Time 3.104 (3.113)-----Loss 2.7865 (3.1556)\n",
      "Epoch 5/21-----Batch 41940/59476-----Step 23320/100000-----Data Time 0.003 (0.005)-----Step Time 3.129 (3.113)-----Loss 2.7607 (3.1553)\n",
      "Epoch 5/21-----Batch 42180/59476-----Step 23340/100000-----Data Time 0.003 (0.005)-----Step Time 3.073 (3.113)-----Loss 3.3709 (3.1551)\n",
      "Epoch 5/21-----Batch 42420/59476-----Step 23360/100000-----Data Time 0.003 (0.005)-----Step Time 3.151 (3.113)-----Loss 2.9955 (3.1553)\n",
      "Epoch 5/21-----Batch 42660/59476-----Step 23380/100000-----Data Time 0.004 (0.005)-----Step Time 3.155 (3.113)-----Loss 2.9983 (3.1550)\n",
      "Epoch 5/21-----Batch 42900/59476-----Step 23400/100000-----Data Time 0.004 (0.005)-----Step Time 3.063 (3.113)-----Loss 3.0837 (3.1547)\n",
      "Epoch 5/21-----Batch 43140/59476-----Step 23420/100000-----Data Time 0.004 (0.005)-----Step Time 3.104 (3.113)-----Loss 2.5922 (3.1544)\n",
      "Epoch 5/21-----Batch 43380/59476-----Step 23440/100000-----Data Time 0.004 (0.005)-----Step Time 3.202 (3.113)-----Loss 2.9909 (3.1545)\n",
      "Epoch 5/21-----Batch 43620/59476-----Step 23460/100000-----Data Time 0.003 (0.005)-----Step Time 3.104 (3.113)-----Loss 2.6398 (3.1543)\n",
      "Epoch 5/21-----Batch 43860/59476-----Step 23480/100000-----Data Time 0.003 (0.005)-----Step Time 3.055 (3.113)-----Loss 2.4976 (3.1544)\n",
      "Epoch 5/21-----Batch 44100/59476-----Step 23500/100000-----Data Time 0.008 (0.005)-----Step Time 3.166 (3.113)-----Loss 2.5299 (3.1543)\n",
      "Epoch 5/21-----Batch 44340/59476-----Step 23520/100000-----Data Time 0.005 (0.005)-----Step Time 3.075 (3.113)-----Loss 2.6272 (3.1541)\n",
      "Epoch 5/21-----Batch 44580/59476-----Step 23540/100000-----Data Time 0.004 (0.005)-----Step Time 3.061 (3.113)-----Loss 2.6817 (3.1541)\n",
      "Epoch 5/21-----Batch 44820/59476-----Step 23560/100000-----Data Time 0.004 (0.005)-----Step Time 3.145 (3.113)-----Loss 3.1323 (3.1543)\n",
      "Epoch 5/21-----Batch 45060/59476-----Step 23580/100000-----Data Time 0.004 (0.005)-----Step Time 3.148 (3.113)-----Loss 4.2732 (3.1542)\n",
      "Epoch 5/21-----Batch 45300/59476-----Step 23600/100000-----Data Time 0.003 (0.005)-----Step Time 3.117 (3.113)-----Loss 3.1050 (3.1542)\n",
      "Epoch 5/21-----Batch 45540/59476-----Step 23620/100000-----Data Time 0.003 (0.005)-----Step Time 3.129 (3.113)-----Loss 3.1288 (3.1540)\n",
      "Epoch 5/21-----Batch 45780/59476-----Step 23640/100000-----Data Time 0.003 (0.005)-----Step Time 3.132 (3.113)-----Loss 3.7777 (3.1538)\n",
      "Epoch 5/21-----Batch 46020/59476-----Step 23660/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.113)-----Loss 2.6593 (3.1540)\n",
      "Epoch 5/21-----Batch 46260/59476-----Step 23680/100000-----Data Time 0.003 (0.005)-----Step Time 3.140 (3.113)-----Loss 2.5283 (3.1540)\n",
      "Epoch 5/21-----Batch 46500/59476-----Step 23700/100000-----Data Time 0.003 (0.005)-----Step Time 3.086 (3.113)-----Loss 2.3506 (3.1541)\n",
      "Epoch 5/21-----Batch 46740/59476-----Step 23720/100000-----Data Time 0.003 (0.005)-----Step Time 3.072 (3.113)-----Loss 2.7306 (3.1543)\n",
      "Epoch 5/21-----Batch 46980/59476-----Step 23740/100000-----Data Time 0.003 (0.005)-----Step Time 3.039 (3.113)-----Loss 3.7817 (3.1543)\n",
      "Epoch 5/21-----Batch 47220/59476-----Step 23760/100000-----Data Time 0.003 (0.005)-----Step Time 3.014 (3.114)-----Loss 3.0080 (3.1544)\n",
      "Epoch 5/21-----Batch 47460/59476-----Step 23780/100000-----Data Time 0.004 (0.005)-----Step Time 3.125 (3.114)-----Loss 3.1152 (3.1544)\n",
      "Epoch 5/21-----Batch 47700/59476-----Step 23800/100000-----Data Time 0.004 (0.005)-----Step Time 3.092 (3.113)-----Loss 3.4119 (3.1547)\n",
      "Epoch 5/21-----Batch 47940/59476-----Step 23820/100000-----Data Time 0.003 (0.005)-----Step Time 3.072 (3.113)-----Loss 3.3119 (3.1547)\n",
      "Epoch 5/21-----Batch 48180/59476-----Step 23840/100000-----Data Time 0.005 (0.005)-----Step Time 3.194 (3.114)-----Loss 2.6292 (3.1546)\n",
      "Epoch 5/21-----Batch 48420/59476-----Step 23860/100000-----Data Time 0.004 (0.005)-----Step Time 3.121 (3.114)-----Loss 2.8818 (3.1544)\n",
      "Epoch 5/21-----Batch 48660/59476-----Step 23880/100000-----Data Time 0.003 (0.005)-----Step Time 3.107 (3.114)-----Loss 2.7100 (3.1546)\n",
      "Epoch 5/21-----Batch 48900/59476-----Step 23900/100000-----Data Time 0.004 (0.005)-----Step Time 3.053 (3.114)-----Loss 2.9448 (3.1543)\n",
      "Epoch 5/21-----Batch 49140/59476-----Step 23920/100000-----Data Time 0.003 (0.005)-----Step Time 3.170 (3.114)-----Loss 2.5904 (3.1543)\n",
      "Epoch 5/21-----Batch 49380/59476-----Step 23940/100000-----Data Time 0.003 (0.005)-----Step Time 3.106 (3.114)-----Loss 2.7330 (3.1544)\n",
      "Epoch 5/21-----Batch 49620/59476-----Step 23960/100000-----Data Time 0.004 (0.005)-----Step Time 3.117 (3.114)-----Loss 3.5766 (3.1541)\n",
      "Epoch 5/21-----Batch 49860/59476-----Step 23980/100000-----Data Time 0.004 (0.005)-----Step Time 3.055 (3.114)-----Loss 3.5840 (3.1541)\n",
      "Epoch 5/21-----Batch 50100/59476-----Step 24000/100000-----Data Time 0.004 (0.005)-----Step Time 3.138 (3.114)-----Loss 2.6289 (3.1539)\n",
      "Epoch 5/21-----Batch 50340/59476-----Step 24020/100000-----Data Time 0.003 (0.005)-----Step Time 3.111 (3.113)-----Loss 2.5159 (3.1537)\n",
      "Epoch 5/21-----Batch 50580/59476-----Step 24040/100000-----Data Time 0.005 (0.005)-----Step Time 3.110 (3.113)-----Loss 2.2906 (3.1535)\n",
      "Epoch 5/21-----Batch 50820/59476-----Step 24060/100000-----Data Time 0.003 (0.005)-----Step Time 3.029 (3.113)-----Loss 3.4041 (3.1535)\n",
      "Epoch 5/21-----Batch 51060/59476-----Step 24080/100000-----Data Time 0.003 (0.005)-----Step Time 3.409 (3.114)-----Loss 4.3524 (3.1535)\n",
      "Epoch 5/21-----Batch 51300/59476-----Step 24100/100000-----Data Time 0.003 (0.005)-----Step Time 3.017 (3.114)-----Loss 3.4922 (3.1534)\n",
      "Epoch 5/21-----Batch 51540/59476-----Step 24120/100000-----Data Time 0.003 (0.005)-----Step Time 2.993 (3.114)-----Loss 3.9000 (3.1534)\n",
      "Epoch 5/21-----Batch 51780/59476-----Step 24140/100000-----Data Time 0.003 (0.005)-----Step Time 3.061 (3.113)-----Loss 3.3805 (3.1532)\n",
      "Epoch 5/21-----Batch 52020/59476-----Step 24160/100000-----Data Time 0.003 (0.005)-----Step Time 3.069 (3.113)-----Loss 3.8937 (3.1534)\n",
      "Epoch 5/21-----Batch 52260/59476-----Step 24180/100000-----Data Time 0.003 (0.005)-----Step Time 3.162 (3.113)-----Loss 2.4224 (3.1533)\n",
      "Epoch 5/21-----Batch 52500/59476-----Step 24200/100000-----Data Time 0.004 (0.005)-----Step Time 3.043 (3.113)-----Loss 2.5955 (3.1532)\n",
      "Epoch 5/21-----Batch 52740/59476-----Step 24220/100000-----Data Time 0.003 (0.005)-----Step Time 3.115 (3.113)-----Loss 3.4565 (3.1531)\n",
      "Epoch 5/21-----Batch 52980/59476-----Step 24240/100000-----Data Time 0.003 (0.005)-----Step Time 3.076 (3.113)-----Loss 3.9733 (3.1530)\n",
      "Epoch 5/21-----Batch 53220/59476-----Step 24260/100000-----Data Time 0.003 (0.005)-----Step Time 3.129 (3.113)-----Loss 4.1069 (3.1531)\n",
      "Epoch 5/21-----Batch 53460/59476-----Step 24280/100000-----Data Time 0.004 (0.005)-----Step Time 3.104 (3.113)-----Loss 2.9544 (3.1533)\n",
      "Epoch 5/21-----Batch 53700/59476-----Step 24300/100000-----Data Time 0.004 (0.005)-----Step Time 3.109 (3.113)-----Loss 3.3723 (3.1532)\n",
      "Epoch 5/21-----Batch 53940/59476-----Step 24320/100000-----Data Time 0.003 (0.005)-----Step Time 3.110 (3.113)-----Loss 2.6608 (3.1531)\n",
      "Epoch 5/21-----Batch 54180/59476-----Step 24340/100000-----Data Time 0.003 (0.005)-----Step Time 3.047 (3.113)-----Loss 2.9981 (3.1532)\n",
      "Epoch 5/21-----Batch 54420/59476-----Step 24360/100000-----Data Time 0.003 (0.005)-----Step Time 3.076 (3.113)-----Loss 3.1369 (3.1528)\n",
      "Epoch 5/21-----Batch 54660/59476-----Step 24380/100000-----Data Time 0.003 (0.005)-----Step Time 3.108 (3.113)-----Loss 2.8708 (3.1524)\n",
      "Epoch 5/21-----Batch 54900/59476-----Step 24400/100000-----Data Time 0.003 (0.005)-----Step Time 3.135 (3.113)-----Loss 2.9379 (3.1522)\n",
      "Epoch 5/21-----Batch 55140/59476-----Step 24420/100000-----Data Time 0.005 (0.005)-----Step Time 3.151 (3.113)-----Loss 2.9404 (3.1522)\n",
      "Epoch 5/21-----Batch 55380/59476-----Step 24440/100000-----Data Time 0.004 (0.005)-----Step Time 3.056 (3.113)-----Loss 3.3361 (3.1524)\n",
      "Epoch 5/21-----Batch 55620/59476-----Step 24460/100000-----Data Time 0.003 (0.005)-----Step Time 3.144 (3.113)-----Loss 3.4918 (3.1522)\n",
      "Epoch 5/21-----Batch 55860/59476-----Step 24480/100000-----Data Time 0.003 (0.005)-----Step Time 3.172 (3.113)-----Loss 3.3998 (3.1521)\n",
      "Epoch 5/21-----Batch 56100/59476-----Step 24500/100000-----Data Time 0.003 (0.005)-----Step Time 3.127 (3.113)-----Loss 2.9924 (3.1520)\n",
      "Epoch 5/21-----Batch 56340/59476-----Step 24520/100000-----Data Time 0.003 (0.005)-----Step Time 3.194 (3.113)-----Loss 2.6766 (3.1519)\n",
      "Epoch 5/21-----Batch 56580/59476-----Step 24540/100000-----Data Time 0.005 (0.005)-----Step Time 3.208 (3.113)-----Loss 2.8795 (3.1516)\n",
      "Epoch 5/21-----Batch 56820/59476-----Step 24560/100000-----Data Time 0.003 (0.005)-----Step Time 3.073 (3.113)-----Loss 2.9715 (3.1516)\n",
      "Epoch 5/21-----Batch 57060/59476-----Step 24580/100000-----Data Time 0.003 (0.005)-----Step Time 3.098 (3.113)-----Loss 3.1804 (3.1516)\n",
      "Epoch 5/21-----Batch 57300/59476-----Step 24600/100000-----Data Time 0.003 (0.005)-----Step Time 3.097 (3.113)-----Loss 2.6635 (3.1513)\n",
      "Epoch 5/21-----Batch 57540/59476-----Step 24620/100000-----Data Time 0.003 (0.005)-----Step Time 3.092 (3.113)-----Loss 3.7229 (3.1511)\n",
      "Epoch 5/21-----Batch 57780/59476-----Step 24640/100000-----Data Time 0.005 (0.005)-----Step Time 3.156 (3.113)-----Loss 2.9052 (3.1512)\n",
      "Epoch 5/21-----Batch 58020/59476-----Step 24660/100000-----Data Time 0.003 (0.005)-----Step Time 3.128 (3.113)-----Loss 3.0087 (3.1511)\n",
      "Epoch 5/21-----Batch 58260/59476-----Step 24680/100000-----Data Time 0.003 (0.005)-----Step Time 3.085 (3.113)-----Loss 2.8059 (3.1509)\n",
      "Epoch 5/21-----Batch 58500/59476-----Step 24700/100000-----Data Time 0.004 (0.005)-----Step Time 3.078 (3.113)-----Loss 2.8140 (3.1509)\n",
      "Epoch 5/21-----Batch 58740/59476-----Step 24720/100000-----Data Time 0.003 (0.005)-----Step Time 3.611 (3.114)-----Loss 3.3157 (3.1508)\n",
      "Epoch 5/21-----Batch 58980/59476-----Step 24740/100000-----Data Time 0.004 (0.005)-----Step Time 3.105 (3.114)-----Loss 3.1923 (3.1507)\n",
      "Epoch 5/21-----Batch 59220/59476-----Step 24760/100000-----Data Time 0.003 (0.005)-----Step Time 3.124 (3.114)-----Loss 4.0737 (3.1505)\n",
      "Epoch 5/21-----Batch 59460/59476-----Step 24780/100000-----Data Time 0.003 (0.005)-----Step Time 3.111 (3.114)-----Loss 3.2378 (3.1502)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:36<00:00, 82.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation loss: 3.112\n",
      "\n",
      "\n",
      " Epoch #  5\n",
      "Epoch 6/21-----Batch 228/59476-----Step 24800/100000-----Data Time 0.004 (0.005)-----Step Time 3.134 (3.029)-----Loss 2.9512 (3.0923)\n",
      "Epoch 6/21-----Batch 468/59476-----Step 24820/100000-----Data Time 0.004 (0.005)-----Step Time 3.098 (3.058)-----Loss 3.3053 (3.0648)\n",
      "Epoch 6/21-----Batch 708/59476-----Step 24840/100000-----Data Time 0.003 (0.005)-----Step Time 3.148 (3.071)-----Loss 2.3414 (3.0610)\n",
      "Epoch 6/21-----Batch 948/59476-----Step 24860/100000-----Data Time 0.003 (0.005)-----Step Time 3.106 (3.076)-----Loss 3.2027 (3.0711)\n",
      "Epoch 6/21-----Batch 1188/59476-----Step 24880/100000-----Data Time 0.004 (0.005)-----Step Time 3.160 (3.079)-----Loss 4.2910 (3.0719)\n",
      "Epoch 6/21-----Batch 1428/59476-----Step 24900/100000-----Data Time 0.004 (0.005)-----Step Time 3.151 (3.085)-----Loss 3.7894 (3.0732)\n",
      "Epoch 6/21-----Batch 1668/59476-----Step 24920/100000-----Data Time 0.003 (0.005)-----Step Time 3.025 (3.091)-----Loss 3.1544 (3.0738)\n",
      "Epoch 6/21-----Batch 1908/59476-----Step 24940/100000-----Data Time 0.004 (0.005)-----Step Time 3.060 (3.094)-----Loss 3.7923 (3.0677)\n",
      "Epoch 6/21-----Batch 2148/59476-----Step 24960/100000-----Data Time 0.006 (0.005)-----Step Time 3.104 (3.094)-----Loss 1.7366 (3.0728)\n",
      "Epoch 6/21-----Batch 2388/59476-----Step 24980/100000-----Data Time 0.004 (0.005)-----Step Time 3.059 (3.094)-----Loss 2.5096 (3.0743)\n",
      "Epoch 6/21-----Batch 2628/59476-----Step 25000/100000-----Data Time 0.003 (0.005)-----Step Time 3.061 (3.094)-----Loss 2.4550 (3.0798)\n",
      "Epoch 6/21-----Batch 2868/59476-----Step 25020/100000-----Data Time 0.009 (0.005)-----Step Time 3.084 (3.096)-----Loss 3.0794 (3.0807)\n",
      "Epoch 6/21-----Batch 3108/59476-----Step 25040/100000-----Data Time 0.004 (0.005)-----Step Time 3.120 (3.099)-----Loss 2.8662 (3.0827)\n",
      "Epoch 6/21-----Batch 3348/59476-----Step 25060/100000-----Data Time 0.003 (0.005)-----Step Time 3.073 (3.100)-----Loss 3.0006 (3.0855)\n",
      "Epoch 6/21-----Batch 3588/59476-----Step 25080/100000-----Data Time 0.003 (0.005)-----Step Time 3.059 (3.101)-----Loss 2.8232 (3.0908)\n",
      "Epoch 6/21-----Batch 3828/59476-----Step 25100/100000-----Data Time 0.003 (0.005)-----Step Time 3.039 (3.101)-----Loss 2.7741 (3.0890)\n",
      "Epoch 6/21-----Batch 4068/59476-----Step 25120/100000-----Data Time 0.003 (0.005)-----Step Time 3.172 (3.102)-----Loss 3.6388 (3.0921)\n",
      "Epoch 6/21-----Batch 4308/59476-----Step 25140/100000-----Data Time 0.003 (0.005)-----Step Time 3.099 (3.103)-----Loss 2.6872 (3.0944)\n",
      "Epoch 6/21-----Batch 4548/59476-----Step 25160/100000-----Data Time 0.003 (0.005)-----Step Time 2.984 (3.102)-----Loss 2.5824 (3.0935)\n",
      "Epoch 6/21-----Batch 4788/59476-----Step 25180/100000-----Data Time 0.005 (0.005)-----Step Time 3.174 (3.105)-----Loss 2.5922 (3.0913)\n",
      "Epoch 6/21-----Batch 5028/59476-----Step 25200/100000-----Data Time 0.004 (0.005)-----Step Time 3.063 (3.105)-----Loss 2.4763 (3.0948)\n",
      "Epoch 6/21-----Batch 5268/59476-----Step 25220/100000-----Data Time 0.003 (0.005)-----Step Time 3.074 (3.104)-----Loss 2.7886 (3.0974)\n",
      "Epoch 6/21-----Batch 5508/59476-----Step 25240/100000-----Data Time 0.003 (0.005)-----Step Time 3.116 (3.104)-----Loss 3.3283 (3.0960)\n",
      "Epoch 6/21-----Batch 5748/59476-----Step 25260/100000-----Data Time 0.005 (0.005)-----Step Time 3.207 (3.103)-----Loss 2.4638 (3.0949)\n",
      "Epoch 6/21-----Batch 5988/59476-----Step 25280/100000-----Data Time 0.004 (0.005)-----Step Time 3.061 (3.103)-----Loss 3.3988 (3.0942)\n",
      "Epoch 6/21-----Batch 6228/59476-----Step 25300/100000-----Data Time 0.004 (0.005)-----Step Time 3.098 (3.104)-----Loss 4.2822 (3.0945)\n",
      "Epoch 6/21-----Batch 6468/59476-----Step 25320/100000-----Data Time 0.004 (0.005)-----Step Time 3.054 (3.104)-----Loss 3.3115 (3.0931)\n",
      "Epoch 6/21-----Batch 6708/59476-----Step 25340/100000-----Data Time 0.003 (0.005)-----Step Time 3.127 (3.103)-----Loss 3.3849 (3.0944)\n",
      "Epoch 6/21-----Batch 6948/59476-----Step 25360/100000-----Data Time 0.003 (0.005)-----Step Time 3.141 (3.103)-----Loss 3.3167 (3.0955)\n",
      "Epoch 6/21-----Batch 7188/59476-----Step 25380/100000-----Data Time 0.003 (0.005)-----Step Time 3.060 (3.103)-----Loss 2.6634 (3.0955)\n",
      "Epoch 6/21-----Batch 7428/59476-----Step 25400/100000-----Data Time 0.003 (0.005)-----Step Time 3.462 (3.103)-----Loss 2.7128 (3.0964)\n",
      "Epoch 6/21-----Batch 7668/59476-----Step 25420/100000-----Data Time 0.004 (0.005)-----Step Time 3.100 (3.103)-----Loss 2.9463 (3.0949)\n",
      "Epoch 6/21-----Batch 7908/59476-----Step 25440/100000-----Data Time 0.004 (0.005)-----Step Time 3.107 (3.103)-----Loss 3.8900 (3.0944)\n",
      "Epoch 6/21-----Batch 8148/59476-----Step 25460/100000-----Data Time 0.003 (0.005)-----Step Time 3.044 (3.103)-----Loss 2.8391 (3.0936)\n",
      "Epoch 6/21-----Batch 8388/59476-----Step 25480/100000-----Data Time 0.004 (0.005)-----Step Time 3.055 (3.103)-----Loss 2.8717 (3.0944)\n",
      "Epoch 6/21-----Batch 8628/59476-----Step 25500/100000-----Data Time 0.003 (0.005)-----Step Time 3.055 (3.103)-----Loss 2.9848 (3.0936)\n",
      "Epoch 6/21-----Batch 8868/59476-----Step 25520/100000-----Data Time 0.003 (0.005)-----Step Time 3.322 (3.113)-----Loss 3.3708 (3.0967)\n",
      "Epoch 6/21-----Batch 9108/59476-----Step 25540/100000-----Data Time 0.004 (0.005)-----Step Time 3.430 (3.117)-----Loss 2.7687 (3.0966)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# One epoch's training\u001b[39;00m\n\u001b[1;32m     10\u001b[0m train_loader\u001b[38;5;241m.\u001b[39mcreate_batches()\n\u001b[0;32m---> 11\u001b[0m train(train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[1;32m     12\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     13\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m     14\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     15\u001b[0m         epoch\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m     16\u001b[0m         step\u001b[38;5;241m=\u001b[39mstep)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# One epoch's validation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m val_loader\u001b[38;5;241m.\u001b[39mcreate_batches()\n",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, step)\u001b[0m\n\u001b[1;32m     48\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(inputs\u001b[38;5;241m=\u001b[39mpredicted_sequences,\n\u001b[1;32m     49\u001b[0m                  targets\u001b[38;5;241m=\u001b[39mtarget_sequences[:, \u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m     50\u001b[0m                  lengths\u001b[38;5;241m=\u001b[39mtarget_sequence_lengths \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# scalar\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Backward prop.\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m (loss \u001b[38;5;241m/\u001b[39m batches_per_step)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Keep track of losses\u001b[39;00m\n\u001b[1;32m     56\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mitem(), (target_sequence_lengths \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[1;32m    268\u001b[0m     tensors,\n\u001b[1;32m    269\u001b[0m     grad_tensors_,\n\u001b[1;32m    270\u001b[0m     retain_graph,\n\u001b[1;32m    271\u001b[0m     create_graph,\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## BEGIN THE TRAINING MY PADAWAN:\n",
    "# Epochs\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # Step\n",
    "    step = epoch * train_loader.n_batches // batches_per_step\n",
    "\n",
    "    print(\" Epoch # \", epoch)\n",
    "\n",
    "    # One epoch's training\n",
    "    train_loader.create_batches()\n",
    "    train(train_loader=train_loader,\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            epoch=epoch,\n",
    "            step=step)\n",
    "\n",
    "    # One epoch's validation\n",
    "    val_loader.create_batches()\n",
    "    validate(val_loader=val_loader,\n",
    "                model=model,\n",
    "                criterion=criterion)\n",
    "\n",
    "    # Save checkpoint\n",
    "    save_checkpoint(epoch, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best translation:  Das Leben ist wie ein Fahrrad, um Ihr Gleichgewicht zu bewahren, müssen Sie sich immer bewegen.\n"
     ]
    }
   ],
   "source": [
    "# Translate: \n",
    "from translate import translate\n",
    "\n",
    "best, all = translate(\"Life is like riding a bicycle. To keep your balance, you must keep moving\")\n",
    "\n",
    "print(\" Best translation: \", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3003/3003 [12:03<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13a tokenization, cased:\n",
      "\n",
      "BLEU = 22.45 54.3/28.1/16.5/10.1 (BP = 1.000 ratio = 1.028 hyp_len = 64440 ref_len = 62688)\n",
      "\n",
      "13a tokenization, caseless:\n",
      "\n",
      "BLEU = 22.89 55.3/28.6/16.8/10.3 (BP = 1.000 ratio = 1.028 hyp_len = 64440 ref_len = 62688)\n",
      "\n",
      "International tokenization, cased:\n",
      "\n",
      "BLEU = 23.11 55.1/28.8/17.1/10.5 (BP = 1.000 ratio = 1.018 hyp_len = 65829 ref_len = 64676)\n",
      "\n",
      "International tokenization, caseless:\n",
      "\n",
      "BLEU = 23.58 56.2/29.3/17.4/10.8 (BP = 1.000 ratio = 1.018 hyp_len = 65829 ref_len = 64676)\n",
      "\n",
      "\n",
      "The first value (13a tokenization, cased) is how the BLEU score is officially calculated by WMT (mteval-v13a.pl). \n",
      "This is probably not how it is calculated in the 'Attention Is All You Need' paper, however.\n",
      "See https://github.com/tensorflow/tensor2tensor/issues/317#issuecomment-380970191 for more details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sacrebleu\n",
    "from translate import translate\n",
    "from tqdm import tqdm\n",
    "from sequence_loader import SequenceLoader\n",
    "import youtokentome\n",
    "import codecs\n",
    "import os\n",
    "\n",
    "# Use sacreBLEU in Python or in the command-line?\n",
    "# Using in Python will use the test data downloaded in prepare_data.py\n",
    "# Using in the command-line will use test data automatically downloaded by sacreBLEU...\n",
    "# ...and will print a standard signature which represents the exact BLEU method used! (Important for others to be able to reproduce or compare!)\n",
    "sacrebleu_in_python = True\n",
    "\n",
    "data_folder = \"/home/savio/Documents/Tutorials/NLP_Tutorials/datasets/wmt-14-eng-deu\"\n",
    "\n",
    "# Make sure the right model checkpoint is selected in translate.py\n",
    "\n",
    "# Data loader\n",
    "test_loader = SequenceLoader(data_folder=data_folder,\n",
    "                             source_suffix=\"en\",\n",
    "                             target_suffix=\"de\",\n",
    "                             split=\"test\",\n",
    "                             tokens_in_batch=None)\n",
    "test_loader.create_batches()\n",
    "\n",
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    hypotheses = list()\n",
    "    references = list()\n",
    "    for i, (source_sequence, target_sequence, source_sequence_length, target_sequence_length, s_maks, t_mask) in enumerate(\n",
    "            tqdm(test_loader, total=test_loader.n_batches)):\n",
    "        hypotheses.append(translate(source_sequence=source_sequence,\n",
    "                                    beam_size=4,\n",
    "                                    length_norm_coefficient=0.6)[0])\n",
    "        references.extend(test_loader.bpe_model.decode(target_sequence.tolist(), ignore_ids=[0, 2, 3]))\n",
    "    if sacrebleu_in_python:\n",
    "        print(\"\\n13a tokenization, cased:\\n\")\n",
    "        print(sacrebleu.corpus_bleu(hypotheses, [references]))\n",
    "        print(\"\\n13a tokenization, caseless:\\n\")\n",
    "        print(sacrebleu.corpus_bleu(hypotheses, [references], lowercase=True))\n",
    "        print(\"\\nInternational tokenization, cased:\\n\")\n",
    "        print(sacrebleu.corpus_bleu(hypotheses, [references], tokenize='intl'))\n",
    "        print(\"\\nInternational tokenization, caseless:\\n\")\n",
    "        print(sacrebleu.corpus_bleu(hypotheses, [references], tokenize='intl', lowercase=True))\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        with codecs.open(\"translated_test.de\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(hypotheses))\n",
    "        print(\"\\n13a tokenization, cased:\\n\")\n",
    "        os.system(\"cat translated_test.de | sacrebleu -t wmt14/full -l en-de\")\n",
    "        print(\"\\n13a tokenization, caseless:\\n\")\n",
    "        os.system(\"cat translated_test.de | sacrebleu -t wmt14/full -l en-de -lc\")\n",
    "        print(\"\\nInternational tokenization, cased:\\n\")\n",
    "        os.system(\"cat translated_test.de | sacrebleu -t wmt14/full -l en-de -tok intl\")\n",
    "        print(\"\\nInternational tokenization, caseless:\\n\")\n",
    "        os.system(\"cat translated_test.de | sacrebleu -t wmt14/full -l en-de -tok intl -lc\")\n",
    "        print(\"\\n\")\n",
    "    print(\n",
    "        \"The first value (13a tokenization, cased) is how the BLEU score is officially calculated by WMT (mteval-v13a.pl). \\nThis is probably not how it is calculated in the 'Attention Is All You Need' paper, however.\\nSee https://github.com/tensorflow/tensor2tensor/issues/317#issuecomment-380970191 for more details.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
